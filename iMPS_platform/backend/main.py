"use client"
from zoneinfo import ZoneInfo
from fastapi import FastAPI,HTTPException,Depends, status,Request,Query,APIRouter, WebSocket, WebSocketDisconnect
from fastapi.encoders import jsonable_encoder 
from fastapi.security import OAuth2PasswordRequestForm,OAuth2PasswordBearer
from jose import JWTError,jwt
from jose.exceptions import ExpiredSignatureError
from datetime import datetime, timedelta, UTC, timezone, time
from pymongo.errors import OperationFailure, PyMongoError,DuplicateKeyError
from pymongo import MongoClient
from pydantic import BaseModel,EmailStr,constr, Field
from bson.objectid import ObjectId
from fastapi.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
import json, os, asyncio

from fastapi.responses import StreamingResponse,Response
from typing import List, Any,Dict, Optional, Union, Literal,Mapping
import bcrypt
from dateutil import parser as dtparser
from bson.decimal128 import Decimal128
from fastapi import Path,UploadFile, File, Form
# from fastapi import UploadFile, File, Form
# from pathlib import Path 
from starlette.staticfiles import StaticFiles
import uuid
from zoneinfo import ZoneInfo
import re
from fastapi import HTTPException, Depends
from fastapi.responses import JSONResponse
from dateutil.relativedelta import relativedelta
import pathlib, secrets
from email.message import EmailMessage
import aiosmtplib
import paho.mqtt.client as mqtt
from contextlib import asynccontextmanager

SECRET_KEY = "supersecret"  # ‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏Ñ‡∏ß‡∏£‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô env
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 60
SESSION_IDLE_MINUTES = 15
REFRESH_TOKEN_EXPIRE_DAYS = 7
th_tz = ZoneInfo("Asia/Bangkok")

# .env ‡∏´‡∏£‡∏∑‡∏≠‡∏ú‡πà‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°
SMTP_HOST = os.getenv("SMTP_HOST", "smtp.gmail.com")
SMTP_PORT = int(os.getenv("SMTP_PORT", "587"))
SMTP_USER = os.getenv("SMTP_USER", "eds194655@gmail.com")
SMTP_PASS = os.getenv("SMTP_PASS", "depllvpufjwtpysc")
SENDER_EMAIL = os.getenv("SENDER_EMAIL", "eds194655@gmail.com")

# BASE = Path(__file__).parent
app = FastAPI()

client1 = MongoClient("mongodb://imps_platform:eds_imps@203.154.130.132:27017/")
client = AsyncIOMotorClient("mongodb://imps_platform:eds_imps@203.154.130.132:27017/")

deviceDB = client["utilizationFactor"]
settingDB = client["settingParameter"]
errorDB = client["errorCode"]

db = client1["iMPS"]
users_collection = db["users"]
station_collection = db["stations"]

MDB_DB = client["MDB"]

CBM_DB = client["monitorCBM"]

PMReportDB = client["PMReport"]
PMUrlDB = client["PMReportURL"]

MDBPMReportDB = client["MDBPMReport"]
MDBPMUrlDB = client["MDBPMReportURL"]

CCBPMReportDB = client["CCBPMReport"]
CCBPMUrlDB = client["CCBPMReportURL"]

CBBOXPMReportDB = client["CBBOXPMReport"]
CBBOXPMUrlDB = client["CBBOXPMReportURL"]

DCTestReportDB = client["DCTestReport"]
DCUrlDB = client["DCUrl"]

ACTestReportDB = client["ACTestReport"]
ACUrlDB = client["ACUrl"]

stationPMReportDB = client["stationPMReport"]
stationPMUrlDB = client["stationPMReportURL"]

CMReportDB = client["CMReport"]
CMUrlDB = client["CMReportURL"]
   
imps_db_async = client["iMPS"]
stations_coll_async = imps_db_async["stations"]
users_coll_async = imps_db_async["users"]
email_log_coll = imps_db_async["errorEmailLog"]

MDB_collection = MDB_DB["Klongluang3"]

BROKER_HOST = "212.80.215.42"
BROKER_PORT = 1883
MQTT_TOPIC  = "iMPS/Test/settingPLC"
MQTT_CLIENT_ID = "imps-backend-setting-plc"
mqtt_client = mqtt.Client(client_id=MQTT_CLIENT_ID, clean_session=True)

def _on_connect(client, userdata, flags, rc):
    pass

def _on_disconnect(client, userdata, rc):
    pass

mqtt_client.on_connect = _on_connect
mqtt_client.on_disconnect = _on_disconnect

async def lifespan(app: FastAPI):
    # ‡πÉ‡∏ä‡πâ connect_async + loop_start ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà block event loop
    mqtt_client.connect_async(BROKER_HOST, BROKER_PORT, keepalive=60)
    mqtt_client.loop_start()
    try:
        yield
    finally:
        try:
            mqtt_client.loop_stop()
            mqtt_client.disconnect()
        except Exception as e:
            print(f"[MQTT] disconnect error: {e}")

app = FastAPI(lifespan=lifespan)

# CORS (‡∏£‡∏∞‡∏ö‡∏∏ origin ‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡∏î‡∏±‡∏Å‡∏ä‡∏±‡∏ô)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def _validate_station_id(station_id: str):
    if not re.fullmatch(r"[A-Za-z0-9_\-]+", str(station_id)):
        raise HTTPException(status_code=400, detail="Bad station_id")

def get_mdb_collection_for(station_id: str):
    # ‡∏Å‡∏±‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡πÅ‡∏õ‡∏•‡∏Å ‡πÜ / injection: ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï a-z A-Z 0-9 _ -
    if not re.fullmatch(r"[A-Za-z0-9_\-]+", str(station_id)):
        raise HTTPException(status_code=400, detail="Bad station_id")
    return MDB_DB.get_collection(str(station_id))

def to_json(obj) -> str:
    # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô single-line ‡πÅ‡∏•‡∏∞‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö UTF-8
    return json.dumps(obj, ensure_ascii=False, separators=(",", ":"))

def get_errorCode_collection_for(station_id: str):
    if not re.fullmatch(r"[A-Za-z0-9_\-]+", str(station_id)):
        raise HTTPException(status_code=400, detail="Bad station_id")
    return errorDB.get_collection(str(station_id))

def _ensure_utc_iso(v):
    """
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á ISO-8601 (UTC 'Z') ‡πÄ‡∏™‡∏°‡∏≠
    - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô datetime ‚Üí ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô UTC + ‡πÄ‡∏ï‡∏¥‡∏° 'Z'
    - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á ISO ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏ã‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ ‚Üí ‡πÄ‡∏ï‡∏¥‡∏° 'Z'
    - ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô ‚Üí ‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏î‡∏¥‡∏°
    """
    if isinstance(v, datetime):
        return v.astimezone(timezone.utc).isoformat().replace("+00:00", "Z")

    if isinstance(v, str) and re.match(r'^\d{4}-\d{2}-\d{2}T', v) and not re.search(r'(Z|[+\-]\d{2}:\d{2})$', v):
        return v + 'Z'
    return v


# def create_access_token(data: dict, expires_delta: int | timedelta = 15):
#     if isinstance(expires_delta, int):
#         expire = datetime.utcnow() + timedelta(minutes=expires_delta)
#     else:
#         expire = datetime.utcnow() + expires_delta
#     data.update({"exp": expire})
#     return jwt.encode(data, SECRET_KEY, algorithm=ALGORITHM)

def create_access_token(data: dict, expires_delta: int | timedelta = 15):
    to_encode = dict(data)
    expire = (datetime.now(timezone.utc) + (timedelta(minutes=expires_delta) if isinstance(expires_delta, int) else expires_delta))
    to_encode["exp"] = int(expire.timestamp())
    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)

class LoginRequest(BaseModel):
    email: str
    password: str

# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["http://localhost:3001"],  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô port 3001 ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏ä‡∏•‡∏ã‡∏µ‡∏Å‡∏±‡∏ö‡∏û‡∏µ‡πà‡πÇ‡∏à‡πâ ‡∏£‡∏±‡∏ô 3000 ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://localhost:3001",
        "http://127.0.0.1:3000",
        "http://203.154.130.132:3000",
        "http://203.154.130.132:3001",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)



oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/login/")

class UserClaims(BaseModel):
    sub: str
    user_id: Optional[str] = None
    username: str
    role: str = "user"
    company: Optional[str] = None
    station_ids: List[str] = []
    

def get_current_user(request: Request) -> UserClaims:
    # 1) ‡∏•‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏Å‡∏Å‡∏µ‡πâ (‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö SSE)
    token = request.cookies.get(ACCESS_COOKIE_NAME)

    # 2) ‡∏™‡∏≥‡∏£‡∏≠‡∏á: Authorization: Bearer ...
    if not token:
        auth = request.headers.get("Authorization", "")
        if auth.startswith("Bearer "):
            token = auth.removeprefix("Bearer ").strip()

    if not token:
        raise HTTPException(status_code=401, detail="Not authenticated")

    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        sub = payload.get("sub")
        if not sub:
            raise HTTPException(status_code=401, detail="invalid_token")

        station_ids = payload.get("station_ids") or []
        if not isinstance(station_ids, list):
            station_ids = [station_ids]

        return UserClaims(
            sub=sub,
            user_id=payload.get("user_id"),
            username=payload.get("username"),
            role=payload.get("role", "user"),
            company=payload.get("company"),
            station_ids=station_ids,
        )
    except ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="token_expired")
    except JWTError:
        raise HTTPException(status_code=401, detail="invalid_token")

ACCESS_COOKIE_NAME = "access_token"

#####################loginnn
# @app.post("/login/")
# def login(form_data: OAuth2PasswordRequestForm = Depends()):
#     user = users_collection.find_one(
#         {"email": form_data.username},
#         {"_id": 1, "email": 1, "username": 1, "password": 1, "role": 1, "company": 1, "station_id": 1},
#     )
#     invalid_cred = HTTPException(status_code=401, detail="Invalid email or password")
#     if not user or not bcrypt.checkpw(form_data.password.encode("utf-8"), user["password"].encode("utf-8")):
#         raise invalid_cred

#     # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ station_ids ‡πÄ‡∏õ‡πá‡∏ô list ‡πÄ‡∏™‡∏°‡∏≠
#     station_ids = user.get("station_id", [])
#     if not isinstance(station_ids, list):
#         station_ids = [station_ids]

#     # ‚ñ∂ Access Token ‡πÉ‡∏™‡πà‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÑ‡∏ß‡πâ‡πÄ‡∏•‡∏¢
#     access_token = create_access_token({
#         "sub": user["email"],
#         "user_id": str(user["_id"]),
#         "username": user.get("username"),
#         "role": user.get("role", "user"),
#         "company": user.get("company"),
#         "station_ids": station_ids,
#     })

#     # ‚ñ∂ Refresh Token (‡∏°‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡∏π‡πà)
#     refresh_token = create_access_token({"sub": user["email"]}, expires_delta=timedelta(days=REFRESH_TOKEN_EXPIRE_DAYS))

#     # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï refresh token ‡πÉ‡∏ô DB (‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö hash ‡∏Å‡πá‡πÑ‡∏î‡πâ ‡∏ï‡∏≤‡∏°‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤)
#     users_collection.update_one({"_id": user["_id"]}, {"$set": {
#         "refreshTokens": [{
#             "token": refresh_token,
#             "createdAt": datetime.utcnow(),
#             "expiresAt": datetime.utcnow() + timedelta(days=REFRESH_TOKEN_EXPIRE_DAYS),
#         }]
#     }})

#     return {
#         "message": "Login success ‚úÖ",
#         "access_token": access_token,
#         "refresh_token": refresh_token,
#         "user": {
#             "user_id": str(user["_id"]),
#             "username": user.get("username"),
#             "email": user["email"],
#             "role": user.get("role", "user"),
#             "company": user.get("company"),
#             "station_id": station_ids,
#         }
#     }

# @app.post("/login/")
# def login(body: LoginRequest, response: Response):
#     # ‡∏´‡∏≤ user
#     user = users_collection.find_one(
#         {"email": body.email},
#         {"_id": 1, "email": 1, "username": 1, "password": 1, "role": 1, "company": 1, "station_id": 1},
#     )
#     if not user or not bcrypt.checkpw(body.password.encode("utf-8"), user["password"].encode("utf-8")):
#         raise HTTPException(status_code=401, detail="Invalid email or password")

#     # ‡πÉ‡∏´‡πâ station_id ‡πÄ‡∏õ‡πá‡∏ô list ‡πÄ‡∏™‡∏°‡∏≠
#     station_ids = user.get("station_id", [])
#     if not isinstance(station_ids, list):
#         station_ids = [station_ids]

#     # ‡∏≠‡∏≠‡∏Å access token
#     jwt_token = create_access_token({
#         "sub": user["email"],
#         "user_id": str(user["_id"]),
#         "username": user.get("username"),
#         "role": user.get("role", "user"),
#         "company": user.get("company"),
#         "station_ids": station_ids,
#     }, expires_delta=timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES))

#     # ‡∏≠‡∏≠‡∏Å refresh token (‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ)
#     refresh_token = create_access_token({"sub": user["email"]}, expires_delta=timedelta(days=REFRESH_TOKEN_EXPIRE_DAYS))
#     users_collection.update_one({"_id": user["_id"]}, {"$set": {
#         "refreshTokens": [{
#             "token": refresh_token,
#             "createdAt": datetime.now(timezone.utc),
#             "expiresAt": datetime.now(timezone.utc) + timedelta(days=REFRESH_TOKEN_EXPIRE_DAYS),
#         }]
#     }})

#     # ‡∏Ñ‡∏∏‡∏Å‡∏Å‡∏µ‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SSE (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç)
#     response.set_cookie(
#         key=ACCESS_COOKIE_NAME,
#         value=jwt_token,
#         httponly=True,
#         secure=False,          # üëà dev ‡∏ö‡∏ô http://localhost ‡πÉ‡∏´‡πâ False
#         samesite="lax",        # üëà dev ‡∏Ç‡πâ‡∏≤‡∏°‡∏û‡∏≠‡∏£‡πå‡∏ï‡∏ö‡πà‡∏≠‡∏¢ ‡πÉ‡∏ä‡πâ "lax" (‡∏ñ‡πâ‡∏≤ cross-domain ‡∏à‡∏£‡∏¥‡∏á‡∏Ñ‡πà‡∏≠‡∏¢‡πÉ‡∏ä‡πâ "none"+secure=True)
#         max_age=int(timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES).total_seconds()),
#         path="/",
#     )

#     # ‡∏Ñ‡∏∑‡∏ô‡πÉ‡∏´‡πâ frontend ‡πÄ‡∏Å‡πá‡∏ö‡∏î‡πâ‡∏ß‡∏¢ (‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö fetch ‡∏≠‡∏∑‡πà‡∏ô‡πÜ)
#     return {
#         "message": "ok",
#         "access_token": jwt_token,
#         "refresh_token": refresh_token,
#         "user": {
#             "user_id": str(user["_id"]),
#             "username": user.get("username"),
#             "email": user["email"],
#             "role": user.get("role", "user"),
#             "company": user.get("company"),
#             "station_id": station_ids,
#         }
#     }

@app.post("/login/")
def login(body: LoginRequest, response: Response):
    user = users_collection.find_one(
        {"email": body.email},
        {"_id": 1, "email": 1, "username": 1, "password": 1, "role": 1, "company": 1, "station_id": 1},
    )
    if not user or not bcrypt.checkpw(body.password.encode("utf-8"), user["password"].encode("utf-8")):
        raise HTTPException(status_code=401, detail="Invalid email or password")

    station_ids = user.get("station_id", [])
    if not isinstance(station_ids, list):
        station_ids = [station_ids]

    # üëá ‡∏™‡∏£‡πâ‡∏≤‡∏á session id + ‡∏ï‡∏µ‡∏ï‡∏£‡∏≤‡πÄ‡∏ß‡∏•‡∏≤
    now = datetime.now(timezone.utc)
    sid = str(uuid.uuid4())

    jwt_token = create_access_token({
        "sub": user["email"],
        "user_id": str(user["_id"]),
        "username": user.get("username"),
        "role": user.get("role", "user"),
        "company": user.get("company"),
        "station_ids": station_ids,
        "sid": sid,  # ‚¨ÖÔ∏è ‡πÅ‡∏ô‡∏ö session id ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô access token
    }, expires_delta=timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES))

    refresh_token = create_access_token({"sub": user["email"]}, expires_delta=timedelta(days=REFRESH_TOKEN_EXPIRE_DAYS))

    # ‚úÖ ‡∏ú‡∏π‡∏Å session ‡πÉ‡∏ô DB (‡πÄ‡∏Å‡πá‡∏ö lastActiveAt ‡πÑ‡∏ß‡πâ‡πÄ‡∏ä‡πá‡∏Ñ idle)
    users_collection.update_one(
        {"_id": user["_id"]},
        {"$set": {
            "refreshTokens": [{
                "sid": sid,
                "token": refresh_token,
                "createdAt": now,
                "lastActiveAt": now,
                "expiresAt": now + timedelta(days=REFRESH_TOKEN_EXPIRE_DAYS),
            }]
        }}
    )

    response.set_cookie(
        key=ACCESS_COOKIE_NAME,
        value=jwt_token,
        httponly=True,
        secure=False,
        samesite="lax",
        max_age=int(timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES).total_seconds()),
        path="/",
    )

    return {
        "message": "ok",
        "access_token": jwt_token,
        "refresh_token": refresh_token,
        "user": {
            "user_id": str(user["_id"]),
            "username": user.get("username"),
            "email": user["email"],
            "role": user.get("role", "user"),
            "company": user.get("company"),
            "station_id": station_ids,
        }
    }

@app.get("/me")
def me(current: UserClaims = Depends(get_current_user)):
    if not current.user_id:
        raise HTTPException(status_code=401, detail="Missing uid in token")

    u = users_collection.find_one(
        {"_id": ObjectId(current.user_id)},
        {"_id": 1, "username": 1, "email": 1, "role": 1, "company": 1, "tel": 1}
    )
    if not u:
        raise HTTPException(status_code=404, detail="User not found")

    return {
        "id": str(u["_id"]),
        "username": u.get("username") or "",
        "email": u.get("email") or "",
        "role": u.get("role") or "",
        "company": u.get("company") or "",
        "tel": u.get("tel") or "",
    }

@app.get("/my-stations/detail")
def my_stations_detail(current: UserClaims = Depends(get_current_user)):
    proj = {"_id": 0, "station_id": 1, "station_name": 1}

    if current.role == "admin":
        docs = list(station_collection.find({}, proj))
        return {"stations": docs}

    # non-admin ‚Üí ‡∏´‡∏≤ station ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á user ‡∏ô‡∏µ‡πâ (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á str ‡πÅ‡∏•‡∏∞ ObjectId)
    conds = [{"user_id": current.user_id}]
    try:
        conds.append({"user_id": ObjectId(current.user_id)})
    except Exception:
        pass

    docs = list(station_collection.find({"$or": conds}, proj))
    return {"stations": docs}

@app.get("/station/info")
def station_info(
    station_id: str = Query(...),
    current: UserClaims = Depends(get_current_user),   # ‡∏î‡∏∂‡∏á claims ‡∏à‡∏≤‡∏Å JWT
):
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡πà‡∏≠‡∏ô (‡∏Ç‡πâ‡∏≠ 5)
    # # if station_id not in set(current.station_ids):
    # if current.role != "admin" and station_id not in set(current.station_ids):
    #     raise HTTPException(status_code=403, detail="Forbidden station_id")

    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô stations
    doc = station_collection.find_one(
        {"station_id": station_id},
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å field ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏Ñ‡∏∑‡∏ô (‡∏ï‡∏±‡∏î _id ‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î serialize ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ObjectId)
        {"_id": 0, "station_id": 1, "station_name": 1, "SN": 1, "WO": 1,"brand":1, "PLCFirmware": 1, "PIFirmware": 1, "RTFirmware": 1, "chargeBoxID": 1, "model": 1, "status": 1}
    )
    if not doc:
        raise HTTPException(status_code=404, detail="Station not found")

    return {"station": doc}

@app.get("/station/info/public")
def station_info_public(
    station_id: str = Query(...)
):
    doc = station_collection.find_one(
        {"station_id": station_id},
        {"_id": 0, "station_id": 1, "station_name": 1, "SN": 1, "WO": 1,"chargeBoxID": 1,
         "model": 1, "status": 1,"brand":1}
    )
    if not doc:
        raise HTTPException(status_code=404, detail="Station not found")
    return {"station": doc}

@app.get("/get_history")
def get_history(
    station_id: str = Query(...),
    start: str = Query(...),
    end: str = Query(...),
    current: UserClaims = Depends(get_current_user),  # ‚Üê ‡∏≠‡πà‡∏≤‡∏ô‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏à‡∏≤‡∏Å JWT
):
    # ‚úÖ ‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏¥‡∏ß‡∏£‡∏µ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
    if station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

class RefreshIn(BaseModel):
    refresh_token: str

@app.post("/refresh")
def refresh(body: RefreshIn, response: Response):
    try:
        payload = jwt.decode(body.refresh_token, SECRET_KEY, algorithms=[ALGORITHM])
        email = payload.get("sub")
        if not email:
            raise HTTPException(status_code=401, detail="Invalid token")

        user = users_collection.find_one({"email": email})
        if not user:
            raise HTTPException(status_code=401, detail="User not found")

        entry = next((t for t in user.get("refreshTokens", []) if t.get("token") == body.refresh_token), None)
        if not entry:
            raise HTTPException(status_code=401, detail="Invalid refresh token")

        now = datetime.now(timezone.utc)
        if entry.get("expiresAt") and now > entry["expiresAt"]:
            raise HTTPException(status_code=401, detail="refresh_token_expired")

        # optional: idle timeout
        idle_at = entry.get("lastActiveAt")
        if idle_at and (now - idle_at) > timedelta(minutes=SESSION_IDLE_MINUTES):
            raise HTTPException(status_code=401, detail="session_idle_timeout")

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á access ‡πÉ‡∏´‡∏°‡πà (‡∏Ñ‡∏á sid ‡πÄ‡∏î‡∏¥‡∏°)
        station_ids = user.get("station_id", [])
        if not isinstance(station_ids, list):
            station_ids = [station_ids]

        new_access = create_access_token({
            "sub": user["email"],
            "user_id": str(user["_id"]),
            "username": user.get("username"),
            "role": user.get("role", "user"),
            "company": user.get("company"),
            "station_ids": station_ids,
            "sid": entry.get("sid"),
        }, expires_delta=timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES))

        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï lastActiveAt
        users_collection.update_one(
            {"_id": user["_id"], "refreshTokens.token": body.refresh_token},
            {"$set": {"refreshTokens.$.lastActiveAt": now}}
        )

        # ‚ö†Ô∏è ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏∏‡∏Å‡∏Å‡∏µ‡πâ access ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ SSE ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ
        response.set_cookie(
            key=ACCESS_COOKIE_NAME,
            value=new_access,
            httponly=True,
            secure=False,          # ‡πÇ‡∏õ‡∏£‡∏î‡∏î‡∏π‡∏Ç‡πâ‡∏≠ 2 ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á
            samesite="lax",        # ‡πÇ‡∏õ‡∏£‡∏î‡∏î‡∏π‡∏Ç‡πâ‡∏≠ 2 ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á
            max_age=int(timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES).total_seconds()),
            path="/",
        )
        return {"access_token": new_access}
    except ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="refresh_token_expired")
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid token")
    
@app.post("/logout")
async def logout(email: str, refresh_token: str):
    result = users_collection.update_one(
        {"email": email, "refreshTokens.token": refresh_token},
        {"$pull": {"refreshTokens": {"token": refresh_token}}}
    )
    if result.modified_count == 0:
        raise HTTPException(status_code=400, detail="Token not found or already logged out")
    return {"msg": "Logged out successfully"}





@app.get("/username")
async def users():
    # ‚úÖ ‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ role = "owner"
    cursor = users_collection.find({"role": "owner"})
    usernames = [u["username"] for u in cursor]

    if not usernames:
        raise HTTPException(status_code=404, detail="owners not found")

    return {"username": usernames}
    
class register(BaseModel):
    username: str
    email: str
    password: str
    tel: str
    company: str
#create
@app.post("/insert_users/")
async def create_users(users: register):
    # hash password
    hashed_pw = bcrypt.hashpw(users.password.encode("utf-8"), bcrypt.gensalt()).decode("utf-8")
    
    now = datetime.now(timezone.utc)

    users_collection.insert_one(
    {
        "username" : users.username,
        "email":users.email,
        "password":hashed_pw,
        "tel":users.tel,
        "refreshTokens": [],
        "role":"Technician",
        "company":users.company,
        "createdAt": now,   # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°
        "updatedAt": now,   # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°
    })

@app.get("/stations/")
async def get_stations(q:str = ""):
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ô‡∏µ"""
    query = {"station_name":{"$regex":  q, "$options": "i"}} if q else {}
    stations = station_collection.find(query,{"_id":0,"station_name":1})
    return [station["station_name"] for station in stations]

def to_json(doc: dict | None) -> str:
    if not doc:
        return "{}"
    d = dict(doc)
    d.pop("password", None)
    if isinstance(d.get("_id"), ObjectId):
        d["_id"] = str(d["_id"])
    return json.dumps(d, ensure_ascii=False, default=str)

# oauth2_scheme = OAuth2PasswordBearer(tokenUrl="login")  # ‡∏ä‡∏µ‡πâ‡πÑ‡∏õ endpoint login
# decode JWT 
    
@app.get("/owner/stations/")
async def get_stations(q: str = "", current: UserClaims = Depends(get_current_user)):
    # current_user ‡∏Ñ‡∏∑‡∏≠ str(_id)
    user_obj_id = ObjectId(current.user_id)

    # ‡∏î‡∏∂‡∏á station_id ‡∏Ç‡∏≠‡∏á user
    user = users_collection.find_one({"_id": user_obj_id}, {"station_id": 1})
    if not user or "station_id" not in user:
        return []

    station_ids = user["station_id"]

    # filter stations ‡∏ï‡∏≤‡∏° station_id ‡∏Ç‡∏≠‡∏á user + query
    query_filter = {"station_id": {"$in": station_ids}}
    if q:
        query_filter["station_name"] = {"$regex": q, "$options": "i"}

    stations = station_collection.find(query_filter, {"_id": 0, "station_name": 1, "station_id": 1})
    return [{"station_name": s["station_name"], "station_id": s["station_id"]} for s in stations]


# @app.get("/selected/station/{station_id}")
# async def get_station_detail(station_id: str, current: UserClaims = Depends(get_current_user)):
#     station = station_collection.find_one({"station_id": station_id})
#     if not station:
#         raise HTTPException(status_code=404, detail="Station not found")

#     # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á _id ‡πÄ‡∏õ‡πá‡∏ô string
#     station["_id"] = str(station["_id"])

#     return station

@app.get("/selected/station/{station_id}")
async def get_station_detail(station_id: str, current: UserClaims = Depends(get_current_user)):
    station = station_collection.find_one({"station_id": station_id})
    if not station:
        raise HTTPException(status_code=404, detail="Station not found")

    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏´‡πâ JSON ‡πÑ‡∏î‡πâ
    return jsonable_encoder(
        station,
        custom_encoder={
            ObjectId: str,
            datetime: lambda v: v.isoformat()
        }
    )

async def mdb_query(request: Request, station_id: str = Query(...), current: UserClaims = Depends(get_current_user)):
    """
    SSE ‡πÅ‡∏ö‡∏ö query param:
    - ‡∏™‡πà‡∏á snapshot ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (event: init)
    - ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô polling ‡∏Ç‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏ß‡∏á ‡πÜ
    """
    headers = {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "X-Accel-Buffering": "no",
    }
    coll = get_mdb_collection_for(station_id)

    async def event_generator():
        last_id = None
        latest = await coll.find_one({}, sort=[("_id", -1)])  # ‚¨ÖÔ∏è ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á filter station_id ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÅ‡∏•‡πâ‡∏ß
        if latest:
            latest["timestamp"] = _ensure_utc_iso(latest.get("timestamp"))
            last_id = latest.get("_id")
            yield "retry: 3000\n"
            yield "event: init\n"
            yield f"data: {to_json(latest)}\n\n"
        else:
            yield "retry: 3000\n\n"

        while True:
            if await request.is_disconnected():
                break

            doc = await coll.find_one({}, sort=[("_id", -1)])
            if doc and doc.get("_id") != last_id:
                doc["timestamp"] = _ensure_utc_iso(doc.get("timestamp"))
                last_id = doc.get("_id")
                yield f"data: {to_json(doc)}\n\n"
            else:
                yield ": keep-alive\n\n"

            await asyncio.sleep(5)

    return StreamingResponse(event_generator(), headers=headers)

def _coerce_date_range(start: str, end: str) -> tuple[str, str]:
    def _norm(s: str, is_end: bool=False) -> str:
        if "T" not in s:  # ‡∏ß‡∏±‡∏ô‡∏•‡πâ‡∏ß‡∏ô
            hhmmss = "23:59:59.999" if is_end else "00:00:00.000"
            dt = datetime.fromisoformat(f"{s}T{hhmmss}+07:00")
            # print("521",dt)
            # print("522",dt.astimezone(timezone.utc).isoformat())
            iso_th = dt.astimezone(th_tz).isoformat()
            # print("iso_th", iso_th)

            test = dt.astimezone(timezone.utc).isoformat()
            # print("526",dt)
            # print("527",type(dt.astimezone(timezone.utc).isoformat().replace("+00:00", "T")))
            # print("528",type(dt))
            # return dt.astimezone(timezone.utc).isoformat().replace("+07:00", "T")
            return iso_th
            
            # return dt
        # ‡∏°‡∏µ T ‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ timezone ‚Üí ‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢
        has_tz = bool(re.search(r'(Z|[+\-]\d{2}:\d{2})$', s))
        if not has_tz:
            dt = datetime.fromisoformat(s + "+07:00")
            # print("528",dt)
        else:
            dt = datetime.fromisoformat(s.replace("Z", "+00:00"))
            # print("531",datetime.fromisoformat(s))
            # print("532",dt)
        # print("533",dt.astimezone(timezone.utc).isoformat())    
        return dt.astimezone(timezone.utc).isoformat().replace("+00:00", "Z")
    try:
        return _norm(start, False), _norm(end, True)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad date range")
    
@app.get("/MDB/history")
async def stream_history(
    request: Request,
    station_id: str = Query(...),
    start: str = Query(...),   # "YYYY-MM-DD" (‡∏ß‡∏±‡∏ô‡πÑ‡∏ó‡∏¢)
    end: str = Query(...),     # "YYYY-MM-DD" (‡∏ß‡∏±‡∏ô‡πÑ‡∏ó‡∏¢)
    current: UserClaims = Depends(get_current_user),
):
    if not re.fullmatch(r"\d{4}-\d{2}-\d{2}", start) or not re.fullmatch(r"\d{4}-\d{2}-\d{2}", end):
        raise HTTPException(status_code=400, detail="start/end must be YYYY-MM-DD")
    if start > end:
        start, end = end, start

    tz_th = ZoneInfo("Asia/Bangkok")
    now_th = datetime.now(tz_th)
    def ensure_dt_with_current_time_th(datestr: str) -> datetime:
        """
        - 'YYYY-MM-DD'                  -> ‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢ (+07:00)
        - 'YYYY-MM-DDTHH[:MM[:SS]]'    -> ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏ã‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ ‡πÉ‡∏´‡πâ‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢ (+07:00)
        - ‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ 'Z' ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ '+/-HH:MM' -> ‡πÉ‡∏ä‡πâ‡πÇ‡∏ã‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å‡∏±‡∏ö‡∏™‡∏ï‡∏£‡∏¥‡∏á
        ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô UTC datetime
        """
        # ‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô ‡∏´‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πâ‡∏ß‡∏ô
        if re.fullmatch(r"\d{4}-\d{2}-\d{2}$", datestr):
            datestr = f"{datestr}T{now_th.strftime('%H:%M:%S')}"

        # ‡∏°‡∏µ‡πÇ‡∏ã‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏•‡πâ‡∏ß (Z ‡∏´‡∏£‡∏∑‡∏≠ +/-HH:MM)
        if re.search(r"(Z|[+\-]\d{2}:\d{2})$", datestr):
            # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 'Z' ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô +00:00
            dt = datetime.fromisoformat(datestr.replace("Z", "+00:00"))
            return dt.astimezone(timezone.utc)

        # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏ã‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ -> ‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô "‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢" (+07:00) ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô UTC
        naive = datetime.fromisoformat(datestr)        # ‡πÑ‡∏°‡πà‡∏ú‡∏π‡∏Å‡πÇ‡∏ã‡∏ô‡∏Å‡πà‡∏≠‡∏ô
        dt_th = naive.replace(tzinfo=tz_th)            # ‚Üê ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£ ‚Äú‡∏ú‡∏π‡∏Å +07:00‚Äù
        return dt_th.astimezone(timezone.utc)          # ‚Üê ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô UTC (‡∏ú‡∏• = ‡∏•‡∏ö 7 ‡∏ä‡∏°.)

    # start_utc = datetime.fromisoformat(start + "T07:00:00").replace(tzinfo=tz_th).astimezone(timezone.utc)
    # start_utc = start 
    # start_utc = ensure_dt_with_current_time_th(start).astimezone(tz_th)
    start_utc = ensure_dt_with_current_time_th(start)
    print("565",start_utc)
    # end_utc   = datetime.fromisoformat(end   + "T23:59:59.999").replace(tzinfo=tz_th).astimezone(timezone.utc)
    # end_utc   = end
    # end_utc   = ensure_dt_with_current_time_th(end).astimezone(tz_th)
    end_utc   = ensure_dt_with_current_time_th(end)
    print("567",end_utc)


    coll = get_mdb_collection_for(station_id)

    # ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ $regexReplace/$replaceOne ‚Äî ‡πÅ‡∏¢‡∏Å case ‡∏î‡πâ‡∏ß‡∏¢ $regexMatch + $toDate/$dateFromString
    def _parse_string(varname: str):
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÇ‡∏ã‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ (Z ‡∏´‡∏£‡∏∑‡∏≠ ¬±HH:MM) ‚Üí ‡πÉ‡∏´‡πâ Mongo ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢ $toDate
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏ã‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ ‚Üí ‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡πâ‡∏ß‡∏¢ $dateFromString timezone "+07:00"
        return {
            "$cond": [
                { "$regexMatch": { "input": f"$${varname}", "regex": r"(Z|[+\-]\d{2}:\d{2})$" } },
                { "$toDate": f"$${varname}" },
                { "$dateFromString": {
                    "dateString": f"$${varname}",
                    "timezone": "+07:00",
                    "onError": None,
                    "onNull": None
                } }
            ]
        }

    pipeline = [
        {   # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á ts ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Date ‡πÄ‡∏™‡∏°‡∏≠ ‡∏à‡∏≤‡∏Å timestamp ‡∏´‡∏£‡∏∑‡∏≠ Datetime (‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á string/date)
            "$addFields": {
                "ts": {
                    "$let": { "vars": { "t": "$timestamp", "d": "$Datetime" }, "in":
                        { "$cond": [
                            { "$ne": ["$$t", None] },
                            { "$switch": {
                                "branches": [
                                    { "case": { "$eq": [ { "$type": "$$t" }, "date"   ] }, "then": "$$t" },
                                    { "case": { "$eq": [ { "$type": "$$t" }, "string" ] }, "then": _parse_string("t") },
                                ],
                                "default": None
                            }},
                            { "$switch": {
                                "branches": [
                                    { "case": { "$eq": [ { "$type": "$$d" }, "date"   ] }, "then": "$$d" },
                                    { "case": { "$eq": [ { "$type": "$$d" }, "string" ] }, "then": _parse_string("d") },
                                ],
                                "default": None
                            }}
                        ] }
                    }
                }
            }
        },
        { "$addFields": { "dayTH": {
            "$dateToString": { "date": "$ts", "format": "%Y-%m-%d", "timezone": "+07:00" }
        }}},
        {   # ‡∏ä‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ß‡∏±‡∏ô‡πÑ‡∏ó‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á
            "$match": { "dayTH": { "$gte": start, "$lte": end } }
        },
        {   # ‚úÖ ‡∏ä‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 2: ts (UTC) ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Å‡∏£‡∏≠‡∏ö‡∏ß‡∏±‡∏ô‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô UTC ‡πÅ‡∏•‡πâ‡∏ß‡∏î‡πâ‡∏ß‡∏¢
            "$match": {
                "$expr": {
                    "$and": [
                        { "$gte": ["$ts", start_utc] },   # <-- ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ start_utc/end_utc ‡∏à‡∏≤‡∏Å Python ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô
                        { "$lte": ["$ts", end_utc] }
                    ]
                }
            }
        },
        { "$sort": { "ts": 1 } },
        { "$project": {
            "_id": 1,
            "timestamp": "$ts",
            "VL1N": 1, "VL2N": 1, "VL3N": 1,
            "I1": 1, "I2": 1, "I3": 1,
            "PL1N": 1, "PL2N": 1, "PL3N": 1,
            # (debug) ‡∏à‡∏∞‡πÇ‡∏ä‡∏ß‡πå dayTH ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏Å‡πá‡πÑ‡∏î‡πâ:
            # "dayTH": 1,
        }}
    ]

    cursor = coll.aggregate(pipeline, allowDiskUse=True)

    headers = {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "X-Accel-Buffering": "no",
    }

    async def event_generator():
        try:
            base = pipeline[:-2]
            cnt = await coll.aggregate(base + [{"$count": "n"}]).to_list(length=1)
            n = cnt[0]["n"] if cnt else 0
            yield "retry: 3000\n"
            yield f"event: stats\ndata: {json.dumps({'matched': n})}\n\n"

            sent = 0
            async for doc in cursor:
                if await request.is_disconnected():
                    break
                doc["_id"] = str(doc["_id"])
                doc["timestamp"] = _ensure_utc_iso(doc.get("timestamp"))
                yield f"data: {json.dumps(doc, ensure_ascii=False)}\n\n"
                sent += 1
                await asyncio.sleep(0.001)

            if sent == 0:
                yield "event: empty\ndata: no documents in range\n\n"
            else:
                yield ": keep-alive\n\n"
        except Exception as e:
            yield f"event: error\ndata: {str(e)}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream", headers=headers)

@app.get("/MDB/history/debug")
async def mdb_history_debug(station_id: str, start: str, end: str):
    start_iso, end_iso = _coerce_date_range(start, end)
    start_key, end_key = start_iso.rstrip("Z"), end_iso.rstrip("Z")
    coll = get_mdb_collection_for(station_id)
    q = {"timestamp": {"$gte": start_key, "$lte": end_key}}
    docs = await coll.find(q, {"_id":0,"timestamp":1}).sort("timestamp", 1).limit(5).to_list(length=5)
    n = await coll.count_documents(q)
    return {"matched": n, "start_key": start_key, "end_key": end_key, "sample": docs}

def extract_token(authorization: str | None, access_token: str | None):
    if authorization and authorization.startswith("Bearer "):
        return authorization.split(" ", 1)[1]
    if access_token:
        return access_token
    raise HTTPException(status_code=401, detail="Not authenticated")
    
@app.get("/MDB/{station_id}")
async def mdb(request: Request, station_id: str, current: UserClaims = Depends(get_current_user)):
    headers = {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "X-Accel-Buffering": "no",
    }

    coll = get_mdb_collection_for(station_id)  # ‚¨ÖÔ∏è ‡πÉ‡∏ä‡πâ coll ‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ

    async def event_generator():
        last_id = None

        latest = await coll.find_one({}, sort=[("_id", -1)])
        if latest:
            latest["timestamp"] = _ensure_utc_iso(latest.get("timestamp"))
            last_id = latest.get("_id")
            yield f"event: init\ndata: {to_json(latest)}\n\n"
        else:
            yield ": keep-alive\n\n"

        while True:
            if await request.is_disconnected():
                break

            doc = await coll.find_one({}, sort=[("_id", -1)])
            if doc and doc.get("_id") != last_id:
                doc["timestamp"] = _ensure_utc_iso(doc.get("timestamp"))
                last_id = doc.get("_id")
                yield f"data: {to_json(doc)}\n\n"
            else:
                yield ": keep-alive\n\n"

            await asyncio.sleep(60)

    return StreamingResponse(event_generator(), headers=headers)


async def _resolve_user_id_by_chargebox(chargebox_id: Optional[str]) -> Optional[str]:
    if not chargebox_id:
        return None
    doc = await stations_coll_async.find_one(
        {"chargeBoxID": chargebox_id},
        projection={"user_id": 1}
    )
    if not doc:
        return None
    return str(doc.get("user_id")) if doc.get("user_id") is not None else None

async def _resolve_user_email_by_user_id(user_id: Optional[str]) -> Optional[str]:
    if not user_id:
        return None

    queries = []
    if ObjectId.is_valid(user_id):
        queries.append({"_id": ObjectId(user_id)})
    queries.append({"_id": user_id})  # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô string

    for q in queries:
        doc = await users_coll_async.find_one(q, projection={"email": 1})
        if doc:
            return doc.get("email")
    return None

async def _send_email_async(to_email: str, subject: str, body: str) -> None:
    msg = EmailMessage()
    msg["From"] = SENDER_EMAIL
    msg["To"] = to_email
    msg["Subject"] = subject
    msg.set_content(body)

    # STARTTLS (port 587). ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ SMTPS (465) ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô use_tls=True ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á starttls
    await aiosmtplib.send(
        msg,
        hostname=SMTP_HOST,
        port=SMTP_PORT,
        start_tls=True,
        username=SMTP_USER,
        password=SMTP_PASS,
        timeout=30,
    )

async def send_error_email_once(to_email: str | None, chargebox_id: str | None, error_text: str | None, doc_id) -> bool:
    """
    ‡∏™‡πà‡∏á‡πÄ‡∏°‡∏•‡πÅ‡∏à‡πâ‡∏á error ‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡πà‡∏≠‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ error (_id)
    - ‡πÉ‡∏ä‡πâ collection iMPS.errorEmailLog ‡πÄ‡∏Å‡πá‡∏ö _id ‡πÄ‡∏õ‡πá‡∏ô unique key
    - ‡∏ñ‡πâ‡∏≤‡∏™‡πà‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏õ‡πá‡∏ô sent
    - ‡∏ñ‡πâ‡∏≤‡∏™‡πà‡∏á‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡∏•‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏ô‡πâ‡∏≤
    """
    if not to_email or not error_text:
        return False

    key = str(doc_id)  # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö ObjectId/str
    now_th = datetime.now(th_tz)

    # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏Å‡∏±‡∏ô‡∏ã‡πâ‡∏≥‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£ insert ‡∏•‡πá‡∏≠‡∏Å (pending) ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß -> ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á
    try:
        await email_log_coll.insert_one({
            "_id": key,                    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ unique key ‡πÄ‡∏õ‡πá‡∏ô doc_id ‡∏Ç‡∏≠‡∏á error
            "status": "pending",
            "to": to_email,
            "chargeBoxID": chargebox_id,
            "createdAt": now_th,
        })
    except DuplicateKeyError:
        return False  # ‡πÄ‡∏Ñ‡∏¢‡∏™‡πà‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß

    # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á subject/body ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡πà‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•
    subject = f"[IMPS Error] {chargebox_id or '-'}"
    body = (
        f"‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ,\n\n"
        f"‡∏°‡∏µ Error ‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ/‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå: {chargebox_id or '-'}\n"
        f"‡πÄ‡∏ß‡∏•‡∏≤ (TH): {now_th:%Y-%m-%d %H:%M:%S}\n\n"
        f"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:\n{error_text}\n\n"
        f"-- ‡∏£‡∏∞‡∏ö‡∏ö iMPS"
    )
    try:
        await _send_email_async(to_email, subject, body)
        await email_log_coll.update_one({"_id": key}, {"$set": {"status": "sent", "sentAt": datetime.now(th_tz)}})
        return True
    except Exception:
        # ‡∏ñ‡πâ‡∏≤‡∏™‡πà‡∏á‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡∏•‡∏ö‡∏•‡πá‡∏≠‡∏Å pending ‡∏≠‡∏≠‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏™‡πà‡∏á‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏£‡∏≠‡∏ö‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
        await email_log_coll.delete_one({"_id": key})
        raise



@app.get("/error/{station_id}")
async def error_stream(request: Request, station_id: str, current: UserClaims = Depends(get_current_user)):
    headers = {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "X-Accel-Buffering": "no",
    }

    coll = get_errorCode_collection_for(station_id)

    async def event_generator():
        last_id = None

        # ----- init -----
        latest = await coll.find_one({}, sort=[("_id", -1)])
        if latest and ("error" in latest):
            last_id = latest.get("_id")

            chargebox_id = latest.get("Chargebox_ID")
            user_id = await _resolve_user_id_by_chargebox(chargebox_id)
            email = await _resolve_user_email_by_user_id(user_id)

            # >>> ‡∏™‡πà‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡πà‡∏≠‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
            # try:
            #     await send_error_email_once(email, chargebox_id, latest.get("error"), last_id)
            # except Exception as e:
            #     # ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ï‡∏Å‡∏™‡∏ï‡∏£‡∏µ‡∏°: log ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡∏ï‡πà‡∏≠
            #     print(f"[email] init send failed for {last_id}: {e}")

            payload = {
                "Chargebox_ID": chargebox_id,
                "user_id": user_id,
                "email": email,
                "error": latest.get("error"),
            }
            # yield f"event: init\ndata: {to_json(payload)}\n\n"
        else:
            yield ": keep-alive\n\n"

        # ----- updates -----
        while True:
            if await request.is_disconnected():
                break

            doc = await coll.find_one({}, sort=[("_id", -1)])
            if doc and doc.get("_id") != last_id and ("error" in doc):
                last_id = doc.get("_id")

                chargebox_id = doc.get("Chargebox_ID")
                user_id = await _resolve_user_id_by_chargebox(chargebox_id)
                email = await _resolve_user_email_by_user_id(user_id)

                # >>> ‡∏™‡πà‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡πà‡∏≠‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
                # try:
                #     await send_error_email_once(email, chargebox_id, doc.get("error"), last_id)
                # except Exception as e:
                #     print(f"[email] update send failed for {last_id}: {e}")

                payload = {
                    "Chargebox_ID": chargebox_id,
                    "user_id": user_id,
                    "email": email,
                    "error": doc.get("error"),
                }
                # yield f"data: {to_json(payload)}\n\n"
            else:
                yield ": keep-alive\n\n"

            await asyncio.sleep(60)

    return StreamingResponse(event_generator(), headers=headers)

def parse_iso_dt(s: str) -> datetime:
    try:
        return datetime.fromisoformat(s.replace("Z", "+00:00"))
    except Exception:
        raise HTTPException(status_code=400, detail=f"Bad datetime: {s}")


def _to_utc_dt(iso_str: str) -> datetime:
    # ‡∏£‡∏±‡∏ö ISO ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢ Z ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏Å‡πá‡πÑ‡∏î‡πâ ‡πÅ‡∏•‡πâ‡∏ß‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô aware UTC
    s = iso_str
    if s.endswith("Z"):
        s = s.replace("Z", "+00:00")
    dt = datetime.fromisoformat(s)  # ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á aware/naive
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    else:
        dt = dt.astimezone(timezone.utc)
    return dt

def to_float(x, default=0.0):
    try:
        if x is None:
            return default
        if isinstance(x, (int, float)):
            return float(x)
        if isinstance(x, Decimal128):
            return float(x.to_decimal())
        s = str(x).strip().replace(",", ".")
        return float(s)
    except Exception:
        return default

async def change_stream_generator(station_id: str):
    coll = get_mdb_collection_for(station_id)
    async with coll.watch() as cs:
        async for change in cs:
            doc = change.get("fullDocument")
            if not doc:
                continue
            payload = {
                "t": _ensure_utc_iso(doc.get("timestamp")),
                "L1": doc.get("VL1N"),
                "L2": doc.get("VL2N"),
                "L3": doc.get("VL3N"),
                "I1": doc.get("I1"),
                "I2": doc.get("I2"),
                "I3": doc.get("I3"),
                "W1": doc.get("PL1N"),
                "W2": doc.get("PL2N"),
                "W3": doc.get("PL3N"),
            }
            yield f"data: {json.dumps(payload)}\n\n"



def floor_bin(dt: datetime, step_sec: int) -> datetime:
    epoch_ms = int(dt.timestamp() * 1000)
    bin_ms = epoch_ms - (epoch_ms % (step_sec * 1000))
    return datetime.fromtimestamp(bin_ms / 1000, tz=timezone.utc)

# def to_json(doc):
#     doc = dict(doc)
#     doc["_id"] = str(doc["_id"])
#     return json.dumps(doc, default=str)

################ Users
# @app.get("/all-users/")
# def all_users():
#     # ‡πÄ‡∏≠‡∏≤‡∏ó‡∏∏‡∏Å‡∏ü‡∏¥‡∏•‡∏î‡πå ‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô password ‡πÅ‡∏•‡∏∞ refreshTokens
#     cursor = users_collection.find({}, {"password": 0, "refreshTokens": 0})
#     docs = list(cursor)

#     # ‡∏ñ‡πâ‡∏≤‡∏à‡∏∞‡∏™‡πà‡∏á _id ‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á ObjectId -> str
#     for d in docs:
#         if "_id" in d:
#             d["_id"] = str(d["_id"])

#     return {"users": docs}

@app.get("/all-users/")
def all_users(current: UserClaims = Depends(get_current_user)):
    # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÄ‡∏â‡∏û‡∏≤‡∏∞ admin (‡∏à‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏° owner ‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢)
    if current.role != "admin":
        raise HTTPException(status_code=403, detail="forbidden")

    cursor = users_collection.find({}, {"password": 0, "refreshTokens": 0})
    docs = list(cursor)
    for d in docs:
        if "_id" in d:
            d["_id"] = str(d["_id"])
    return {"users": docs}

class addUsers(BaseModel):
    username:str
    email:str
    password:str
    tel:str
    company_name:str
    station_id:Optional[Union[str, int, List[Union[str, int]]]] = None
    role:str 

class UserOut(BaseModel):
    id: str
    username: str
    email: EmailStr
    role: str
    company: str
    station_id: List[str] = Field(default_factory=list)
    tel: str
    # payment: Optional[bool] = None

# @app.post("/add_users/", response_model=UserOut, status_code=201)
# def insert_users(body: addUsers):
#     email = body.email.lower()
#     hashed = bcrypt.hashpw(body.password.encode("utf-8"), bcrypt.gensalt()).decode("utf-8")

#     # station_id -> list[str]
#     station_ids: List[str] = []
#     if body.station_id is not None and body.station_id != "":
#         if isinstance(body.station_id, list):
#             station_ids = [str(x) for x in body.station_id if str(x).strip() != ""]
#         else:
#             station_ids = [str(body.station_id)]

#     doc = {
#         "username": body.username.strip(),
#         "email": email,
#         "password": hashed,
#         "role": body.role,
#         # "company": (body.company_name or body.company or "").strip() or None,
#         "company": (body.company_name or "").strip() or None,
#         "tel": (body.tel or "").strip() or None,
#         # "payment": (body.payment.lower() == "y"),
#         "station_id": station_ids,
#         "refreshTokens": [],
#         "createdAt": datetime.now(timezone.utc),
        
#     }

#     try:
#         res = users_collection.insert_one(doc)
#     except DuplicateKeyError:
#         raise HTTPException(status_code=409, detail="Email already exists")

#     return {
#         "id": str(res.inserted_id),
#         "username": doc["username"],
#         "email": doc["email"],
#         "role": doc["role"],
#         "company": doc.get("company"),
#         "station_id": doc["station_id"],
#         "tel": doc.get("tel"),
#         # "payment": doc.get("payment"),
#         "createdAt": doc["createdAt"],
#     }

@app.post("/add_users/", response_model=UserOut, status_code=201)
def insert_users(body: addUsers, current: UserClaims = Depends(get_current_user)):
    if current.role != "admin":
        raise HTTPException(status_code=403, detail="forbidden")

    email = body.email.lower()
    hashed = bcrypt.hashpw(body.password.encode("utf-8"), bcrypt.gensalt()).decode("utf-8")

    station_ids: List[str] = []
    if body.station_id is not None and body.station_id != "":
        if isinstance(body.station_id, list):
            station_ids = [str(x) for x in body.station_id if str(x).strip() != ""]
        else:
            station_ids = [str(body.station_id)]

    doc = {
        "username": body.username.strip(),
        "email": email,
        "password": hashed,
        "role": body.role,
        "company": (body.company_name or "").strip() or None,
        "tel": (body.tel or "").strip() or None,
        "station_id": station_ids,
        "refreshTokens": [],
        "createdAt": datetime.now(timezone.utc),
    }

    try:
        res = users_collection.insert_one(doc)
    except DuplicateKeyError:
        raise HTTPException(status_code=409, detail="Email already exists")

    return {
        "id": str(res.inserted_id),
        "username": doc["username"],
        "email": doc["email"],
        "role": doc["role"],
        "company": doc.get("company"),
        "station_id": doc["station_id"],
        "tel": doc.get("tel"),
        "createdAt": doc["createdAt"],
    }

@app.delete("/delete_users/{user_id}", status_code=204)
def delete_user(user_id: str, current: UserClaims = Depends(get_current_user)):
    # (‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å) ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞ admin/owner
    if current.role not in ("admin", "owner"):
        raise HTTPException(status_code=403, detail="Forbidden")

    try:
        oid = ObjectId(user_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid user id")

    res = users_collection.delete_one({"_id": oid})
    if res.deleted_count == 0:
        raise HTTPException(status_code=404, detail="User not found")

    # 204 No Content
    return Response(status_code=204)

class UserUpdate(BaseModel):
    username: str | None = None
    email: EmailStr | None = None
    tel : str | None = None      # ‡πÉ‡∏ä‡πâ "phone" ‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ
    company: str | None = None
    role: str | None = None       # admin ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏î‡πâ
    is_active: bool | None = None # admin ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏î‡πâ
    password: str | None = None   # ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÅ‡∏Æ‡∏ä‡πÄ‡∏™‡∏°‡∏≠‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡πà‡∏≤

def hash_password(raw: str) -> str:
    return bcrypt.hashpw(raw.encode("utf-8"), bcrypt.gensalt()).decode("utf-8")

# ‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï
ALLOW_FIELDS_ADMIN_USER = {"username", "email", "tel", "company", "role", "is_active", "password"}
ALLOW_FIELDS_SELF_USER  = {"username", "email", "tel", "company", "password"}


# ===== Endpoint =====
# @app.patch("/user_update/{id}", response_model=UserOut)
# def update_user(id: str, body: UserUpdate, current: UserClaims = Depends(get_current_user)):
#     oid = to_object_id_or_400(id)

#     doc = users_collection.find_one({"_id": oid})
#     if not doc:
#         raise HTTPException(status_code=404, detail="user not found")

#     if current.role != "admin" and current.user_id != str(oid):
#         raise HTTPException(status_code=403, detail="forbidden")

#     incoming = {
#         k: (v.strip() if isinstance(v, str) else v)
#         for k, v in body.model_dump(exclude_none=True).items()
#     }
#     if not incoming:
#         raise HTTPException(status_code=400, detail="no fields to update")

#     allowed = ALLOW_FIELDS_ADMIN_USER if current.role == "admin" else ALLOW_FIELDS_SELF_USER
#     payload = {k: v for k, v in incoming.items() if k in allowed}
#     if not payload:
#         raise HTTPException(status_code=400, detail="no permitted fields to update")

#     if "password" in payload:
#         payload["password"] = hash_password(payload["password"])

#     if "is_active" in payload and not isinstance(payload["is_active"], bool):
#         raise HTTPException(status_code=400, detail="is_active must be boolean")

#     now = datetime.now(timezone.utc)
#     payload["updatedAt"] = now

#     try:
#         users_collection.update_one({"_id": oid}, {"$set": payload})
#     except DuplicateKeyError:
#         raise HTTPException(status_code=409, detail="duplicate email or username")

#     newdoc = users_collection.find_one({"_id": oid}) or {}
#     created_at = newdoc.get("createdAt") or now
#     if "createdAt" not in newdoc:
#         users_collection.update_one({"_id": oid}, {"$set": {"createdAt": created_at}})

#     # ‚úÖ ‡πÉ‡∏ä‡πâ tel ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà phone
#     return {
#         "id": str(newdoc["_id"]),
#         "username": newdoc.get("username", ""),
#         "email": newdoc.get("email", ""),
#         "role": newdoc.get("role", ""),
#         "company": (newdoc.get("company") or ""),
#         "station_id": list(newdoc.get("station_id") or []),
#         "tel": (newdoc.get("tel") or ""),
#         "createdAt": created_at,
#         "updatedAt": newdoc.get("updatedAt", now),
#     }

@app.patch("/user_update/{id}", response_model=UserOut)
def update_user(id: str, body: UserUpdate, current: UserClaims = Depends(get_current_user)):
    oid = to_object_id_or_400(id)

    doc = users_collection.find_one({"_id": oid})
    if not doc:
        raise HTTPException(status_code=404, detail="user not found")

    # ‚îÄ‚îÄ Permission: admin ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î, owner ‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á, ‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡∏´‡πâ‡∏≤‡∏°
    if current.role == "admin":
        pass  # ‡∏ú‡πà‡∏≤‡∏ô
    elif current.role == "owner":
        if current.user_id != str(oid):
            raise HTTPException(status_code=403, detail="forbidden")
    else:
        # ‡∏Å‡∏±‡∏ô‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏≠‡∏∑‡πà‡∏ô ‡πÜ (‡πÄ‡∏ä‡πà‡∏ô user) ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï
        raise HTTPException(status_code=403, detail="forbidden")

    # ‚îÄ‚îÄ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° incoming fields
    incoming = {
        k: (v.strip() if isinstance(v, str) else v)
        for k, v in body.model_dump(exclude_none=True).items()
    }
    if not incoming:
        raise HTTPException(status_code=400, detail="no fields to update")

    # ‚îÄ‚îÄ ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ï‡∏≤‡∏°‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó
    # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏™‡∏≠‡∏á‡∏ä‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå settings:
    ALLOW_FIELDS_ADMIN_USER = {"username","email","password","role","company","tel","is_active"}
    ALLOW_FIELDS_SELF_OWNER = {"username","email","password","tel"}  # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ‡πÄ‡∏≠‡∏á‡πÑ‡∏î‡πâ
    if current.role == "admin":
        allowed = ALLOW_FIELDS_ADMIN_USER
    else:  # owner
        allowed = ALLOW_FIELDS_SELF_OWNER

    payload = {k: v for k, v in incoming.items() if k in allowed}
    if not payload:
        raise HTTPException(status_code=400, detail="no permitted fields to update")

    # ‚îÄ‚îÄ ‡πÅ‡∏Æ‡∏ä‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    if "password" in payload:
        payload["password"] = hash_password(payload["password"])

    # ‚îÄ‚îÄ validate is_active (admin ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡∏ñ‡∏∂‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß)
    if "is_active" in payload and not isinstance(payload["is_active"], bool):
        raise HTTPException(status_code=400, detail="is_active must be boolean")

    now = datetime.now(timezone.utc)
    payload["updatedAt"] = now

    try:
        users_collection.update_one({"_id": oid}, {"$set": payload})
    except DuplicateKeyError:
        raise HTTPException(status_code=409, detail="duplicate email or username")

    newdoc = users_collection.find_one({"_id": oid}) or {}
    created_at = newdoc.get("createdAt") or now
    if "createdAt" not in newdoc:
        users_collection.update_one({"_id": oid}, {"$set": {"createdAt": created_at}})

    return {
        "id": str(newdoc["_id"]),
        "username": newdoc.get("username", ""),
        "email": newdoc.get("email", ""),
        "role": newdoc.get("role", ""),
        "company": (newdoc.get("company") or ""),
        "station_id": list(newdoc.get("station_id") or []),
        "tel": (newdoc.get("tel") or ""),
        "createdAt": created_at,
        "updatedAt": newdoc.get("updatedAt", now),
    }


def parse_iso_utc(s: str) -> Optional[datetime]:
    try:
        # "2025-09-29T16:19:54.659Z"
        return datetime.fromisoformat(s.replace("Z", "+00:00"))
    except Exception:
        return None

def latest_onoff(station_id: str) -> Dict[str, Any]:
    """
    ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å stationsOnOff/<station_id>
    ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á doc:
      { payload: { value: 0/1, timestamp: "ISO-UTC" }, ... }
    """
    coll = stationOnOff.get_collection(station_id)
    doc = coll.find_one(
        sort=[("payload.timestamp", -1), ("_id", -1)]
    )
    if not doc:
        return {"status": None, "statusAt": None}

    payload = doc.get("payload", {})
    val = payload.get("value", None)
    ts = payload.get("timestamp", None)

    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô bool ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô: 1/true => True, 0/false => False, ‡∏≠‡∏∑‡πà‡∏ô‡πÜ -> None
    if isinstance(val, (int, bool)):
        status = bool(val)
    else:
        try:
            status = bool(int(val))
        except Exception:
            status = None

    status_at = parse_iso_utc(ts) if isinstance(ts, str) else None
    return {"status": status, "statusAt": status_at}

@app.get("/all-stations/")
def all_stations(current: UserClaims = Depends(get_current_user)):
    # 1) ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç match ‡∏ï‡∏≤‡∏° role
    if current.role == "admin":
        match_query = {}
    else:
        if not current.user_id:
            raise HTTPException(status_code=401, detail="Missing uid in token")
        # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏Å‡πá‡∏ö user_id ‡πÄ‡∏õ‡πá‡∏ô string ‡∏´‡∏£‡∏∑‡∏≠ ObjectId
        conds = [{"user_id": current.user_id}]
        try:
            conds.append({"user_id": ObjectId(current.user_id)})
        except Exception:
            pass
        match_query = {"$or": conds}

    pipeline = [
        {"$match": match_query},

        # 2) ‡πÅ‡∏õ‡∏•‡∏á user_id -> ObjectId ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô string (‡πÄ‡∏û‡∏∑‡πà‡∏≠ lookup)
        {"$addFields": {
            "user_obj_id": {
                "$cond": [
                    {"$eq": [{"$type": "$user_id"}, "string"]},
                    {"$toObjectId": "$user_id"},
                    "$user_id"  # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô ObjectId ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏î‡∏¥‡∏°
                ]
            }
        }},

        # 3) ‡∏î‡∏∂‡∏á username (‡πÅ‡∏•‡∏∞‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏≠‡∏∑‡πà‡∏ô‡πÜ‡∏à‡∏≤‡∏Å users) ‡∏î‡πâ‡∏ß‡∏¢ $lookup
        {"$lookup": {
            "from": "users",              # ‡∏ä‡∏∑‡πà‡∏≠ collection ‡∏Ç‡∏≠‡∏á user
            "localField": "user_obj_id",  # _id ‡πÉ‡∏ô users ‡πÄ‡∏õ‡πá‡∏ô ObjectId
            "foreignField": "_id",
            "as": "owner"
        }},
        {"$addFields": {
            "username": {"$arrayElemAt": ["$owner.username", 0]},
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏î‡πâ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô email/phone/company
            # "owner_email": {"$arrayElemAt": ["$owner.email", 0]},
        }},

        # 4) ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á array owner ‡∏Å‡∏±‡∏ö‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ
        {"$project": {"owner": 0, "user_obj_id": 0}},
    ]

    docs = list(station_collection.aggregate(pipeline))

    # ‚òÖ ‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå‡∏ï‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ
    for d in docs:
        sid = d.get("station_id")
        try:
            last = latest_onoff(str(sid))
        except Exception:
            last = {"status": None, "statusAt": None}
        d["status"] = last["status"]          # true/false/None
        d["statusAt"] = last["statusAt"]      # datetime | None

    docs = jsonable_encoder(docs, custom_encoder={ObjectId: str})
    for d in docs:
        if "_id" in d:
            d["_id"] = str(d["_id"])
    return {"stations": docs}

class addStations(BaseModel):
    station_id:str
    station_name:str
    brand:str
    model:str
    SN:str
    WO:str 
    PLCFirmware:str 
    PIFirmware:str 
    RTFirmware:str
    chargeBoxID: str 
    user_id: Optional[str] = None  
    owner: Optional[str] = None
    is_active:Optional[bool] = None

# class StationOut(BaseModel):
#     id: str
#     station_id:str
#     station_name:str
#     brand:str
#     model:str
#     SN:str
#     WO:str 
#     PLCFirmware:str 
#     PIFirmware:str 
#     RTFirmware:str 
#     chargeBoxID:str
#     user_id: str 
#     username: Optional[str] = None
#     is_active:  Optional[bool] = None
#     createdAt: Optional[datetime] = None

#     class Config:
#         json_encoders = {
#             datetime: lambda v: v.astimezone(ZoneInfo("Asia/Bangkok")).isoformat()
#         }

class StationOut(BaseModel):
    id: str
    station_id:str
    station_name:str
    brand:str
    model:str
    SN:str
    WO:str 
    PLCFirmware:str 
    PIFirmware:str 
    RTFirmware:str 
    chargeBoxID:str
    user_id: str 
    username: Optional[str] = None
    is_active:  Optional[bool] = None
    images: Optional[dict] = None   # ‚¨ÖÔ∏è ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ
    createdAt: Optional[datetime] = None
    class Config:
        json_encoders = {
            datetime: lambda v: v.astimezone(ZoneInfo("Asia/Bangkok")).isoformat()
        }


@app.post("/add_stations/", response_model=StationOut, status_code=201)
def insert_stations(
    body: addStations,
    current: UserClaims = Depends(get_current_user)
):
    # 1) ‡∏ï‡∏±‡∏î/‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î string fields
    station_id   = body.station_id.strip()
    station_name = body.station_name.strip()
    brand        = body.brand.strip()
    model        = body.model.strip()
    SN           = body.SN.strip()
    WO           = body.WO.strip()
    PLCFirmware           = body.PLCFirmware.strip()
    PIFirmware           = body.PIFirmware.strip()
    RTFirmware           = body.RTFirmware.strip()
    chargeBoxID           = body.chargeBoxID.strip()

    # (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö station_id)
    # if not re.fullmatch(r"[A-Za-z0-9_]+", station_id):
    #     raise HTTPException(status_code=422, detail="station_id must be [A-Za-z0-9_]")

    # 2) ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à owner ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏Ç‡∏≠‡∏á update:
    #    - admin: ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏™‡πà‡∏á user_id (24hex) ‡∏´‡∏£‡∏∑‡∏≠ owner(username) ‡∏°‡∏≤‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏à‡πâ‡∏≤‡∏Ç‡∏≠‡∏á
    #             ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡πÄ‡∏•‡∏¢ ‡∏à‡∏∞ fallback ‡πÄ‡∏õ‡πá‡∏ô current.user_id
    #    - non-admin: ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô current.user_id (‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏ß‡∏°‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå)
    if current.role == "admin":
        owner_oid = None
        if body.user_id:
            owner_oid = to_object_id_or_400(body.user_id)
        elif body.owner:
            u = users_collection.find_one({"username": body.owner.strip()}, {"_id": 1})
            if not u:
                raise HTTPException(status_code=400, detail="invalid owner username")
            owner_oid = u["_id"]
        else:
            if not current.user_id:
                raise HTTPException(status_code=401, detail="Missing uid in token")
            owner_oid = to_object_id_or_400(current.user_id)
    else:
        if not current.user_id:
            raise HTTPException(status_code=401, detail="Missing uid in token")
        owner_oid = to_object_id_or_400(current.user_id)

    # 3) is_active ‡πÄ‡∏õ‡πá‡∏ô boolean ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
    is_active = True if body.is_active is None else bool(body.is_active)

    # 4) ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô UTC ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö user_id ‡πÄ‡∏õ‡πá‡∏ô ObjectId ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÉ‡∏ô PATCH)
    # doc: Dict[str, Any] = {
    #     "station_id": station_id,
    #     "station_name": station_name,
    #     "brand": brand,
    #     "model": model,
    #     "SN": SN,
    #     "WO": WO,
    #     "PLCFirmware": PLCFirmware,
    #     "PIFirmware": PIFirmware,
    #     "RTFirmware": RTFirmware,
    #     "chargeBoxID": chargeBoxID,
    #     "user_id": owner_oid,                 # ObjectId ‡πÉ‡∏ô DB
    #     "is_active": is_active,
    #     "createdAt": datetime.now(timezone.utc),
    # }
    doc: Dict[str, Any] = {
        "station_id": station_id,
        "station_name": station_name,
        "brand": brand,
        "model": model,
        "SN": SN,
        "WO": WO,
        "PLCFirmware": PLCFirmware,
        "PIFirmware": PIFirmware,
        "RTFirmware": RTFirmware,
        "chargeBoxID": chargeBoxID,
        "user_id": owner_oid,
        "is_active": is_active,
        "images": {},      
        "createdAt": datetime.now(timezone.utc),
    }

    # 5) insert + ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ duplicate key ‡∏Ç‡∏≠‡∏á station_id
    try:
        res = station_collection.insert_one(doc)
    except DuplicateKeyError:
        raise HTTPException(status_code=409, detail="station_id already exists")

    # 6) ‡∏´‡∏≤ username ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡πÉ‡∏ô table)
    owner_doc = users_collection.find_one({"_id": owner_oid}, {"username": 1})
    owner_username = owner_doc.get("username") if owner_doc else None

    # 7) ‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö PATCH: user_id ‡πÄ‡∏õ‡πá‡∏ô string, ‡πÅ‡∏ñ‡∏° username
    # return {
    #     "id": str(res.inserted_id),
    #     "station_id": doc["station_id"],
    #     "station_name": doc["station_name"],
    #     "brand": doc["brand"],
    #     "model": doc["model"],
    #     "SN": doc["SN"],
    #     "WO": doc["WO"],
    #     "PLCFirmware": doc["PLCFirmware"],
    #     "PIFirmware": doc["PIFirmware"],
    #     "RTFirmware": doc["RTFirmware"],
    #     "chargeBoxID": doc["chargeBoxID"],
    #     "user_id": str(doc["user_id"]),       # string ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö client
    #     "username": owner_username,           # ‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÉ‡∏´‡πâ table ‡πÇ‡∏ä‡∏ß‡πå‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
    #     "is_active": doc["is_active"],
    #     "createdAt": doc["createdAt"],
    #     # "updatedAt": None,  # ‡∏à‡∏∞‡πÉ‡∏™‡πà‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ schema‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô PATCH ‡πÄ‡∏õ‡πä‡∏∞
    # }
    return {
        "id": str(res.inserted_id),
        "station_id": doc["station_id"],
        "station_name": doc["station_name"],
        "brand": doc["brand"],
        "model": doc["model"],
        "SN": doc["SN"],
        "WO": doc["WO"],
        "PLCFirmware": doc["PLCFirmware"],
        "PIFirmware": doc["PIFirmware"],
        "RTFirmware": doc["RTFirmware"],
        "chargeBoxID": doc["chargeBoxID"],
        "user_id": str(doc["user_id"]),
        "username": owner_username,
        "is_active": doc["is_active"],
        "images": doc.get("images", {}),        # ‚¨ÖÔ∏è ‡πÄ‡∏û‡∏¥‡πà‡∏°
        "createdAt": doc["createdAt"],
        
    }



@app.delete("/delete_stations/{id}", status_code=204)
def delete_station(id: str, current: UserClaims = Depends(get_current_user)):
    if current.role not in ("admin", "owner"):
        raise HTTPException(status_code=403, detail="Forbidden")
    try:
        oid = ObjectId(id)
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid id")
    res = station_collection.delete_one({"_id":  oid})
    if res.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Station not found")
    return Response(status_code=204)

class StationUpdate(BaseModel):
    station_name: Optional[str] = None
    brand: Optional[str] = None
    model: Optional[str] = None
    SN: Optional[str] = None
    WO: Optional[str] = None
    PLCFirmware: Optional[str] = None
    PIFirmware: Optional[str] = None
    RTFirmware: Optional[str] = None
    chargeBoxID: Optional[str] = None
    # status: Optional[bool] = None
    images: Optional[dict] = None
    is_active: Optional[bool] = None
    user_id: str | None = None 


ALLOW_FIELDS_ADMIN = {"station_id", "station_name", "brand", "model", "SN", "WO", "PLCFirmware", "PIFirmware", "RTFirmware", "chargeBoxID", "status","is_active", "user_id","images"}
# ALLOW_FIELDS_NONADMIN = {"status"}

def to_object_id_or_400(s: str) -> ObjectId:
    try:
        return ObjectId(s)
    except Exception:
        raise HTTPException(status_code=400, detail="invalid user_id")

# ===== Helpers ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ =====
STATION_IMG_ALLOWED = {"image/jpeg", "image/png", "image/webp"}
STATION_IMG_MAX_BYTES = 3 * 1024 * 1024  # 3 MB

def _ensure_dir(p: pathlib.Path):
    p.mkdir(parents=True, exist_ok=True)

async def save_station_image(station_id: str, kind: str, up: UploadFile) -> str:
    """
    ‡πÄ‡∏ã‡∏ü‡πÑ‡∏ü‡∏•‡πå‡∏•‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå /uploads/stations/<station_id>/
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ URL ‡∏ó‡∏µ‡πà‡∏ù‡∏±‡πà‡∏á Frontend ‡πÉ‡∏ä‡πâ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ (/uploads/...)
    """
    if up.content_type not in STATION_IMG_ALLOWED:
        raise HTTPException(status_code=415, detail=f"Unsupported file type: {up.content_type}")

    data = await up.read()
    if len(data) > STATION_IMG_MAX_BYTES:
        raise HTTPException(status_code=413, detail="File too large (> 3MB)")

    # ‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á
    subdir = pathlib.Path(UPLOADS_ROOT) / "stations" / station_id
    _ensure_dir(subdir)

    # ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå: kind-uuid.ext
    ext = {
        "image/jpeg": ".jpg",
        "image/png": ".png",
        "image/webp": ".webp",
    }.get(up.content_type, "")
    fname = f"{kind}-{uuid.uuid4().hex}{ext}"
    dest  = subdir / fname

    with open(dest, "wb") as f:
        f.write(data)

    # URL ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡πÅ‡∏™‡∏î‡∏á
    url = f"/uploads/stations/{station_id}/{fname}"
    return url

@app.patch("/update_stations/{id}", response_model=StationOut)
def update_station(
    id: str,
    body: StationUpdate,
    current: UserClaims = Depends(get_current_user)
):
    # ‡∏ï‡∏£‡∏ß‡∏à id ‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ
    try:
        oid = ObjectId(id)
    except Exception:
        raise HTTPException(status_code=400, detail="invalid id")

    # ‡∏´‡∏≤ station
    st = station_collection.find_one({"_id": oid})
    if not st:
        raise HTTPException(status_code=404, detail="station not found")

    # ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå: non-admin ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô owner ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    if current.role != "admin":
        st_owner = st.get("user_id")  # ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô ObjectId
        st_owner_str = str(st_owner) if st_owner is not None else None
        if not current.user_id or current.user_id != st_owner_str:
            raise HTTPException(status_code=403, detail="forbidden")

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤
    incoming: Dict[str, Any] = {
        k: (v.strip() if isinstance(v, str) else v)
        for k, v in body.model_dump(exclude_none=True).items()
    }
    if not incoming:
        raise HTTPException(status_code=400, detail="no fields to update")

    # ‡∏ó‡∏≥ allowlist + map owner (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ admin)
    if current.role == "admin":
        payload = {k: v for k, v in incoming.items() if k in ALLOW_FIELDS_ADMIN}

        # ‡∏ñ‡πâ‡∏≤ admin ‡∏™‡πà‡∏á user_id ‡∏°‡∏≤ ‚Üí ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô ObjectId ‡πÅ‡∏•‡∏∞ validate
        if "user_id" in payload:
            user_id_raw = payload["user_id"]

            # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏™‡∏≠‡∏á‡πÅ‡∏ö‡∏ö: ‡∏™‡πà‡∏á‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô id (24hex) ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏á‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô username
            udoc = None
            if isinstance(user_id_raw, str) and len(user_id_raw) == 24:
                # ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô ObjectId string
                udoc = users_collection.find_one({"_id": to_object_id_or_400(user_id_raw)})
            else:
                # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏ì‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ö‡πâ‡∏≤‡∏ô‡∏™‡πà‡∏á username ‡∏°‡∏≤ (‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡πÅ‡∏ï‡πà‡∏Å‡∏±‡∏ô‡πÑ‡∏ß‡πâ)
                udoc = users_collection.find_one({"username": user_id_raw})

            if not udoc:
                raise HTTPException(status_code=400, detail="invalid user_id")

            # ‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô ObjectId ‡πÉ‡∏ô DB
            payload["user_id"] = udoc["_id"]
    

    if "is_active" in payload and not isinstance(payload["is_active"], bool):
        raise HTTPException(status_code=400, detail="is_active must be boolean")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á update
    update_doc: Dict[str, Any] = {"$set": payload}

    # ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‚Äú‡∏•‡∏ö‚Äù ‡∏ü‡∏¥‡∏•‡∏î‡πå username ‡πÄ‡∏î‡∏¥‡∏°‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å stations (‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞ user_id)
    # ‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ ‡πÉ‡∏™‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏•‡∏≠‡∏î):
    update_doc["$unset"] = {"username": ""}

    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï
    res = station_collection.update_one({"_id": oid}, update_doc)
    if res.matched_count == 0:
        raise HTTPException(status_code=404, detail="station not found")

    # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡∏∑‡∏ô
    doc = station_collection.find_one({"_id": oid})
    created_at = doc.get("createdAt")
    if created_at is None:
        created_at = datetime.now(timezone.utc)   # üëà ‡∏Å‡∏±‡∏ô‡∏Ñ‡πà‡∏≤ None
    return {
        "id": str(doc["_id"]),
        "station_id": doc.get("station_id", ""),
        "station_name": doc.get("station_name", ""),
        "brand": doc.get("brand", ""),
        "model": doc.get("model", ""),
        "SN": doc.get("SN", ""),
        "WO": doc.get("WO", ""),
        "PLCFirmware": doc.get("PLCFirmware", ""),
        "PIFirmware": doc.get("PIFirmware", ""),
        "RTFirmware": doc.get("RTFirmware", ""),
        "chargeBoxID": doc.get("chargeBoxID", ""),
        "createdAt": created_at,  
        # ‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô string ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ù‡∏±‡πà‡∏á client ‡πÉ‡∏ä‡πâ‡∏á‡πà‡∏≤‡∏¢
        "user_id": str(doc["user_id"]) if doc.get("user_id") else "",
        "username": doc.get("username"),
        "is_active": bool(doc.get("is_active", False)),
        "images": doc.get("images", {}),       # ‚úÖ ‡πÉ‡∏™‡πà‡∏†‡∏≤‡∏û‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢
        "updatedAt": datetime.now(timezone.utc)
    }

@app.post("/stations/{station_id}/upload-images")
async def upload_station_images(
    station_id: str,
    station: Optional[UploadFile] = File(None),
    mdb: Optional[UploadFile]     = File(None),
    charger: Optional[UploadFile] = File(None),
    device: Optional[UploadFile]  = File(None),
    current: UserClaims = Depends(get_current_user),
):
    # ‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ
    doc = station_collection.find_one({"station_id": station_id})
    if not doc:
        raise HTTPException(status_code=404, detail="station not found")

    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå: admin ‡∏ú‡πà‡∏≤‡∏ô / owner ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    owner_str = str(doc.get("user_id")) if doc.get("user_id") else None
    if current.role != "admin" and current.user_id != owner_str:
        raise HTTPException(status_code=403, detail="forbidden")

    updated: dict[str, str] = {}
    for kind, up in {"station": station, "mdb": mdb, "charger": charger, "device": device}.items():
        if up is None:
            continue
        url = await save_station_image(station_id, kind, up)
        updated[kind] = url

    if not updated:
        return {"updated": False, "images": doc.get("images", {})}

    images = doc.get("images", {})
    images.update(updated)

    station_collection.update_one(
        {"_id": doc["_id"]},
        {"$set": {"images": images, "updatedAt": datetime.now(timezone.utc)}}
    )

    return {"updated": True, "images": images}

@app.get("/owners")
async def get_owners():
    cursor = users_collection.find({"role": "owner"}, {"_id": 1, "username": 1})
    owners = [{"user_id": str(u["_id"]), "username": u["username"]} for u in cursor]

    if not owners:
        raise HTTPException(status_code=404, detail="owners not found")

    return {"owners": owners}

stationOnOff = client1["stationsOnOff"]
class StationIdsIn(BaseModel):
    station_ids: List[str]

def _latest_onoff_bool(sid: str) -> bool:
    coll = stationOnOff.get_collection(str(sid))
    doc = coll.find_one(sort=[("payload.timestamp", -1), ("_id", -1)])  # ‚Üê ‡πÄ‡∏≠‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏£‡∏¥‡∏á ‡πÜ
    if not doc:
        return False
    payload = doc.get("payload", {})
    val = payload.get("value", 0)
    # map ‡πÄ‡∏õ‡πá‡∏ô bool ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î
    if isinstance(val, bool):
        return val
    try:
        return bool(int(val))
    except Exception:
        return False

@app.post("/station-onoff/bulk")
def get_station_onoff_bulk(body: StationIdsIn):
    out: Dict[str, bool] = {}
    for sid in body.station_ids:
        try:
            out[sid] = _latest_onoff_bool(sid)
        except Exception:
            out[sid] = False
    return {"status": out}

@app.get("/station-onoff/{station_id}")
def station_onoff_latest(station_id: str, current: UserClaims = Depends(get_current_user)):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    data = latest_onoff(str(station_id))
    status_at_iso = (
        data["statusAt"].astimezone(ZoneInfo("Asia/Bangkok")).isoformat()
        if data["statusAt"] else None
    )
    return {"station_id": station_id, "status": data["status"], "statusAt": status_at_iso}

def parse_iso_any_tz(s: str) -> datetime | None:
    if not isinstance(s, str):
        return None
    try:
        return datetime.fromisoformat(s.replace("Z", "+00:00"))
    except Exception:
        try:
            return datetime.fromisoformat(s + "+00:00")
        except Exception:
            return None

# -------------------------------------------------- PMReportPage (charger)       
def get_pmreport_collection_for(station_id: str):
    # ‡∏Å‡∏±‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏Å ‡πÜ
    if not re.fullmatch(r"[A-Za-z0-9_\-]+", str(station_id)):
        raise HTTPException(status_code=400, detail="Bad station_id")
    return PMReportDB.get_collection(str(station_id))



def _compute_next_pm_date_str(pm_date_str: str | None) -> str | None:
    if not pm_date_str:
        return None
    # pm_date ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô "YYYY-MM-DD"
    try:
        d = datetime.fromisoformat(pm_date_str).date()  # date object
    except ValueError:
        return None
    next_d = d + relativedelta(months=+6)              # ‚Üê ‡∏ï‡∏£‡∏á 6 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
    return next_d.isoformat()     

def _pick_latest_from_pm_reports(pm_reports: list[dict] | None):
    """‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å array pm_reports ‡πÇ‡∏î‡∏¢‡∏î‡∏π timestamp (string/datetime)"""
    if not pm_reports:
        return None

    def _to_dt(x):
        ts = x.get("timestamp")
        if isinstance(ts, str):
            try:
                return parse_iso_any_tz(ts)
            except Exception:
                return None
        if isinstance(ts, datetime):
            return ts
        return None

    pm_reports_sorted = sorted(
        pm_reports,
        key=lambda r: (_to_dt(r) or datetime.min.replace(tzinfo=ZoneInfo("UTC")))
    )
    return pm_reports_sorted[-1] if pm_reports_sorted else None

# --- helper: ‡πÄ‡∏≠‡∏≤ pm_date ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å PMReportDB/<station_id> ---
async def _latest_pm_date_from_pmreport(station_id: str) -> dict | None:
    if not re.fullmatch(r"[A-Za-z0-9_\-]+", str(station_id)):
        raise HTTPException(status_code=400, detail="Bad station_id")
    coll = PMReportDB.get_collection(str(station_id))

    pipeline = [
        {"$addFields": {
            "_ts": {
                "$ifNull": [
                    {
                        "$cond": [
                            {"$eq": [{"$type": "$timestamp"}, "string"]},
                            {"$dateFromString": {
                                "dateString": "$timestamp",
                                "timezone": "UTC",
                                "onError": None,
                                "onNull": None
                            }},
                            "$timestamp"
                        ]
                    },
                    {"$toDate": "$_id"}
                ]
            }
        }},
        {"$sort": {"_ts": -1, "_id": -1}},
        {"$limit": 1},
        {"$project": {"_id": 1, "pm_date": 1, "timestamp": 1}}
    ]

    cursor = coll.aggregate(pipeline)
    docs = await cursor.to_list(length=1)
    return docs[0] if docs else None

async def _pmreport_latest_core(station_id: str, current: UserClaims):
    # --- auth & validate ---
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")
    if not re.fullmatch(r"[A-Za-z0-9_\-]+", str(station_id)):
        raise HTTPException(status_code=400, detail="Bad station_id")

    # 1) ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å stations
    st = station_collection.find_one(
        {"station_id": station_id},
        {"_id": 1, "PIFirmware": 1, "PLCFirmware": 1, "RTFirmware": 1, "timestamp": 1, "updatedAt": 1}
    )
    if not st:
        raise HTTPException(status_code=404, detail="Station not found")

    pi_fw  = st.get("PIFirmware")
    plc_fw = st.get("PLCFirmware")
    rt_fw  = st.get("RTFirmware")

    # 2) ‡∏î‡∏∂‡∏á pm_date ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å PMReportDB
    pm_latest = await _latest_pm_date_from_pmreport(station_id)
    pm_date = pm_latest.get("pm_date") if pm_latest else None

    # ‡πÄ‡∏ß‡∏•‡∏≤: ‡πÉ‡∏ä‡πâ timestamp ‡∏à‡∏≤‡∏Å pm report ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡πÑ‡∏°‡πà‡∏á‡∏±‡πâ‡∏ô fallback ‡πÑ‡∏õ‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ
    ts_raw = (pm_latest.get("timestamp") if pm_latest else None) or st.get("timestamp") or st.get("updatedAt")

    ts_dt = (parse_iso_any_tz(ts_raw) if isinstance(ts_raw, str)
             else (ts_raw if isinstance(ts_raw, datetime) else None))
    ts_utc = ts_dt.astimezone(ZoneInfo("UTC")).isoformat() if ts_dt else None
    ts_th  = ts_dt.astimezone(ZoneInfo("Asia/Bangkok")).isoformat() if ts_dt else None

    pm_next_date = _compute_next_pm_date_str(pm_date)

    return {
        "_id": str(st["_id"]),
        "pi_firmware": pi_fw,
        "plc_firmware": plc_fw,
        "rt_firmware": rt_fw,
        "pm_date": pm_date,              # ‚Üê ‡∏°‡∏≤‡∏à‡∏≤‡∏Å PMReportDB
        "pm_next_date": pm_next_date, 
        "timestamp": ts_raw,             # pmreport.timestamp ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        "timestamp_utc": ts_utc,
        "timestamp_th": ts_th,
        "source": "stations + PMReportDB",  # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠ debug
    }


# ‡πÄ‡∏î‡∏¥‡∏° (path param) ‚Üí ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å helper
@app.get("/pmreport/latest/{station_id}")
async def pmreport_latest(station_id: str, current: UserClaims = Depends(get_current_user)):
    return await _pmreport_latest_core(station_id, current)

# ‡πÉ‡∏´‡∏°‡πà (query param) ‚Üí ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö /pmreport/latest/?station_id=...
@app.get("/pmreport/latest/")
async def pmreport_latest_q(
    station_id: str = Query(..., description="‡πÄ‡∏ä‡πà‡∏ô Klongluang3"),
    current: UserClaims = Depends(get_current_user),
):
    return await _pmreport_latest_core(station_id, current)


class PMMeasureRow(BaseModel):
    value: str = ""
    unit: str = "V"

class PMMeasures(BaseModel):
    m17: Dict[str, PMMeasureRow] = Field(default_factory=dict)  # L1-L2, L2-L3, ...
    cp: PMMeasureRow = PMMeasureRow()

class PMRowPF(BaseModel):
    pf: Optional[Literal["PASS","FAIL","NA",""]] = ""
    remark: Optional[str] = ""

class PMSubmitIn(BaseModel):
    station_id: str
    job: dict
    rows: dict
    measures: dict
    summary: str
    pm_date:str

@app.post("/pmreport/submit")
async def pmreport_submit(body: PMSubmitIn, current: UserClaims = Depends(get_current_user)):
    print("HIT /pmreport/submit")
    station_id = body.station_id.strip()
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_pmreport_collection_for(station_id)
    doc = {
        "station_id": station_id,
        "job": body.job,
        "rows": body.rows,
        "measures": body.measures,
        "summary": body.summary,
        "pm_date": body.pm_date,
        "photos": {},                   # ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ï‡∏¥‡∏°‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á
        "status": "draft",              # ‡∏´‡∏£‡∏∑‡∏≠ "submitted" ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        "timestamp": datetime.now(timezone.utc),
    }
    res = await coll.insert_one(doc)
    report_id = str(res.inserted_id)
    return {"ok": True, "report_id": report_id}

@app.get("/pmreport/list")
async def pmreport_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
):
    coll = get_pmreport_collection_for(station_id)
    skip = (page - 1) * pageSize

    cursor = coll.find({}, {"_id": 1, "pm_date": 1, "createdAt": 1}).sort(
        [("createdAt", -1), ("_id", -1)]
    ).skip(skip).limit(pageSize)
    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    # --- ‡∏î‡∏∂‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å PMReportURL ‡πÇ‡∏î‡∏¢ map ‡∏î‡πâ‡∏ß‡∏¢ pm_date (string) ---
    pm_dates = [it.get("pm_date") for it in items_raw if it.get("pm_date")]
    urls_coll = get_pmurl_coll_upload(station_id)
    url_by_day: dict[str, str] = {}

    if pm_dates:
        ucur = urls_coll.find({"pm_date": {"$in": pm_dates}}, {"pm_date": 1, "urls": 1})
        url_docs = await ucur.to_list(length=10_000)
        for u in url_docs:
            day = u.get("pm_date")
            first_url = (u.get("urls") or [None])[0]
            if day and first_url and day not in url_by_day:
                url_by_day[day] = first_url

    items = [{
        "id": str(it["_id"]),
        "pm_date": it.get("pm_date"),
        "createdAt": _ensure_utc_iso(it.get("createdAt")),
        "file_url": url_by_day.get(it.get("pm_date") or "", ""),
    } for it in items_raw]

    pm_date_arr = [it.get("pm_date") for it in items_raw if it.get("pm_date")]
    return {"items": items, "pm_date": pm_date_arr, "page": page, "pageSize": pageSize, "total": total}


# ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
UPLOADS_ROOT = os.getenv("UPLOADS_ROOT", "./uploads")
os.makedirs(UPLOADS_ROOT, exist_ok=True)

# ‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏∑‡∏ô‡πÉ‡∏´‡πâ Frontend ‡∏ú‡πà‡∏≤‡∏ô /uploads/...
app.mount("/uploads", StaticFiles(directory=UPLOADS_ROOT, html=False), name="uploads")

ALLOWED_EXTS = {"jpg","jpeg","png","webp","gif"}
MAX_FILE_MB = 10

def _safe_name(name: str) -> str:
    # ‡∏Å‡∏±‡∏ô path traversal ‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡πÅ‡∏õ‡∏•‡∏Å ‡πÜ
    base = re.sub(r"[^A-Za-z0-9._-]+", "_", name)
    return base[:120] or secrets.token_hex(4)

def _ext(fname: str) -> str:
    return (fname.rsplit(".",1)[-1].lower() if "." in fname else "")

@app.post("/pmreport/{report_id}/photos")
async def pmreport_upload_photos(
    report_id: str,
    station_id: str = Form(...),
    group: str = Form(...),                   # ‡πÄ‡∏ä‡πà‡∏ô "g1" .. "g10"
    files: list[UploadFile] = File(...),
    remark: str | None = Form(None),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")
    if not re.fullmatch(r"g\d+", group):
        raise HTTPException(status_code=400, detail="Bad group key")

    coll = get_pmreport_collection_for(station_id)
    from bson import ObjectId
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    # ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ß‡πà‡∏≤‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô station ‡∏ô‡∏µ‡πâ
    doc = await coll.find_one({"_id": oid}, {"_id":1, "station_id":1})
    if not doc:
        raise HTTPException(status_code=404, detail="Report not found")
    if doc.get("station_id") != station_id:
        raise HTTPException(status_code=400, detail="station_id mismatch")

    # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "pm" / station_id / report_id / group
    dest_dir.mkdir(parents=True, exist_ok=True)

    saved = []
    total = 0
    for f in files:
        ext = _ext(f.filename or "")
        if ext not in ALLOWED_EXTS:
            raise HTTPException(status_code=400, detail=f"File type not allowed: {ext}")

        data = await f.read()
        total += len(data)
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        fname = _safe_name(f.filename or f"image_{secrets.token_hex(3)}.{ext}")
        path = dest_dir / fname
        with open(path, "wb") as out:
            out.write(data)

        # URL ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ô Frontend
        url_path = f"/uploads/pm/{station_id}/{report_id}/{group}/{fname}"
        saved.append({
            "filename": fname,
            "size": len(data),
            "url": url_path,
            "remark": remark or "",
            "uploadedAt": datetime.now(timezone.utc)
        })

    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ PMReport: push ‡∏•‡∏á photos.<group>
    await coll.update_one(
        {"_id": oid},
        {"$push": {f"photos.{group}": {"$each": saved}}}
    )

    return {"ok": True, "count": len(saved), "group": group, "files": saved}


@app.post("/pmreport/{report_id}/finalize")
async def pmreport_finalize(
    report_id: str,
    station_id: str = Form(...),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_pmreport_collection_for(station_id)
    from bson import ObjectId
    oid = ObjectId(report_id)
    res = await coll.update_one(
        {"_id": oid},
        {"$set": {"status": "submitted", "submittedAt": datetime.now(timezone.utc)}}
    )
    if res.matched_count == 0:
        raise HTTPException(status_code=404, detail="Report not found")
    return {"ok": True}

def parse_report_date_to_utc(s: str) -> datetime:
    # 'YYYY-MM-DD' => ‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô UTC
    if re.fullmatch(r"\d{4}-\d{2}-\d{2}$", s):
        tz_th = ZoneInfo("Asia/Bangkok")
        dt_th = datetime.fromisoformat(s + "T00:00:00").replace(tzinfo=tz_th)
        return dt_th.astimezone(timezone.utc)
    # ISO ‡∏ó‡∏µ‡πà‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢ Z ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏≠‡∏≠‡∏ü‡πÄ‡∏ã‡πá‡∏ï
    if s.endswith("Z"):
        return datetime.fromisoformat(s.replace("Z", "+00:00")).astimezone(timezone.utc)
    if re.search(r"[+\-]\d{2}:\d{2}$", s):
        return datetime.fromisoformat(s).astimezone(timezone.utc)
    # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏ã‡∏ô ‚Üí ‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢
    return datetime.fromisoformat(s + "+07:00").astimezone(timezone.utc)

def get_pmurl_coll_upload(station_id: str):
    _validate_station_id(station_id)
    coll = PMUrlDB.get_collection(str(station_id))
    # # ‡πÄ‡∏Å‡πá‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡∏ö Date ‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏ß‡πâ query ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    # try:
    #     coll.create_index([("reportDate", 1)])
    #     coll.create_index([("createdAt", -1), ("_id", -1)])
    # except Exception:
    #     pass
    return coll

# --- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö PDF ---
ALLOWED_EXTS = {"jpg","jpeg","png","webp","gif","pdf"}  # <<-- ‡πÄ‡∏û‡∏¥‡πà‡∏° pdf
MAX_FILE_MB = 20  # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô

def _safe_name(name: str) -> str:
    base = re.sub(r"[^A-Za-z0-9._-]+", "_", name)
    return base[:120] or secrets.token_hex(4)

def normalize_pm_date(s: str) -> str:
    """
    ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á:
      - 'YYYY-MM-DD'           -> ‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏î‡∏¥‡∏°
      - ISO (‡∏°‡∏µ Z/offset ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ) -> ‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏∑‡∏ô date().isoformat()
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô 'YYYY-MM-DD' (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏ß‡∏•‡∏≤)
    """
    if re.fullmatch(r"\d{4}-\d{2}-\d{2}$", s):
        return s
    # ‡∏°‡∏µ‡πÇ‡∏ã‡∏ô‡πÄ‡∏ß‡∏•‡∏≤
    if s.endswith("Z") or re.search(r"[+\-]\d{2}:\d{2}$", s):
        dt = datetime.fromisoformat(s.replace("Z", "+00:00"))
    else:
        # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏ã‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ -> ‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢
        dt = datetime.fromisoformat(s).replace(tzinfo=th_tz)
    return dt.astimezone(th_tz).date().isoformat()

@app.post("/pmurl/upload-files", status_code=201)
async def pmurl_upload_files(
    station_id: str = Form(...),
    reportDate: str = Form(...),                 # "YYYY-MM-DD" ‡∏´‡∏£‡∏∑‡∏≠ ISO
    files: list[UploadFile] = File(...),
    current: UserClaims = Depends(get_current_user),
):
    # auth
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    # ‡∏ï‡∏£‡∏ß‡∏à/‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô
    coll = get_pmurl_coll_upload(station_id)

    # parse ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô UTC datetime (‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß)
    pm_date = normalize_pm_date(reportDate)

    # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á: /uploads/pmurl/<station_id>/<YYYY-MM-DD>/
    # subdir = report_dt_utc.astimezone(th_tz).date().isoformat()
    subdir = pm_date
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "pmurl" / station_id / subdir
    dest_dir.mkdir(parents=True, exist_ok=True)

    urls = []
    metas = []
    total_size = 0

    for f in files:
        ext = (f.filename.rsplit(".",1)[-1].lower() if "." in f.filename else "")
        if ext not in ALLOWED_EXTS or ext != "pdf":
            raise HTTPException(status_code=400, detail=f"Only PDF allowed, got: {ext}")

        data = await f.read()
        total_size += len(data)
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        safe = _safe_name(f.filename or f"file_{secrets.token_hex(3)}.pdf")
        dest = dest_dir / safe
        with open(dest, "wb") as out:
            out.write(data)

        url = f"/uploads/pmurl/{station_id}/{subdir}/{safe}"   # ‚Üê ‡∏à‡∏∞‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å StaticFiles ‡∏ó‡∏µ‡πà mount ‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß
        urls.append(url)
        metas.append({"name": f.filename, "size": len(data)})

    now = datetime.now(timezone.utc)
    doc = {
        "station": station_id,
        "pm_date": pm_date,   
        "urls": urls,
        "meta": {"files": metas},
        "source": "upload-files",
        "createdAt": now,
        "updatedAt": now,
    }
    res = await coll.insert_one(doc)

    return {"ok": True, "inserted_id": str(res.inserted_id), "count": len(urls), "urls": urls}

@app.get("/pmurl/list")
async def pmurl_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
):
    """
    ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå PM (PDF) ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ‡∏ï‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ ‡∏à‡∏≤‡∏Å PMUrlDB/<station_id>
    - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö pm_date (string 'YYYY-MM-DD') ‡πÅ‡∏•‡∏∞ reportDate (Date/ISO)
    - ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏õ‡πÄ‡∏Å‡πà‡∏≤ (createdAt desc, _id desc)
    - ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô /pmreport/list (‡∏°‡∏µ file_url ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å)
    """
    coll = get_pmurl_coll_upload(station_id)
    skip = (page - 1) * pageSize

    # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    cursor = coll.find(
        {},
        {"_id": 1, "pm_date": 1, "reportDate": 1, "urls": 1, "createdAt": 1}
    ).sort([("createdAt", -1), ("_id", -1)]).skip(skip).limit(pageSize)

    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    def _pm_date_from(doc: dict) -> str | None:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ string 'YYYY-MM-DD'
        - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ pm_date (string) ‚Üí ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
        - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ reportDate (datetime/string) ‚Üí ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡πâ‡∏ß .date().isoformat()
        """
        # ‡∏£‡∏∏‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà: ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô pm_date (string)
        s = doc.get("pm_date")
        if isinstance(s, str) and re.fullmatch(r"\d{4}-\d{2}-\d{2}$", s):
            return s

        # ‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Å‡πà‡∏≤: ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô reportDate (Date/ISO)
        rd = doc.get("reportDate")
        if isinstance(rd, datetime):
            return rd.astimezone(th_tz).date().isoformat()
        if isinstance(rd, str):
            try:
                dt = datetime.fromisoformat(rd.replace("Z", "+00:00"))
            except Exception:
                # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏ã‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ ‚Üí ‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢
                try:
                    dt = datetime.fromisoformat(rd).replace(tzinfo=th_tz)
                except Exception:
                    return None
            return dt.astimezone(th_tz).date().isoformat()

        return None

    items = []
    pm_date_arr = []

    for it in items_raw:
        pm_date_str = _pm_date_from(it)
        if pm_date_str:
            pm_date_arr.append(pm_date_str)

        urls = it.get("urls") or []
        first_url = urls[0] if urls else ""

        items.append({
            "id": str(it["_id"]),
            "pm_date": pm_date_str,                         # 'YYYY-MM-DD' | None
            "createdAt": _ensure_utc_iso(it.get("createdAt")),
            "file_url": first_url,                          # ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å (‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î)
            "urls": urls,                                   # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ü‡∏£‡∏≠‡∏ô‡∏ï‡πå‡∏≠‡∏¢‡∏≤‡∏Å‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        })

    return {
        "items": items,
        "pm_date": [d for d in pm_date_arr if d],          # ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô /pmreport/list
        "page": page,
        "pageSize": pageSize,
        "total": total,
    }

# -------------------------------------------------- PMReportPage (MDB)       

def get_mdbpmreport_collection_for(station_id: str):
    _validate_station_id(station_id)
    return MDBPMReportDB.get_collection(str(station_id))

def get_mdbpmurl_coll_upload(station_id: str):
    _validate_station_id(station_id)
    return MDBPMUrlDB.get_collection(str(station_id))

class MDBPMSubmitIn(BaseModel):
    station_id: str
    job: Dict[str, Any]         # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô (location/date/inspector ‡∏Ø‡∏•‡∏Ø)
    rows: Dict[str, Dict[str, Any]]  # {"r1": {"pf": "...", "remark": "..."}, ...}
    measures: Dict[str, Dict[str, Any]]  # {"m4": {...}, "m5": {...}, ..., "m8": {...}}
    summary: str
    pm_date: str                # "YYYY-MM-DD"

@app.post("/mdbpmreport/submit")
async def mdbpmreport_submit(body: MDBPMSubmitIn, current: UserClaims = Depends(get_current_user)):
    print("HIT /mdbpmreport/submit")  # debug
    station_id = body.station_id.strip()
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_mdbpmreport_collection_for(station_id)

    # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô draft ‡∏Å‡πà‡∏≠‡∏ô
    doc = {
        "station_id": station_id,
        "job": body.job,
        "rows": body.rows,
        "measures": body.measures,         # m4..m8
        "summary": body.summary,
        "pm_date": body.pm_date,           # string YYYY-MM-DD (‡∏ï‡∏≤‡∏°‡∏ü‡∏£‡∏≠‡∏ô‡∏ï‡πå)
        "status": "draft",
        "photos": {},                      # ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏ô /photos
        "createdAt": datetime.now(timezone.utc),
        "updatedAt": datetime.now(timezone.utc),
    }

    res = await coll.insert_one(doc)
    return {"ok": True, "report_id": str(res.inserted_id)}

@app.get("/mdbpmreport/list")
async def mdbpmreport_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_mdbpmreport_collection_for(station_id)
    skip = (page - 1) * pageSize

    cursor = coll.find({}, {"_id": 1, "pm_date": 1, "createdAt": 1}).sort(
        [("createdAt", -1), ("_id", -1)]
    ).skip(skip).limit(pageSize)

    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    # ‡∏ú‡∏π‡∏Å URL PDF ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡∏à‡∏≤‡∏Å MDBPMUrlDB (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    pm_dates = [it.get("pm_date") for it in items_raw if it.get("pm_date")]
    url_by_day: Dict[str, str] = {}
    if pm_dates:
        ucoll = get_mdbpmurl_coll_upload(station_id)
        ucur = ucoll.find({"pm_date": {"$in": pm_dates}}, {"pm_date": 1, "urls": 1})
        url_docs = await ucur.to_list(length=10_000)
        for u in url_docs:
            day = u.get("pm_date")
            first_url = (u.get("urls") or [None])[0]
            if day and first_url and day not in url_by_day:
                url_by_day[day] = first_url

    items = [{
        "id": str(it["_id"]),
        "pm_date": it.get("pm_date"),
        "createdAt": _ensure_utc_iso(it.get("createdAt")),
        "file_url": url_by_day.get(it.get("pm_date") or "", ""),
    } for it in items_raw]

    return {"items": items, "pm_date": [it.get("pm_date") for it in items_raw if it.get("pm_date")], "page": page, "pageSize": pageSize, "total": total}

@app.post("/mdbpmreport/{report_id}/photos")
async def mdbpmreport_upload_photos(
    report_id: str,
    station_id: str = Form(...),
    group: str = Form(...),                   # "g1" .. "g11"
    files: List[UploadFile] = File(...),
    remark: Optional[str] = Form(None),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")
    if not re.fullmatch(r"g\d+", group):
        raise HTTPException(status_code=400, detail="Bad group key")

    coll = get_mdbpmreport_collection_for(station_id)
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    doc = await coll.find_one({"_id": oid}, {"_id": 1, "station_id": 1})
    if not doc:
        raise HTTPException(status_code=404, detail="Report not found")
    if doc.get("station_id") != station_id:
        raise HTTPException(status_code=400, detail="station_id mismatch")

    # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: /uploads/mdbpm/{station_id}/{report_id}/{group}/
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "mdbpm" / station_id / report_id / group
    dest_dir.mkdir(parents=True, exist_ok=True)

    saved = []
    for f in files:
        ext = (f.filename.rsplit(".",1)[-1].lower() if f.filename and "." in f.filename else "")
        if ext not in ALLOWED_EXTS:
            raise HTTPException(status_code=400, detail=f"File type not allowed: {ext}")

        data = await f.read()
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        fname = _safe_name(f.filename or f"image_{secrets.token_hex(3)}.{ext}")
        path = dest_dir / fname
        with open(path, "wb") as out:
            out.write(data)

        url_path = f"/uploads/mdbpm/{station_id}/{report_id}/{group}/{fname}"
        saved.append({
            "filename": fname,
            "size": len(data),
            "url": url_path,
            "remark": remark or "",
            "uploadedAt": datetime.now(timezone.utc)
        })

    await coll.update_one(
        {"_id": oid},
        {
            "$push": {f"photos.{group}": {"$each": saved}},
            "$set": {"updatedAt": datetime.now(timezone.utc)}
        }
    )
    return {"ok": True, "count": len(saved), "group": group, "files": saved}

@app.post("/mdbpmreport/{report_id}/finalize")
async def mdbpmreport_finalize(
    report_id: str,
    station_id: str = Form(...),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_mdbpmreport_collection_for(station_id)
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    # (‡∏≠‡∏≠‡∏õ‡∏ä‡∏±‡∏ô) ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏Å‡πà‡∏≠‡∏ô finalize ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
    res = await coll.update_one(
        {"_id": oid},
        {"$set": {"status": "submitted", "submittedAt": datetime.now(timezone.utc), "updatedAt": datetime.now(timezone.utc)}}
    )
    if res.matched_count == 0:
        raise HTTPException(status_code=404, detail="Report not found")
    return {"ok": True}

# -------------------------- ‡πÑ‡∏ü‡∏•‡πå PDF ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô (MDB PM URL) --------------------------

@app.post("/mdbpmurl/upload-files", status_code=201)
async def mdbpmurl_upload_files(
    station_id: str = Form(...),
    reportDate: str = Form(...),            # "YYYY-MM-DD" ‡∏´‡∏£‡∏∑‡∏≠ ISO -> ‡∏à‡∏∞ normalize ‡πÄ‡∏õ‡πá‡∏ô YYYY-MM-DD
    files: List[UploadFile] = File(...),    # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÄ‡∏â‡∏û‡∏≤‡∏∞ .pdf
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_mdbpmurl_coll_upload(station_id)
    pm_date = normalize_pm_date(reportDate)  # ‡∏Ñ‡∏∑‡∏ô YYYY-MM-DD

    # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà /uploads/mdbpmurl/<station_id>/<YYYY-MM-DD>/
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "mdbpmurl" / station_id / pm_date
    dest_dir.mkdir(parents=True, exist_ok=True)

    urls, metas = [], []
    for f in files:
        ext = (f.filename.rsplit(".",1)[-1].lower() if f.filename and "." in f.filename else "")
        if ext != "pdf":
            raise HTTPException(status_code=400, detail=f"Only PDF allowed, got: {ext}")

        data = await f.read()
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        fname = _safe_name(f.filename or f"file_{secrets.token_hex(3)}.pdf")
        path = dest_dir / fname
        with open(path, "wb") as out:
            out.write(data)

        url = f"/uploads/mdbpmurl/{station_id}/{pm_date}/{fname}"
        urls.append(url)
        metas.append({"name": f.filename, "size": len(data)})

    now = datetime.now(timezone.utc)
    res = await coll.insert_one({
        "station": station_id,
        "pm_date": pm_date,
        "urls": urls,
        "meta": {"files": metas},
        "source": "upload-files",
        "createdAt": now,
        "updatedAt": now,
    })
    return {"ok": True, "inserted_id": str(res.inserted_id), "count": len(urls), "urls": urls}

@app.get("/mdbpmurl/list")
async def mdbpmurl_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_mdbpmurl_coll_upload(station_id)
    skip = (page - 1) * pageSize

    cursor = coll.find(
        {},
        {"_id": 1, "pm_date": 1, "urls": 1, "createdAt": 1}
    ).sort([("createdAt", -1), ("_id", -1)]).skip(skip).limit(pageSize)

    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    items = []
    for it in items_raw:
        urls = it.get("urls") or []
        first_url = urls[0] if urls else ""
        items.append({
            "id": str(it["_id"]),
            "pm_date": it.get("pm_date"),
            "createdAt": _ensure_utc_iso(it.get("createdAt")),
            "file_url": first_url,
            "urls": urls,
        })

    return {"items": items, "pm_date": [i["pm_date"] for i in items if i.get("pm_date")], "page": page, "pageSize": pageSize, "total": total}

# -------------------------------------------------- PMReportPage (CCB)       
def get_ccbpmreport_collection_for(station_id: str):
    _validate_station_id(station_id)
    return CCBPMReportDB.get_collection(str(station_id))

def get_ccbpmurl_coll_upload(station_id: str):
    _validate_station_id(station_id)
    return CCBPMUrlDB.get_collection(str(station_id))

class CCBPMSubmitIn(BaseModel):
    station_id: str
    job: Dict[str, Any]         # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô (location/date/inspector ‡∏Ø‡∏•‡∏Ø)
    rows: Dict[str, Dict[str, Any]]  # {"r1": {"pf": "...", "remark": "..."}, ...}
    measures: Dict[str, Dict[str, Any]]  # {"m4": {...}, "m5": {...}, ..., "m8": {...}}
    summary: str
    pm_date: str                # "YYYY-MM-DD"

@app.post("/ccbpmreport/submit")
async def ccbpmreport_submit(body: CCBPMSubmitIn, current: UserClaims = Depends(get_current_user)):
    print("HIT /ccbpmreport/submit")  # debug
    station_id = body.station_id.strip()
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_ccbpmreport_collection_for(station_id)

    # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô draft ‡∏Å‡πà‡∏≠‡∏ô
    doc = {
        "station_id": station_id,
        "job": body.job,
        "rows": body.rows,
        "measures": body.measures,         # m4..m8
        "summary": body.summary,
        "pm_date": body.pm_date,           # string YYYY-MM-DD (‡∏ï‡∏≤‡∏°‡∏ü‡∏£‡∏≠‡∏ô‡∏ï‡πå)
        "status": "draft",
        "photos": {},                      # ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏ô /photos
        "createdAt": datetime.now(timezone.utc),
        "updatedAt": datetime.now(timezone.utc),
    }

    res = await coll.insert_one(doc)
    return {"ok": True, "report_id": str(res.inserted_id)}

@app.get("/ccbpmreport/list")
async def ccbpmreport_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_ccbpmreport_collection_for(station_id)
    skip = (page - 1) * pageSize

    cursor = coll.find({}, {"_id": 1, "pm_date": 1, "createdAt": 1}).sort(
        [("createdAt", -1), ("_id", -1)]
    ).skip(skip).limit(pageSize)

    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    # ‡∏ú‡∏π‡∏Å URL PDF ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡∏à‡∏≤‡∏Å MDBPMUrlDB (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    pm_dates = [it.get("pm_date") for it in items_raw if it.get("pm_date")]
    url_by_day: Dict[str, str] = {}
    if pm_dates:
        ucoll = get_ccbpmurl_coll_upload(station_id)
        ucur = ucoll.find({"pm_date": {"$in": pm_dates}}, {"pm_date": 1, "urls": 1})
        url_docs = await ucur.to_list(length=10_000)
        for u in url_docs:
            day = u.get("pm_date")
            first_url = (u.get("urls") or [None])[0]
            if day and first_url and day not in url_by_day:
                url_by_day[day] = first_url

    items = [{
        "id": str(it["_id"]),
        "pm_date": it.get("pm_date"),
        "createdAt": _ensure_utc_iso(it.get("createdAt")),
        "file_url": url_by_day.get(it.get("pm_date") or "", ""),
    } for it in items_raw]

    return {"items": items, "pm_date": [it.get("pm_date") for it in items_raw if it.get("pm_date")], "page": page, "pageSize": pageSize, "total": total}

@app.post("/ccbpmreport/{report_id}/photos")
async def ccbpmreport_upload_photos(
    report_id: str,
    station_id: str = Form(...),
    group: str = Form(...),                   # "g1" .. "g11"
    files: List[UploadFile] = File(...),
    remark: Optional[str] = Form(None),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")
    if not re.fullmatch(r"g\d+", group):
        raise HTTPException(status_code=400, detail="Bad group key")

    coll = get_ccbpmreport_collection_for(station_id)
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    doc = await coll.find_one({"_id": oid}, {"_id": 1, "station_id": 1})
    if not doc:
        raise HTTPException(status_code=404, detail="Report not found")
    if doc.get("station_id") != station_id:
        raise HTTPException(status_code=400, detail="station_id mismatch")

    # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: /uploads/mdbpm/{station_id}/{report_id}/{group}/
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "ccbpm" / station_id / report_id / group
    dest_dir.mkdir(parents=True, exist_ok=True)

    saved = []
    for f in files:
        ext = (f.filename.rsplit(".",1)[-1].lower() if f.filename and "." in f.filename else "")
        if ext not in ALLOWED_EXTS:
            raise HTTPException(status_code=400, detail=f"File type not allowed: {ext}")

        data = await f.read()
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        fname = _safe_name(f.filename or f"image_{secrets.token_hex(3)}.{ext}")
        path = dest_dir / fname
        with open(path, "wb") as out:
            out.write(data)

        url_path = f"/uploads/ccbpm/{station_id}/{report_id}/{group}/{fname}"
        saved.append({
            "filename": fname,
            "size": len(data),
            "url": url_path,
            "remark": remark or "",
            "uploadedAt": datetime.now(timezone.utc)
        })

    await coll.update_one(
        {"_id": oid},
        {
            "$push": {f"photos.{group}": {"$each": saved}},
            "$set": {"updatedAt": datetime.now(timezone.utc)}
        }
    )
    return {"ok": True, "count": len(saved), "group": group, "files": saved}

@app.post("/ccbpmreport/{report_id}/finalize")
async def ccbpmreport_finalize(
    report_id: str,
    station_id: str = Form(...),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_ccbpmreport_collection_for(station_id)
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    # (‡∏≠‡∏≠‡∏õ‡∏ä‡∏±‡∏ô) ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏Å‡πà‡∏≠‡∏ô finalize ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
    res = await coll.update_one(
        {"_id": oid},
        {"$set": {"status": "submitted", "submittedAt": datetime.now(timezone.utc), "updatedAt": datetime.now(timezone.utc)}}
    )
    if res.matched_count == 0:
        raise HTTPException(status_code=404, detail="Report not found")
    return {"ok": True}

# -------------------------- ‡πÑ‡∏ü‡∏•‡πå PDF ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô (MDB PM URL) --------------------------

@app.post("/ccbpmurl/upload-files", status_code=201)
async def ccbpmurl_upload_files(
    station_id: str = Form(...),
    reportDate: str = Form(...),            # "YYYY-MM-DD" ‡∏´‡∏£‡∏∑‡∏≠ ISO -> ‡∏à‡∏∞ normalize ‡πÄ‡∏õ‡πá‡∏ô YYYY-MM-DD
    files: List[UploadFile] = File(...),    # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÄ‡∏â‡∏û‡∏≤‡∏∞ .pdf
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_ccbpmurl_coll_upload(station_id)
    pm_date = normalize_pm_date(reportDate)  # ‡∏Ñ‡∏∑‡∏ô YYYY-MM-DD

    # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà /uploads/mdbpmurl/<station_id>/<YYYY-MM-DD>/
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "ccbpmurl" / station_id / pm_date
    dest_dir.mkdir(parents=True, exist_ok=True)

    urls, metas = [], []
    for f in files:
        ext = (f.filename.rsplit(".",1)[-1].lower() if f.filename and "." in f.filename else "")
        if ext != "pdf":
            raise HTTPException(status_code=400, detail=f"Only PDF allowed, got: {ext}")

        data = await f.read()
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        fname = _safe_name(f.filename or f"file_{secrets.token_hex(3)}.pdf")
        path = dest_dir / fname
        with open(path, "wb") as out:
            out.write(data)

        url = f"/uploads/ccbpmurl/{station_id}/{pm_date}/{fname}"
        urls.append(url)
        metas.append({"name": f.filename, "size": len(data)})

    now = datetime.now(timezone.utc)
    res = await coll.insert_one({
        "station": station_id,
        "pm_date": pm_date,
        "urls": urls,
        "meta": {"files": metas},
        "source": "upload-files",
        "createdAt": now,
        "updatedAt": now,
    })
    return {"ok": True, "inserted_id": str(res.inserted_id), "count": len(urls), "urls": urls}

@app.get("/ccbpmurl/list")
async def ccbpmurl_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_ccbpmurl_coll_upload(station_id)
    skip = (page - 1) * pageSize

    cursor = coll.find(
        {},
        {"_id": 1, "pm_date": 1, "urls": 1, "createdAt": 1}
    ).sort([("createdAt", -1), ("_id", -1)]).skip(skip).limit(pageSize)

    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    items = []
    for it in items_raw:
        urls = it.get("urls") or []
        first_url = urls[0] if urls else ""
        items.append({
            "id": str(it["_id"]),
            "pm_date": it.get("pm_date"),
            "createdAt": _ensure_utc_iso(it.get("createdAt")),
            "file_url": first_url,
            "urls": urls,
        })

    return {"items": items, "pm_date": [i["pm_date"] for i in items if i.get("pm_date")], "page": page, "pageSize": pageSize, "total": total}

# -------------------------------------------------- PMReportPage (CCB)       
# def get_ccbpmreport_collection_for(station_id: str):
#     _validate_station_id(station_id)
#     return CCBPMReportDB.get_collection(str(station_id))

# def get_ccbpmurl_coll_upload(station_id: str):
#     _validate_station_id(station_id)
#     return CCBPMUrlDB.get_collection(str(station_id))

# class CCBPMSubmitIn(BaseModel):
#     station_id: str
#     job: Dict[str, Any]         # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô (location/date/inspector ‡∏Ø‡∏•‡∏Ø)
#     rows: Dict[str, Dict[str, Any]]  # {"r1": {"pf": "...", "remark": "..."}, ...}
#     measures: Dict[str, Dict[str, Any]]  # {"m4": {...}, "m5": {...}, ..., "m8": {...}}
#     summary: str
#     pm_date: str                # "YYYY-MM-DD"

# @app.post("/ccbpmreport/submit")
# async def ccbpmreport_submit(body: CCBPMSubmitIn, current: UserClaims = Depends(get_current_user)):
#     print("HIT /ccbpmreport/submit")  # debug
#     station_id = body.station_id.strip()
#     if current.role != "admin" and station_id not in set(current.station_ids):
#         raise HTTPException(status_code=403, detail="Forbidden station_id")

#     coll = get_ccbpmreport_collection_for(station_id)

#     # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô draft ‡∏Å‡πà‡∏≠‡∏ô
#     doc = {
#         "station_id": station_id,
#         "job": body.job,
#         "rows": body.rows,
#         "measures": body.measures,         # m4..m8
#         "summary": body.summary,
#         "pm_date": body.pm_date,           # string YYYY-MM-DD (‡∏ï‡∏≤‡∏°‡∏ü‡∏£‡∏≠‡∏ô‡∏ï‡πå)
#         "status": "draft",
#         "photos": {},                      # ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏ô /photos
#         "createdAt": datetime.now(timezone.utc),
#         "updatedAt": datetime.now(timezone.utc),
#     }

#     res = await coll.insert_one(doc)
#     return {"ok": True, "report_id": str(res.inserted_id)}

# @app.get("/ccbpmreport/list")
# async def ccbpmreport_list(
#     station_id: str = Query(...),
#     page: int = Query(1, ge=1),
#     pageSize: int = Query(20, ge=1, le=100),
#     current: UserClaims = Depends(get_current_user),
# ):
#     if current.role != "admin" and station_id not in set(current.station_ids):
#         raise HTTPException(status_code=403, detail="Forbidden station_id")

#     coll = get_ccbpmreport_collection_for(station_id)
#     skip = (page - 1) * pageSize

#     cursor = coll.find({}, {"_id": 1, "pm_date": 1, "createdAt": 1}).sort(
#         [("createdAt", -1), ("_id", -1)]
#     ).skip(skip).limit(pageSize)

#     items_raw = await cursor.to_list(length=pageSize)
#     total = await coll.count_documents({})

#     # ‡∏ú‡∏π‡∏Å URL PDF ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡∏à‡∏≤‡∏Å MDBPMUrlDB (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
#     pm_dates = [it.get("pm_date") for it in items_raw if it.get("pm_date")]
#     url_by_day: Dict[str, str] = {}
#     if pm_dates:
#         ucoll = get_ccbpmurl_coll_upload(station_id)
#         ucur = ucoll.find({"pm_date": {"$in": pm_dates}}, {"pm_date": 1, "urls": 1})
#         url_docs = await ucur.to_list(length=10_000)
#         for u in url_docs:
#             day = u.get("pm_date")
#             first_url = (u.get("urls") or [None])[0]
#             if day and first_url and day not in url_by_day:
#                 url_by_day[day] = first_url

#     items = [{
#         "id": str(it["_id"]),
#         "pm_date": it.get("pm_date"),
#         "createdAt": _ensure_utc_iso(it.get("createdAt")),
#         "file_url": url_by_day.get(it.get("pm_date") or "", ""),
#     } for it in items_raw]

#     return {"items": items, "pm_date": [it.get("pm_date") for it in items_raw if it.get("pm_date")], "page": page, "pageSize": pageSize, "total": total}

# @app.post("/ccbpmreport/{report_id}/photos")
# async def ccbpmreport_upload_photos(
#     report_id: str,
#     station_id: str = Form(...),
#     group: str = Form(...),                   # "g1" .. "g11"
#     files: List[UploadFile] = File(...),
#     remark: Optional[str] = Form(None),
#     current: UserClaims = Depends(get_current_user),
# ):
#     if current.role != "admin" and station_id not in set(current.station_ids):
#         raise HTTPException(status_code=403, detail="Forbidden station_id")
#     if not re.fullmatch(r"g\d+", group):
#         raise HTTPException(status_code=400, detail="Bad group key")

#     coll = get_ccbpmreport_collection_for(station_id)
#     try:
#         oid = ObjectId(report_id)
#     except Exception:
#         raise HTTPException(status_code=400, detail="Bad report_id")

#     doc = await coll.find_one({"_id": oid}, {"_id": 1, "station_id": 1})
#     if not doc:
#         raise HTTPException(status_code=404, detail="Report not found")
#     if doc.get("station_id") != station_id:
#         raise HTTPException(status_code=400, detail="station_id mismatch")

#     # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: /uploads/mdbpm/{station_id}/{report_id}/{group}/
#     dest_dir = pathlib.Path(UPLOADS_ROOT) / "ccbpm" / station_id / report_id / group
#     dest_dir.mkdir(parents=True, exist_ok=True)

#     saved = []
#     for f in files:
#         ext = (f.filename.rsplit(".",1)[-1].lower() if f.filename and "." in f.filename else "")
#         if ext not in ALLOWED_EXTS:
#             raise HTTPException(status_code=400, detail=f"File type not allowed: {ext}")

#         data = await f.read()
#         if len(data) > MAX_FILE_MB * 1024 * 1024:
#             raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

#         fname = _safe_name(f.filename or f"image_{secrets.token_hex(3)}.{ext}")
#         path = dest_dir / fname
#         with open(path, "wb") as out:
#             out.write(data)

#         url_path = f"/uploads/ccbpm/{station_id}/{report_id}/{group}/{fname}"
#         saved.append({
#             "filename": fname,
#             "size": len(data),
#             "url": url_path,
#             "remark": remark or "",
#             "uploadedAt": datetime.now(timezone.utc)
#         })

#     await coll.update_one(
#         {"_id": oid},
#         {
#             "$push": {f"photos.{group}": {"$each": saved}},
#             "$set": {"updatedAt": datetime.now(timezone.utc)}
#         }
#     )
#     return {"ok": True, "count": len(saved), "group": group, "files": saved}

# @app.post("/ccbpmreport/{report_id}/finalize")
# async def ccbpmreport_finalize(
#     report_id: str,
#     station_id: str = Form(...),
#     current: UserClaims = Depends(get_current_user),
# ):
#     if current.role != "admin" and station_id not in set(current.station_ids):
#         raise HTTPException(status_code=403, detail="Forbidden station_id")

#     coll = get_ccbpmreport_collection_for(station_id)
#     try:
#         oid = ObjectId(report_id)
#     except Exception:
#         raise HTTPException(status_code=400, detail="Bad report_id")

#     # (‡∏≠‡∏≠‡∏õ‡∏ä‡∏±‡∏ô) ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏Å‡πà‡∏≠‡∏ô finalize ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
#     res = await coll.update_one(
#         {"_id": oid},
#         {"$set": {"status": "submitted", "submittedAt": datetime.now(timezone.utc), "updatedAt": datetime.now(timezone.utc)}}
#     )
#     if res.matched_count == 0:
#         raise HTTPException(status_code=404, detail="Report not found")
#     return {"ok": True}

# # -------------------------- ‡πÑ‡∏ü‡∏•‡πå PDF ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô (MDB PM URL) --------------------------

# @app.post("/ccbpmurl/upload-files", status_code=201)
# async def ccbpmurl_upload_files(
#     station_id: str = Form(...),
#     reportDate: str = Form(...),            # "YYYY-MM-DD" ‡∏´‡∏£‡∏∑‡∏≠ ISO -> ‡∏à‡∏∞ normalize ‡πÄ‡∏õ‡πá‡∏ô YYYY-MM-DD
#     files: List[UploadFile] = File(...),    # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÄ‡∏â‡∏û‡∏≤‡∏∞ .pdf
#     current: UserClaims = Depends(get_current_user),
# ):
#     if current.role != "admin" and station_id not in set(current.station_ids):
#         raise HTTPException(status_code=403, detail="Forbidden station_id")

#     coll = get_ccbpmurl_coll_upload(station_id)
#     pm_date = normalize_pm_date(reportDate)  # ‡∏Ñ‡∏∑‡∏ô YYYY-MM-DD

#     # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà /uploads/mdbpmurl/<station_id>/<YYYY-MM-DD>/
#     dest_dir = pathlib.Path(UPLOADS_ROOT) / "ccbpmurl" / station_id / pm_date
#     dest_dir.mkdir(parents=True, exist_ok=True)

#     urls, metas = [], []
#     for f in files:
#         ext = (f.filename.rsplit(".",1)[-1].lower() if f.filename and "." in f.filename else "")
#         if ext != "pdf":
#             raise HTTPException(status_code=400, detail=f"Only PDF allowed, got: {ext}")

#         data = await f.read()
#         if len(data) > MAX_FILE_MB * 1024 * 1024:
#             raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

#         fname = _safe_name(f.filename or f"file_{secrets.token_hex(3)}.pdf")
#         path = dest_dir / fname
#         with open(path, "wb") as out:
#             out.write(data)

#         url = f"/uploads/ccbpmurl/{station_id}/{pm_date}/{fname}"
#         urls.append(url)
#         metas.append({"name": f.filename, "size": len(data)})

#     now = datetime.now(timezone.utc)
#     res = await coll.insert_one({
#         "station": station_id,
#         "pm_date": pm_date,
#         "urls": urls,
#         "meta": {"files": metas},
#         "source": "upload-files",
#         "createdAt": now,
#         "updatedAt": now,
#     })
#     return {"ok": True, "inserted_id": str(res.inserted_id), "count": len(urls), "urls": urls}

# @app.get("/ccbpmurl/list")
# async def ccbpmurl_list(
#     station_id: str = Query(...),
#     page: int = Query(1, ge=1),
#     pageSize: int = Query(20, ge=1, le=100),
#     current: UserClaims = Depends(get_current_user),
# ):
#     if current.role != "admin" and station_id not in set(current.station_ids):
#         raise HTTPException(status_code=403, detail="Forbidden station_id")

#     coll = get_ccbpmurl_coll_upload(station_id)
#     skip = (page - 1) * pageSize

#     cursor = coll.find(
#         {},
#         {"_id": 1, "pm_date": 1, "urls": 1, "createdAt": 1}
#     ).sort([("createdAt", -1), ("_id", -1)]).skip(skip).limit(pageSize)

#     items_raw = await cursor.to_list(length=pageSize)
#     total = await coll.count_documents({})

#     items = []
#     for it in items_raw:
#         urls = it.get("urls") or []
#         first_url = urls[0] if urls else ""
#         items.append({
#             "id": str(it["_id"]),
#             "pm_date": it.get("pm_date"),
#             "createdAt": _ensure_utc_iso(it.get("createdAt")),
#             "file_url": first_url,
#             "urls": urls,
#         })

#     return {"items": items, "pm_date": [i["pm_date"] for i in items if i.get("pm_date")], "page": page, "pageSize": pageSize, "total": total}

# -------------------------------------------------- PMReportPage (CB-BOX)       

def get_cbboxpmreport_collection_for(station_id: str):
    _validate_station_id(station_id)
    return CBBOXPMReportDB.get_collection(str(station_id))

def get_cbboxpmurl_coll_upload(station_id: str):
    _validate_station_id(station_id)
    return CBBOXPMUrlDB.get_collection(str(station_id))

class CBBOXPMSubmitIn(BaseModel):
    station_id: str
    job: Dict[str, Any]         # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô (location/date/inspector ‡∏Ø‡∏•‡∏Ø)
    rows: Dict[str, Dict[str, Any]]  # {"r1": {"pf": "...", "remark": "..."}, ...}
    measures: Dict[str, Dict[str, Any]]  # {"m4": {...}, "m5": {...}, ..., "m8": {...}}
    summary: str
    pm_date: str                # "YYYY-MM-DD"

@app.post("/cbboxpmreport/submit")
async def cbboxpmreport_submit(body: CBBOXPMSubmitIn, current: UserClaims = Depends(get_current_user)):
   
    station_id = body.station_id.strip()
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_cbboxpmreport_collection_for(station_id)

    # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô draft ‡∏Å‡πà‡∏≠‡∏ô
    doc = {
        "station_id": station_id,
        "job": body.job,
        "rows": body.rows,
        "measures": body.measures,         # m4..m8
        "summary": body.summary,
        "pm_date": body.pm_date,           # string YYYY-MM-DD (‡∏ï‡∏≤‡∏°‡∏ü‡∏£‡∏≠‡∏ô‡∏ï‡πå)
        "status": "draft",
        "photos": {},                      # ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏ô /photos
        "createdAt": datetime.now(timezone.utc),
        "updatedAt": datetime.now(timezone.utc),
    }

    res = await coll.insert_one(doc)
    return {"ok": True, "report_id": str(res.inserted_id)}

@app.get("/cbboxpmreport/list")
async def cbboxpmreport_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_cbboxpmreport_collection_for(station_id)
    skip = (page - 1) * pageSize

    cursor = coll.find({}, {"_id": 1, "pm_date": 1, "createdAt": 1}).sort(
        [("createdAt", -1), ("_id", -1)]
    ).skip(skip).limit(pageSize)

    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    # ‡∏ú‡∏π‡∏Å URL PDF ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡∏à‡∏≤‡∏Å MDBPMUrlDB (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    pm_dates = [it.get("pm_date") for it in items_raw if it.get("pm_date")]
    url_by_day: Dict[str, str] = {}
    if pm_dates:
        ucoll = get_cbboxpmurl_coll_upload(station_id)
        ucur = ucoll.find({"pm_date": {"$in": pm_dates}}, {"pm_date": 1, "urls": 1})
        url_docs = await ucur.to_list(length=10_000)
        for u in url_docs:
            day = u.get("pm_date")
            first_url = (u.get("urls") or [None])[0]
            if day and first_url and day not in url_by_day:
                url_by_day[day] = first_url

    items = [{
        "id": str(it["_id"]),
        "pm_date": it.get("pm_date"),
        "createdAt": _ensure_utc_iso(it.get("createdAt")),
        "file_url": url_by_day.get(it.get("pm_date") or "", ""),
    } for it in items_raw]

    return {"items": items, "pm_date": [it.get("pm_date") for it in items_raw if it.get("pm_date")], "page": page, "pageSize": pageSize, "total": total}

@app.post("/cbboxpmreport/{report_id}/photos")
async def cbboxpmreport_upload_photos(
    report_id: str,
    station_id: str = Form(...),
    group: str = Form(...),                   # "g1" .. "g11"
    files: List[UploadFile] = File(...),
    remark: Optional[str] = Form(None),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")
    if not re.fullmatch(r"g\d+", group):
        raise HTTPException(status_code=400, detail="Bad group key")

    coll = get_cbboxpmreport_collection_for(station_id)
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    doc = await coll.find_one({"_id": oid}, {"_id": 1, "station_id": 1})
    if not doc:
        raise HTTPException(status_code=404, detail="Report not found")
    if doc.get("station_id") != station_id:
        raise HTTPException(status_code=400, detail="station_id mismatch")

    # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: /uploads/mdbpm/{station_id}/{report_id}/{group}/
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "cbboxpm" / station_id / report_id / group
    dest_dir.mkdir(parents=True, exist_ok=True)

    saved = []
    for f in files:
        ext = (f.filename.rsplit(".",1)[-1].lower() if f.filename and "." in f.filename else "")
        if ext not in ALLOWED_EXTS:
            raise HTTPException(status_code=400, detail=f"File type not allowed: {ext}")

        data = await f.read()
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        fname = _safe_name(f.filename or f"image_{secrets.token_hex(3)}.{ext}")
        path = dest_dir / fname
        with open(path, "wb") as out:
            out.write(data)

        url_path = f"/uploads/cbboxpm/{station_id}/{report_id}/{group}/{fname}"
        saved.append({
            "filename": fname,
            "size": len(data),
            "url": url_path,
            "remark": remark or "",
            "uploadedAt": datetime.now(timezone.utc)
        })

    await coll.update_one(
        {"_id": oid},
        {
            "$push": {f"photos.{group}": {"$each": saved}},
            "$set": {"updatedAt": datetime.now(timezone.utc)}
        }
    )
    return {"ok": True, "count": len(saved), "group": group, "files": saved}

@app.post("/cbboxpmreport/{report_id}/finalize")
async def cbboxpmreport_finalize(
    report_id: str,
    station_id: str = Form(...),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_cbboxpmreport_collection_for(station_id)
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    # (‡∏≠‡∏≠‡∏õ‡∏ä‡∏±‡∏ô) ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏Å‡πà‡∏≠‡∏ô finalize ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
    res = await coll.update_one(
        {"_id": oid},
        {"$set": {"status": "submitted", "submittedAt": datetime.now(timezone.utc), "updatedAt": datetime.now(timezone.utc)}}
    )
    if res.matched_count == 0:
        raise HTTPException(status_code=404, detail="Report not found")
    return {"ok": True}

# -------------------------- ‡πÑ‡∏ü‡∏•‡πå PDF ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô (MDB PM URL) --------------------------

@app.post("/cbboxpmurl/upload-files", status_code=201)
async def cbboxpmurl_upload_files(
    station_id: str = Form(...),
    reportDate: str = Form(...),            # "YYYY-MM-DD" ‡∏´‡∏£‡∏∑‡∏≠ ISO -> ‡∏à‡∏∞ normalize ‡πÄ‡∏õ‡πá‡∏ô YYYY-MM-DD
    files: List[UploadFile] = File(...),    # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÄ‡∏â‡∏û‡∏≤‡∏∞ .pdf
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_cbboxpmurl_coll_upload(station_id)
    pm_date = normalize_pm_date(reportDate)  # ‡∏Ñ‡∏∑‡∏ô YYYY-MM-DD

    # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà /uploads/mdbpmurl/<station_id>/<YYYY-MM-DD>/
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "cbboxpmurl" / station_id / pm_date
    dest_dir.mkdir(parents=True, exist_ok=True)

    urls, metas = [], []
    for f in files:
        ext = (f.filename.rsplit(".",1)[-1].lower() if f.filename and "." in f.filename else "")
        if ext != "pdf":
            raise HTTPException(status_code=400, detail=f"Only PDF allowed, got: {ext}")

        data = await f.read()
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        fname = _safe_name(f.filename or f"file_{secrets.token_hex(3)}.pdf")
        path = dest_dir / fname
        with open(path, "wb") as out:
            out.write(data)

        url = f"/uploads/cbboxpmurl/{station_id}/{pm_date}/{fname}"
        urls.append(url)
        metas.append({"name": f.filename, "size": len(data)})

    now = datetime.now(timezone.utc)
    res = await coll.insert_one({
        "station": station_id,
        "pm_date": pm_date,
        "urls": urls,
        "meta": {"files": metas},
        "source": "upload-files",
        "createdAt": now,
        "updatedAt": now,
    })
    return {"ok": True, "inserted_id": str(res.inserted_id), "count": len(urls), "urls": urls}

@app.get("/cbboxpmurl/list")
async def cbboxpmurl_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_cbboxpmurl_coll_upload(station_id)
    skip = (page - 1) * pageSize

    cursor = coll.find(
        {},
        {"_id": 1, "pm_date": 1, "urls": 1, "createdAt": 1}
    ).sort([("createdAt", -1), ("_id", -1)]).skip(skip).limit(pageSize)

    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    items = []
    for it in items_raw:
        urls = it.get("urls") or []
        first_url = urls[0] if urls else ""
        items.append({
            "id": str(it["_id"]),
            "pm_date": it.get("pm_date"),
            "createdAt": _ensure_utc_iso(it.get("createdAt")),
            "file_url": first_url,
            "urls": urls,
        })

    return {"items": items, "pm_date": [i["pm_date"] for i in items if i.get("pm_date")], "page": page, "pageSize": pageSize, "total": total}



# -------------------------------------------------- PMReportPage (station)       
def get_stationpmreport_collection_for(station_id: str):
    _validate_station_id(station_id)
    return stationPMReportDB.get_collection(str(station_id))

def get_stationpmurl_coll_upload(station_id: str):
    _validate_station_id(station_id)
    return stationPMUrlDB.get_collection(str(station_id))

class stationPMSubmitIn(BaseModel):
    station_id: str
    job: Dict[str, Any]         # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô (location/date/inspector ‡∏Ø‡∏•‡∏Ø)
    rows: Dict[str, Dict[str, Any]]  # {"r1": {"pf": "...", "remark": "..."}, ...}
    # measures: Dict[str, Dict[str, Any]]  # {"m4": {...}, "m5": {...}, ..., "m8": {...}}
    summary: str
    pm_date: str                # "YYYY-MM-DD"

@app.post("/stationpmreport/submit")
async def stationpmreport_submit(body: stationPMSubmitIn, current: UserClaims = Depends(get_current_user)):
    print("HIT /stationpmreport/submit")  # debug
    station_id = body.station_id.strip()
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_stationpmreport_collection_for(station_id)

    # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô draft ‡∏Å‡πà‡∏≠‡∏ô
    doc = {
        "station_id": station_id,
        "job": body.job,
        "rows": body.rows,
        # "measures": body.measures,         # m4..m8
        "summary": body.summary,
        "pm_date": body.pm_date,           # string YYYY-MM-DD (‡∏ï‡∏≤‡∏°‡∏ü‡∏£‡∏≠‡∏ô‡∏ï‡πå)
        "status": "draft",
        "photos": {},                      # ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏ô /photos
        "createdAt": datetime.now(timezone.utc),
        "updatedAt": datetime.now(timezone.utc),
    }

    res = await coll.insert_one(doc)
    return {"ok": True, "report_id": str(res.inserted_id)}

@app.get("/stationpmreport/list")
async def ccbpmreport_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_stationpmreport_collection_for(station_id)
    skip = (page - 1) * pageSize

    cursor = coll.find({}, {"_id": 1, "pm_date": 1, "createdAt": 1}).sort(
        [("createdAt", -1), ("_id", -1)]
    ).skip(skip).limit(pageSize)

    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    # ‡∏ú‡∏π‡∏Å URL PDF ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡∏à‡∏≤‡∏Å MDBPMUrlDB (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    pm_dates = [it.get("pm_date") for it in items_raw if it.get("pm_date")]
    url_by_day: Dict[str, str] = {}
    if pm_dates:
        ucoll = get_stationpmurl_coll_upload(station_id)
        ucur = ucoll.find({"pm_date": {"$in": pm_dates}}, {"pm_date": 1, "urls": 1})
        url_docs = await ucur.to_list(length=10_000)
        for u in url_docs:
            day = u.get("pm_date")
            first_url = (u.get("urls") or [None])[0]
            if day and first_url and day not in url_by_day:
                url_by_day[day] = first_url

    items = [{
        "id": str(it["_id"]),
        "pm_date": it.get("pm_date"),
        "createdAt": _ensure_utc_iso(it.get("createdAt")),
        "file_url": url_by_day.get(it.get("pm_date") or "", ""),
    } for it in items_raw]

    return {"items": items, "pm_date": [it.get("pm_date") for it in items_raw if it.get("pm_date")], "page": page, "pageSize": pageSize, "total": total}

@app.post("/stationpmreport/{report_id}/photos")
async def stationpmreport_upload_photos(
    report_id: str,
    station_id: str = Form(...),
    group: str = Form(...),                   # "g1" .. "g11"
    files: List[UploadFile] = File(...),
    remark: Optional[str] = Form(None),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")
    if not re.fullmatch(r"g\d+", group):
        raise HTTPException(status_code=400, detail="Bad group key")

    coll = get_stationpmreport_collection_for(station_id)
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    doc = await coll.find_one({"_id": oid}, {"_id": 1, "station_id": 1})
    if not doc:
        raise HTTPException(status_code=404, detail="Report not found")
    if doc.get("station_id") != station_id:
        raise HTTPException(status_code=400, detail="station_id mismatch")

    # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: /uploads/mdbpm/{station_id}/{report_id}/{group}/
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "stationpm" / station_id / report_id / group
    dest_dir.mkdir(parents=True, exist_ok=True)

    saved = []
    for f in files:
        ext = (f.filename.rsplit(".",1)[-1].lower() if f.filename and "." in f.filename else "")
        if ext not in ALLOWED_EXTS:
            raise HTTPException(status_code=400, detail=f"File type not allowed: {ext}")

        data = await f.read()
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        fname = _safe_name(f.filename or f"image_{secrets.token_hex(3)}.{ext}")
        path = dest_dir / fname
        with open(path, "wb") as out:
            out.write(data)

        url_path = f"/uploads/stationpm/{station_id}/{report_id}/{group}/{fname}"
        saved.append({
            "filename": fname,
            "size": len(data),
            "url": url_path,
            "remark": remark or "",
            "uploadedAt": datetime.now(timezone.utc)
        })

    await coll.update_one(
        {"_id": oid},
        {
            "$push": {f"photos.{group}": {"$each": saved}},
            "$set": {"updatedAt": datetime.now(timezone.utc)}
        }
    )
    return {"ok": True, "count": len(saved), "group": group, "files": saved}

@app.post("/stationpmreport/{report_id}/finalize")
async def stationpmreport_finalize(
    report_id: str,
    station_id: str = Form(...),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_stationpmreport_collection_for(station_id)
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    # (‡∏≠‡∏≠‡∏õ‡∏ä‡∏±‡∏ô) ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏Å‡πà‡∏≠‡∏ô finalize ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
    res = await coll.update_one(
        {"_id": oid},
        {"$set": {"status": "submitted", "submittedAt": datetime.now(timezone.utc), "updatedAt": datetime.now(timezone.utc)}}
    )
    if res.matched_count == 0:
        raise HTTPException(status_code=404, detail="Report not found")
    return {"ok": True}

# -------------------------- ‡πÑ‡∏ü‡∏•‡πå PDF ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô (MDB PM URL) --------------------------

@app.post("/stationpmurl/upload-files", status_code=201)
async def stationmurl_upload_files(
    station_id: str = Form(...),
    reportDate: str = Form(...),            # "YYYY-MM-DD" ‡∏´‡∏£‡∏∑‡∏≠ ISO -> ‡∏à‡∏∞ normalize ‡πÄ‡∏õ‡πá‡∏ô YYYY-MM-DD
    files: List[UploadFile] = File(...),    # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÄ‡∏â‡∏û‡∏≤‡∏∞ .pdf
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_stationpmurl_coll_upload(station_id)
    pm_date = normalize_pm_date(reportDate)  # ‡∏Ñ‡∏∑‡∏ô YYYY-MM-DD

    # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà /uploads/mdbpmurl/<station_id>/<YYYY-MM-DD>/
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "stationpmurl" / station_id / pm_date
    dest_dir.mkdir(parents=True, exist_ok=True)

    urls, metas = [], []
    for f in files:
        ext = (f.filename.rsplit(".",1)[-1].lower() if f.filename and "." in f.filename else "")
        if ext != "pdf":
            raise HTTPException(status_code=400, detail=f"Only PDF allowed, got: {ext}")

        data = await f.read()
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        fname = _safe_name(f.filename or f"file_{secrets.token_hex(3)}.pdf")
        path = dest_dir / fname
        with open(path, "wb") as out:
            out.write(data)

        url = f"/uploads/stationpmurl/{station_id}/{pm_date}/{fname}"
        urls.append(url)
        metas.append({"name": f.filename, "size": len(data)})

    now = datetime.now(timezone.utc)
    res = await coll.insert_one({
        "station": station_id,
        "pm_date": pm_date,
        "urls": urls,
        "meta": {"files": metas},
        "source": "upload-files",
        "createdAt": now,
        "updatedAt": now,
    })
    return {"ok": True, "inserted_id": str(res.inserted_id), "count": len(urls), "urls": urls}

@app.get("/stationpmurl/list")
async def stationpmurl_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_stationpmurl_coll_upload(station_id)
    skip = (page - 1) * pageSize

    cursor = coll.find(
        {},
        {"_id": 1, "pm_date": 1, "urls": 1, "createdAt": 1}
    ).sort([("createdAt", -1), ("_id", -1)]).skip(skip).limit(pageSize)

    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    items = []
    for it in items_raw:
        urls = it.get("urls") or []
        first_url = urls[0] if urls else ""
        items.append({
            "id": str(it["_id"]),
            "pm_date": it.get("pm_date"),
            "createdAt": _ensure_utc_iso(it.get("createdAt")),
            "file_url": first_url,
            "urls": urls,
        })

    return {"items": items, "pm_date": [i["pm_date"] for i in items if i.get("pm_date")], "page": page, "pageSize": pageSize, "total": total}


#---------------------------------------------------------------------- CM Report
def get_cmreport_collection_for(station_id: str):
    _validate_station_id(station_id)
    coll = CMReportDB.get_collection(str(station_id))
    return coll

def get_cmurl_coll_upload(station_id: str):
    _validate_station_id(station_id)
    coll = CMUrlDB.get_collection(str(station_id))
    return coll

@app.get("/cmreport/list")
async def cmreport_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
):
    coll = get_cmreport_collection_for(station_id)
    skip = (page - 1) * pageSize

    cursor = coll.find({}, {"_id": 1, "cm_date": 1, "status": 1, "createdAt": 1}).sort(
        [("createdAt", -1), ("_id", -1)]
    ).skip(skip).limit(pageSize)
    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    # --- ‡∏î‡∏∂‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å PMReportURL ‡πÇ‡∏î‡∏¢ map ‡∏î‡πâ‡∏ß‡∏¢ pm_date (string) ---
    cm_dates = [it.get("cm_date") for it in items_raw if it.get("cm_date")]
    urls_coll = get_cmurl_coll_upload(station_id)
    url_by_day: dict[str, str] = {}

    if cm_dates:
        ucur = urls_coll.find({"cm_date": {"$in": cm_dates}}, {"cm_date": 1, "status": 1, "urls": 1})
        url_docs = await ucur.to_list(length=10_000)
        for u in url_docs:
            day = u.get("cm_date")
            first_url = (u.get("urls") or [None])[0]
            if day and first_url and day not in url_by_day:
                url_by_day[day] = first_url

    items = [{
        "id": str(it["_id"]),
        "cm_date": it.get("cm_date"),
        "status": it.get("status"),
        "createdAt": _ensure_utc_iso(it.get("createdAt")),
        "file_url": url_by_day.get(it.get("cm_date") or "", ""),
    } for it in items_raw]

    cm_date_arr = [it.get("cm_date") for it in items_raw if it.get("cm_date")]
    status_arr = [it.get("status") for it in items_raw if it.get("status")]
    return {"items": items, "cm_date": cm_date_arr, "status": status_arr, "page": page, "pageSize": pageSize, "total": total}

# ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
UPLOADS_ROOT = os.getenv("UPLOADS_ROOT", "./uploads")
os.makedirs(UPLOADS_ROOT, exist_ok=True)

# ‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏∑‡∏ô‡πÉ‡∏´‡πâ Frontend ‡∏ú‡πà‡∏≤‡∏ô /uploads/...
app.mount("/uploads", StaticFiles(directory=UPLOADS_ROOT, html=False), name="uploads")

# ALLOWED_EXTS = {"jpg","jpeg","png","webp","gif"}
# MAX_FILE_MB = 10

def _safe_name(name: str) -> str:
    # ‡∏Å‡∏±‡∏ô path traversal ‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡πÅ‡∏õ‡∏•‡∏Å ‡πÜ
    base = re.sub(r"[^A-Za-z0-9._-]+", "_", name)
    return base[:120] or secrets.token_hex(4)

def _ext(fname: str) -> str:
    return (fname.rsplit(".",1)[-1].lower() if "." in fname else "")

@app.post("/cmreport/{report_id}/photos")
async def cmreport_upload_photos(
    report_id: str,
    station_id: str = Form(...),
    group: str = Form(...),                   # ‡πÄ‡∏ä‡πà‡∏ô "g1" .. "g10"
    files: list[UploadFile] = File(...),
    remark: str | None = Form(None),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")
    if not re.fullmatch(r"g\d+", group):
        raise HTTPException(status_code=400, detail="Bad group key")

    coll = get_cmreport_collection_for(station_id)
    from bson import ObjectId
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    # ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ß‡πà‡∏≤‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô station ‡∏ô‡∏µ‡πâ
    doc = await coll.find_one({"_id": oid}, {"_id":1, "station_id":1})
    if not doc:
        raise HTTPException(status_code=404, detail="Report not found")
    if doc.get("station_id") != station_id:
        raise HTTPException(status_code=400, detail="station_id mismatch")

    # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "cm" / station_id / report_id / group
    dest_dir.mkdir(parents=True, exist_ok=True)

    saved = []
    total = 0
    for f in files:
        ext = _ext(f.filename or "")
        if ext not in ALLOWED_EXTS:
            raise HTTPException(status_code=400, detail=f"File type not allowed: {ext}")

        data = await f.read()
        total += len(data)
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        fname = _safe_name(f.filename or f"image_{secrets.token_hex(3)}.{ext}")
        path = dest_dir / fname
        with open(path, "wb") as out:
            out.write(data)

        # URL ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ô Frontend
        url_path = f"/uploads/cm/{station_id}/{report_id}/{group}/{fname}"
        saved.append({
            "filename": fname,
            "size": len(data),
            "url": url_path,
            "remark": remark or "",
            "uploadedAt": datetime.now(timezone.utc)
        })

    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ PMReport: push ‡∏•‡∏á photos.<group>
    await coll.update_one(
        {"_id": oid},
        {"$push": {f"photos.{group}": {"$each": saved}}}
    )

    return {"ok": True, "count": len(saved), "group": group, "files": saved}

@app.post("/cmreport/{report_id}/finalize")
async def cmreport_finalize(
    report_id: str,
    station_id: str = Form(...),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_cmreport_collection_for(station_id)
    from bson import ObjectId
    oid = ObjectId(report_id)
    res = await coll.update_one(
        {"_id": oid},
        {"$set": {"status": "submitted", "submittedAt": datetime.now(timezone.utc)}}
    )
    if res.matched_count == 0:
        raise HTTPException(status_code=404, detail="Report not found")
    return {"ok": True}

@app.post("/cmurl/upload-files", status_code=201)
async def cmurl_upload_files(
    station_id: str = Form(...),
    reportDate: str = Form(...),                 # "YYYY-MM-DD" ‡∏´‡∏£‡∏∑‡∏≠ ISO
    files: list[UploadFile] = File(...),
    status: str = Form(...),  
    current: UserClaims = Depends(get_current_user),
):
    # auth
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    # ‡∏ï‡∏£‡∏ß‡∏à/‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô
    coll = get_cmurl_coll_upload(station_id)

    # parse ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô UTC datetime (‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß)
    cm_date = normalize_pm_date(reportDate)

    # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á: /uploads/pmurl/<station_id>/<YYYY-MM-DD>/
    # subdir = report_dt_utc.astimezone(th_tz).date().isoformat()
    subdir = cm_date
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "cmurl" / station_id / subdir
    dest_dir.mkdir(parents=True, exist_ok=True)

    urls = []
    metas = []
    total_size = 0

    for f in files:
        ext = (f.filename.rsplit(".",1)[-1].lower() if "." in f.filename else "")
        if ext not in ALLOWED_EXTS or ext != "pdf":
            raise HTTPException(status_code=400, detail=f"Only PDF allowed, got: {ext}")

        data = await f.read()
        total_size += len(data)
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        safe = _safe_name(f.filename or f"file_{secrets.token_hex(3)}.pdf")
        dest = dest_dir / safe
        with open(dest, "wb") as out:
            out.write(data)

        url = f"/uploads/cmurl/{station_id}/{subdir}/{safe}"   # ‚Üê ‡∏à‡∏∞‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å StaticFiles ‡∏ó‡∏µ‡πà mount ‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß
        urls.append(url)
        metas.append({"name": f.filename, "size": len(data)})

    now = datetime.now(timezone.utc)

    doc = {
        "station": station_id,
        "cm_date": cm_date,
        "status": (status or "").strip(), 
        "urls": urls,
        "meta": {"files": metas},
        "source": "upload-files",
        "createdAt": now,
        "updatedAt": now,
    }
    res = await coll.insert_one(doc)

    return {"ok": True, "inserted_id": str(res.inserted_id), "count": len(urls), "urls": urls}

@app.get("/cmurl/list")
async def cmurl_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
    status: str | None = Query(None),
):
    coll = get_cmurl_coll_upload(station_id)
    skip = (page - 1) * pageSize

    # --- ‡∏™‡∏£‡πâ‡∏≤‡∏á filter ‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ (optional ‡πÅ‡∏ï‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥) ---
    mongo_filter: dict = {}
    if status:
        want = (status or "").strip()
        mongo_filter["$or"] = [
            {"status": {"$regex": f"^{re.escape(want)}$", "$options": "i"}},
            {"job.status": {"$regex": f"^{re.escape(want)}$", "$options": "i"}},
        ]

    # --- ‡∏Ç‡∏≠‡∏ü‡∏¥‡∏•‡∏î‡πå status ‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢ ---
    projection = {
        "_id": 1, "cm_date": 1, "reportDate": 1,
        "urls": 1, "createdAt": 1,
        "status": 1, "job": 1,   # üëà ‡πÄ‡∏û‡∏¥‡πà‡∏°
    }

    cursor = (
        coll.find(mongo_filter, projection)
            .sort([("createdAt", -1), ("_id", -1)])
            .skip(skip)
            .limit(pageSize)
    )

    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents(mongo_filter)

    def _cm_date_from(doc: dict) -> str | None:
        s = doc.get("cm_date")
        if isinstance(s, str) and re.fullmatch(r"\d{4}-\d{2}-\d{2}$", s):
            return s
        rd = doc.get("reportDate")
        if isinstance(rd, datetime):
            return rd.astimezone(th_tz).date().isoformat()
        if isinstance(rd, str):
            try:
                dt = datetime.fromisoformat(rd.replace("Z", "+00:00"))
            except Exception:
                try:
                    dt = datetime.fromisoformat(rd).replace(tzinfo=th_tz)
                except Exception:
                    return None
            return dt.astimezone(th_tz).date().isoformat()
        return None

    items = []
    cm_date_arr = []

    for it in items_raw:
        cm_date_str = _cm_date_from(it)
        if cm_date_str:
            cm_date_arr.append(cm_date_str)

        urls = it.get("urls") or []
        first_url = urls[0] if urls else ""

        items.append({
            "id": str(it["_id"]),
            "cm_date": cm_date_str,
            "createdAt": _ensure_utc_iso(it.get("createdAt")),
            "status": (it.get("status") or (it.get("job") or {}).get("status") or ""),  # üëà ‡∏î‡∏∂‡∏á‡∏ï‡∏£‡∏á‡πÜ
            "file_url": first_url,
            "urls": urls,
        })

    return {
        "items": items,
        "cm_date": [d for d in cm_date_arr if d],
        # ‡∏à‡∏∞ echo ‡∏Ñ‡πà‡∏≤ query ‡∏Å‡∏•‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡πá‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô:
        # "status": (status or "").strip(),
        "page": page,
        "pageSize": pageSize,
        "total": total,
    }


class CMSubmitIn(BaseModel):
    station_id: str
    job: Dict[str, Any]          # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏°‡∏ü‡∏≠‡∏£‡πå‡∏° (issue_id, found_date, ... )
    summary: str = ""            # ‡∏™‡∏£‡∏∏‡∏õ/‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡πÅ‡∏ö‡∏ö‡∏¢‡∏≤‡∏ß (‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ)
    cm_date: Optional[str] = None  # "YYYY-MM-DD" ‡∏´‡∏£‡∏∑‡∏≠ ISO; ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏à‡∏∞ fallback ‡πÄ‡∏õ‡πá‡∏ô job.found_date

async def _ensure_cm_indexes(coll):
    try:
        await coll.create_index([("createdAt", -1), ("_id", -1)])
        # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏±‡∏ô‡∏ã‡πâ‡∏≥‡πÄ‡∏•‡∏Ç‡πÉ‡∏ö‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ: ‡πÄ‡∏õ‡∏¥‡∏î unique issue_id ‡∏Å‡πá‡πÑ‡∏î‡πâ (‡∏ñ‡πâ‡∏≤‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤ unique)
        # await coll.create_index("issue_id", unique=True, sparse=True)
    except Exception:
        pass

@app.post("/cmreport/submit")
async def cmreport_submit(body: CMSubmitIn, current: UserClaims = Depends(get_current_user)):
    station_id = body.station_id.strip()
    # Auth: admin ‡∏ú‡πà‡∏≤‡∏ô‡∏´‡∏°‡∏î, ‡∏Ñ‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÉ‡∏ô station ‡∏ô‡∏µ‡πâ
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_cmreport_collection_for(station_id)
    await _ensure_cm_indexes(coll)

    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î cm_date (string 'YYYY-MM-DD') ‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á /cmreport/list
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏°‡∏≤ ‚Üí ‡πÉ‡∏ä‡πâ job.found_date ‚Üí ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏µ‡∏Å ‚Üí ‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ (‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢)
    cm_date_src = body.cm_date or body.job.get("found_date")
    if cm_date_src:
        cm_date = normalize_pm_date(cm_date_src)   # ‡∏Ñ‡∏∑‡∏ô "YYYY-MM-DD"
    else:
        cm_date = datetime.now(th_tz).date().isoformat()

    doc = {
        "station_id": station_id,
        "cm_date": cm_date,
        "job": body.job,              # ‡πÄ‡∏Å‡πá‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏Å‡πâ‡∏≠‡∏ô (issue_id, severity, etc.)
        "summary": body.summary,
        "issue_id": body.job.get("issue_id"),
        "status": body.job.get("status", "Open"),      # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏≠‡∏¢‡∏≤‡∏Å query
        "createdAt": datetime.now(timezone.utc),
        "updatedAt": datetime.now(timezone.utc),
        "photos": {},                 # ‡∏£‡∏π‡∏õ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ï‡∏¥‡∏°‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏µ‡πà /cmreport/{report_id}/photos
    }

    res = await coll.insert_one(doc)
    return {"ok": True, "report_id": str(res.inserted_id)}


@app.get("/cmreport/{report_id}")
async def cmreport_detail_path(
    report_id: str,
    station_id: str = Query(...),
    current: UserClaims = Depends(get_current_user),
):
    # auth
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_cmreport_collection_for(station_id)
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    doc = await coll.find_one({"_id": oid, "station_id": station_id})
    if not doc:
        raise HTTPException(status_code=404, detail="Report not found")

    return {
        "id": str(doc["_id"]),
        "station_id": doc.get("station_id"),
        "cm_date": doc.get("cm_date"),
        "issue_id": doc.get("issue_id"),
        "status": doc.get("status"),
        "summary": doc.get("summary", ""),
        "job": doc.get("job", {}),
        "photos": doc.get("photos", {}),
        "createdAt": _ensure_utc_iso(doc.get("createdAt")),
        "updatedAt": _ensure_utc_iso(doc.get("updatedAt")),
    }

@app.get("/cmreport/detail")
async def cmreport_detail_query(
    id: str = Query(..., alias="id"),
    station_id: str = Query(...),
    current: UserClaims = Depends(get_current_user),
):
    return await cmreport_detail_path(id, station_id, current)  # reuse logic

class CMStatusUpdateIn(BaseModel):
    station_id: str
    status: Literal["Open", "In Progress", "Closed"]
    job: Optional[Dict[str, Any]] = None
    summary: Optional[str] = None
    cm_date: Optional[str] = None  # "YYYY-MM-DD" ‡∏´‡∏£‡∏∑‡∏≠ ISO

ALLOWED_STATUS: set[str] = {"Open", "In Progress", "Closed"}

@app.patch("/cmreport/{report_id}/status")
async def cmreport_update_status(
    report_id: str,
    body: CMStatusUpdateIn,
    current: UserClaims = Depends(get_current_user),
):
    station_id = body.station_id.strip()
    if body.status not in ALLOWED_STATUS:
        raise HTTPException(status_code=400, detail="Invalid status")

    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_cmreport_collection_for(station_id)
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    updates: Dict[str, Any] = {
        "status": body.status,          # top-level
        "job.status": body.status,      # sync ‡πÉ‡∏ô job
    }

    if body.summary is not None:
        updates["summary"] = body.summary

    if body.cm_date is not None:
        updates["cm_date"] = normalize_pm_date(body.cm_date)

    if body.job is not None:
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏à‡∏≤‡∏Å‡∏ü‡∏≠‡∏£‡πå‡∏°
        allowed_job_keys = {
            "issue_id","found_date","location","wo","sn",
            "equipment_list","problem_details","problem_type","severity",
            "reported_by","assignee","initial_cause","corrective_actions",
            "resolved_date","repair_result","preventive_action","remarks"
        }
        # ‡∏ñ‡πâ‡∏≤ job.status ‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡∏°‡∏≤ ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡πÅ‡∏•‡∏∞ sync
        if "status" in body.job:
            js = body.job["status"]
            if js not in ALLOWED_STATUS:
                raise HTTPException(status_code=400, detail="Invalid job.status")
            updates["status"] = js
            updates["job.status"] = js

        for k, v in body.job.items():
            if k in allowed_job_keys:
                updates[f"job.{k}"] = v

        # optional: sync cm_date ‡∏à‡∏≤‡∏Å found_date
        if "found_date" in body.job and body.job.get("found_date"):
            try:
                updates.setdefault("cm_date", normalize_pm_date(body.job["found_date"]))
            except Exception:
                pass

    updates["updatedAt"] = datetime.now(timezone.utc)

    res = await coll.update_one({"_id": oid, "station_id": station_id}, {"$set": updates})
    if res.matched_count == 0:
        raise HTTPException(status_code=404, detail="Report not found")

    return {"ok": True, "status": updates["status"]}
#---------------------------------------------------------------------- Test Report (DC)
def get_dc_testreport_collection_for(station_id: str):
    _validate_station_id(station_id)
    coll = DCTestReportDB.get_collection(str(station_id))
    return coll

def get_dcurl_coll_upload(station_id: str):
    _validate_station_id(station_id)
    coll = DCUrlDB.get_collection(str(station_id))
    return coll

@app.get("/dctestreport/list")
async def dctestreport_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
):
    coll = get_dc_testreport_collection_for(station_id)
    skip = (page - 1) * pageSize

    cursor = coll.find({}, {"_id": 1, "inspection_date": 1, "createdAt": 1}).sort(
        [("createdAt", -1), ("_id", -1)]
    ).skip(skip).limit(pageSize)
    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    # --- ‡∏î‡∏∂‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å PMReportURL ‡πÇ‡∏î‡∏¢ map ‡∏î‡πâ‡∏ß‡∏¢ pm_date (string) ---
    dc_dates = [it.get("inspection_date") for it in items_raw if it.get("inspection_date")]
    urls_coll = get_dcurl_coll_upload(station_id)
    url_by_day: dict[str, str] = {}

    if dc_dates:
        ucur = urls_coll.find({"inspection_date": {"$in": dc_dates}}, {"inspection_date": 1, "urls": 1})
        url_docs = await ucur.to_list(length=10_000)
        for u in url_docs:
            day = u.get("inspection_date")
            first_url = (u.get("urls") or [None])[0]
            if day and first_url and day not in url_by_day:
                url_by_day[day] = first_url

    items = [{
        "id": str(it["_id"]),
        "inspection_date": it.get("inspection_date"),
        "createdAt": _ensure_utc_iso(it.get("createdAt")),
        "file_url": url_by_day.get(it.get("inspection_date") or "", ""),
    } for it in items_raw]

    dc_date_arr = [it.get("inspection_date") for it in items_raw if it.get("inspection_date")]
    # status_arr = [it.get("status") for it in items_raw if it.get("status")]
    return {"items": items, "inspection_date": dc_date_arr, "page": page, "pageSize": pageSize, "total": total}

# ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
UPLOADS_ROOT = os.getenv("UPLOADS_ROOT", "./uploads")
os.makedirs(UPLOADS_ROOT, exist_ok=True)

# ‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏∑‡∏ô‡πÉ‡∏´‡πâ Frontend ‡∏ú‡πà‡∏≤‡∏ô /uploads/...
app.mount("/uploads", StaticFiles(directory=UPLOADS_ROOT, html=False), name="uploads")

# ALLOWED_EXTS = {"jpg","jpeg","png","webp","gif"}
# MAX_FILE_MB = 10

def _safe_name(name: str) -> str:
    # ‡∏Å‡∏±‡∏ô path traversal ‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡πÅ‡∏õ‡∏•‡∏Å ‡πÜ
    base = re.sub(r"[^A-Za-z0-9._-]+", "_", name)
    return base[:120] or secrets.token_hex(4)

def _ext(fname: str) -> str:
    return (fname.rsplit(".",1)[-1].lower() if "." in fname else "")

# ---- config ‡πÑ‡∏ü‡∏•‡πå/‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡∏ß‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô) ----
ALLOWED_IMAGE_EXTS = {"jpg", "jpeg", "png", "webp", "gif"}
MAX_IMAGE_FILE_MB = 10

PHOTO_GROUP_KEYS = [
    "nameplate",       # index 0
    "charger",         # index 1
    "circuit_breaker", # index 2
    "rcd",             # index 3
    "gun1",            # index 4
    "gun2",            # index 5
]

def _key_for_index(i: int) -> str:
    return PHOTO_GROUP_KEYS[i] if 0 <= i < len(PHOTO_GROUP_KEYS) else f"extra{i-5}"


# @app.post("/dctestreport/{report_id}/photos")
# async def dc_testreport_upload_photos(
#     report_id: str,
#     station_id: str = Form(...),
#     group: str = Form(...),                   # ‡πÄ‡∏ä‡πà‡∏ô "g1" .. "g10"
#     files: list[UploadFile] = File(...),
#     remark: str | None = Form(None),
#     current: UserClaims = Depends(get_current_user),
# ):
#     if current.role != "admin" and station_id not in set(current.station_ids):
#         raise HTTPException(status_code=403, detail="Forbidden station_id")
#     if not re.fullmatch(r"g\d+", group):
#         raise HTTPException(status_code=400, detail="Bad group key")

#     coll = get_dc_testreport_collection_for(station_id)
#     from bson import ObjectId
#     try:
#         oid = ObjectId(report_id)
#     except Exception:
#         raise HTTPException(status_code=400, detail="Bad report_id")

#     # ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ß‡πà‡∏≤‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô station ‡∏ô‡∏µ‡πâ
#     doc = await coll.find_one({"_id": oid}, {"_id":1, "station_id":1})
#     if not doc:
#         raise HTTPException(status_code=404, detail="Report not found")
#     if doc.get("station_id") != station_id:
#         raise HTTPException(status_code=400, detail="station_id mismatch")

#     # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á
#     dest_dir = pathlib.Path(UPLOADS_ROOT) / "dctest" / station_id / report_id / group
#     dest_dir.mkdir(parents=True, exist_ok=True)

#     saved = []
#     total = 0
#     for f in files:
#         ext = _ext(f.filename or "")
#         if ext not in ALLOWED_EXTS:
#             raise HTTPException(status_code=400, detail=f"File type not allowed: {ext}")

#         data = await f.read()
#         total += len(data)
#         if len(data) > MAX_FILE_MB * 1024 * 1024:
#             raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

#         fname = _safe_name(f.filename or f"image_{secrets.token_hex(3)}.{ext}")
#         path = dest_dir / fname
#         with open(path, "wb") as out:
#             out.write(data)

#         # URL ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ô Frontend
#         url_path = f"/uploads/dctest/{station_id}/{report_id}/{group}/{fname}"
#         saved.append({
#             "filename": fname,
#             "size": len(data),
#             "url": url_path,
#             "remark": remark or "",
#             "uploadedAt": datetime.now(timezone.utc)
#         })

#     # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ PMReport: push ‡∏•‡∏á photos.<group>
#     await coll.update_one(
#         {"_id": oid},
#         {"$push": {f"photos.{group}": {"$each": saved}}}
#     )

#     return {"ok": True, "count": len(saved), "group": group, "files": saved}

@app.post("/dctestreport/{report_id}/photos")
async def dc_testreport_upload_photos(
    report_id: str,
    station_id: str = Form(...),
    item_index: int = Form(...),               # <<-- ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å group ‚Üí index
    files: list[UploadFile] = File(...),
    remark: str | None = Form(None),
    current: UserClaims = Depends(get_current_user),
):
    # auth
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    # ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ô‡∏µ‡πâ
    coll = get_dc_testreport_collection_for(station_id)
    from bson import ObjectId
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    doc = await coll.find_one({"_id": oid}, {"_id": 1, "station_id": 1})
    if not doc:
        raise HTTPException(status_code=404, detail="Report not found")
    if doc.get("station_id") != station_id:
        raise HTTPException(status_code=400, detail="station_id mismatch")

    # ‡πÅ‡∏õ‡∏•‡∏á index ‚Üí ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏µ‡∏¢‡πå‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå/‡∏Ñ‡∏µ‡∏¢‡πå‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
    key = _key_for_index(item_index)  # e.g. nameplate/charger/.../extra1

    # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "dctest" / station_id / report_id / key
    dest_dir.mkdir(parents=True, exist_ok=True)

    saved = []
    for f in files:
        ext = (f.filename.rsplit(".", 1)[-1].lower() if "." in (f.filename or "") else "")
        if ext not in ALLOWED_IMAGE_EXTS:
            raise HTTPException(status_code=400, detail=f"File type not allowed: {ext}")

        data = await f.read()
        if len(data) > MAX_IMAGE_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_IMAGE_FILE_MB} MB)")

        fname = _safe_name(f.filename or f"image_{secrets.token_hex(3)}.{ext}")
        path = dest_dir / fname
        with open(path, "wb") as out:
            out.write(data)

        url_path = f"/uploads/dctest/{station_id}/{report_id}/{key}/{fname}"
        saved.append({
            "filename": fname,
            "size": len(data),
            "url": url_path,
            "remark": remark or "",
            "uploadedAt": datetime.now(timezone.utc),
            "index": item_index,          # ‡πÄ‡∏Å‡πá‡∏ö index ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Å‡∏•‡∏±‡∏ö
        })

    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô: push ‡∏•‡∏á photos.<key>
    await coll.update_one(
        {"_id": oid},
        {"$push": {f"photos.{key}": {"$each": saved}}, "$set": {"updatedAt": datetime.now(timezone.utc)}}
    )

    return {"ok": True, "count": len(saved), "key": key, "files": saved}


@app.post("/dctestreport/{report_id}/finalize")
async def dc_testreport_finalize(
    report_id: str,
    station_id: str = Form(...),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_dc_testreport_collection_for(station_id)
    from bson import ObjectId
    oid = ObjectId(report_id)
    res = await coll.update_one(
        {"_id": oid},
        {"$set": {"status": "submitted", "submittedAt": datetime.now(timezone.utc)}}
    )
    if res.matched_count == 0:
        raise HTTPException(status_code=404, detail="Report not found")
    return {"ok": True}

@app.post("/dcurl/upload-files", status_code=201)
async def dcurl_upload_files(
    station_id: str = Form(...),
    reportDate: str = Form(...),                 # "YYYY-MM-DD" ‡∏´‡∏£‡∏∑‡∏≠ ISO
    files: list[UploadFile] = File(...),
    current: UserClaims = Depends(get_current_user),
):
    # auth
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    # ‡∏ï‡∏£‡∏ß‡∏à/‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô
    coll = get_dcurl_coll_upload(station_id)

    # parse ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô UTC datetime (‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß)
    dc_date = normalize_pm_date(reportDate)

    # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á: /uploads/pmurl/<station_id>/<YYYY-MM-DD>/
    # subdir = report_dt_utc.astimezone(th_tz).date().isoformat()
    subdir = dc_date
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "dcurl" / station_id / subdir
    dest_dir.mkdir(parents=True, exist_ok=True)

    urls = []
    metas = []
    total_size = 0

    for f in files:
        ext = (f.filename.rsplit(".",1)[-1].lower() if "." in f.filename else "")
        if ext not in ALLOWED_EXTS or ext != "pdf":
            raise HTTPException(status_code=400, detail=f"Only PDF allowed, got: {ext}")

        data = await f.read()
        total_size += len(data)
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        safe = _safe_name(f.filename or f"file_{secrets.token_hex(3)}.pdf")
        dest = dest_dir / safe
        with open(dest, "wb") as out:
            out.write(data)

        url = f"/uploads/dcurl/{station_id}/{subdir}/{safe}"   # ‚Üê ‡∏à‡∏∞‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å StaticFiles ‡∏ó‡∏µ‡πà mount ‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß
        urls.append(url)
        metas.append({"name": f.filename, "size": len(data)})

    now = datetime.now(timezone.utc)
    doc = {
        "station": station_id,
        "dc_date": dc_date,   
        "urls": urls,
        "meta": {"files": metas},
        "source": "upload-files",
        "createdAt": now,
        "updatedAt": now,
    }
    res = await coll.insert_one(doc)

    return {"ok": True, "inserted_id": str(res.inserted_id), "count": len(urls), "urls": urls}

@app.get("/dcurl/list")
async def dcurl_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
):
    """
    ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå PM (PDF) ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ‡∏ï‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ ‡∏à‡∏≤‡∏Å PMUrlDB/<station_id>
    - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö pm_date (string 'YYYY-MM-DD') ‡πÅ‡∏•‡∏∞ reportDate (Date/ISO)
    - ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏õ‡πÄ‡∏Å‡πà‡∏≤ (createdAt desc, _id desc)
    - ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô /pmreport/list (‡∏°‡∏µ file_url ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å)
    """
    coll = get_dcurl_coll_upload(station_id)
    skip = (page - 1) * pageSize

    # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    cursor = coll.find(
        {},
        {"_id": 1, "dc_date": 1, "reportDate": 1, "urls": 1, "createdAt": 1}
    ).sort([("createdAt", -1), ("_id", -1)]).skip(skip).limit(pageSize)

    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    def _dc_date_from(doc: dict) -> str | None:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ string 'YYYY-MM-DD'
        - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ pm_date (string) ‚Üí ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
        - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ reportDate (datetime/string) ‚Üí ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡πâ‡∏ß .date().isoformat()
        """
        # ‡∏£‡∏∏‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà: ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô pm_date (string)
        s = doc.get("dc_date")
        if isinstance(s, str) and re.fullmatch(r"\d{4}-\d{2}-\d{2}$", s):
            return s

        # ‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Å‡πà‡∏≤: ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô reportDate (Date/ISO)
        rd = doc.get("reportDate")
        if isinstance(rd, datetime):
            return rd.astimezone(th_tz).date().isoformat()
        if isinstance(rd, str):
            try:
                dt = datetime.fromisoformat(rd.replace("Z", "+00:00"))
            except Exception:
                # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏ã‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ ‚Üí ‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢
                try:
                    dt = datetime.fromisoformat(rd).replace(tzinfo=th_tz)
                except Exception:
                    return None
            return dt.astimezone(th_tz).date().isoformat()

        return None

    items = []
    dc_date_arr = []

    for it in items_raw:
        dc_date_str = _dc_date_from(it)
        if dc_date_str:
            dc_date_arr.append(dc_date_str)

        urls = it.get("urls") or []
        first_url = urls[0] if urls else ""

        items.append({
            "id": str(it["_id"]),
            "dc_date": dc_date_str,                         # 'YYYY-MM-DD' | None
            "createdAt": _ensure_utc_iso(it.get("createdAt")),
            "file_url": first_url,                          # ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å (‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î)
            "urls": urls,                                   # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ü‡∏£‡∏≠‡∏ô‡∏ï‡πå‡∏≠‡∏¢‡∏≤‡∏Å‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        })

    return {
        "items": items,
        "dc_date": [d for d in dc_date_arr if d],          # ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô /pmreport/list
        "page": page,
        "pageSize": pageSize,
        "total": total,
    }



class EquipmentBlock(BaseModel):
    manufacturers: List[str] = []
    models: List[str] = []
    serialNumbers: List[str] = []

SymbolLiteral = Literal["", "pass", "notPass", "notTest"]
PhaseLiteral  = Literal["", "L1L2L3", "L3L2L1"]

class PersonSig(BaseModel):
    name: str = ""
    signature: str = ""   # ‡πÄ‡∏Å‡πá‡∏ö path/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏≤‡∏¢‡πÄ‡∏ã‡πá‡∏ô (‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)
    date: str = ""        # "YYYY-MM-DD"
    company: str = ""

class ResponsibilityBlock(BaseModel):
    performed: PersonSig = PersonSig()
    approved:  PersonSig = PersonSig()
    witnessed: PersonSig = PersonSig()

class SignatureBlock(BaseModel):
    responsibility: ResponsibilityBlock = ResponsibilityBlock()

class DCSubmitIn(BaseModel):
    station_id: str
    issue_id: Optional[str] = None 
    job: Dict[str, Any]          # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏°‡∏ü‡∏≠‡∏£‡πå‡∏° (issue_id, found_date, ... )
    head: Dict[str,Any]
    inspection_date: Optional[str] = None  # "YYYY-MM-DD" ‡∏´‡∏£‡∏∑‡∏≠ ISO; ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏à‡∏∞ fallback ‡πÄ‡∏õ‡πá‡∏ô job.found_date
    equipment: Optional[EquipmentBlock] = None
    electrical_safety: Dict[str, Any] = Field(default_factory=dict)
    charger_safety: Dict[str, Any] = Field(default_factory=dict)
    remarks: Dict[str, Any] = Field(default_factory=dict)
    symbol: Optional[SymbolLiteral] = None
    phaseSequence: Optional[PhaseLiteral] = None
    signature: Optional[SignatureBlock] = None 

async def _ensure_dc_indexes(coll):
    try:
        await coll.create_index([("createdAt", -1), ("_id", -1)])
        # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏±‡∏ô‡∏ã‡πâ‡∏≥‡πÄ‡∏•‡∏Ç‡πÉ‡∏ö‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ: ‡πÄ‡∏õ‡∏¥‡∏î unique issue_id ‡∏Å‡πá‡πÑ‡∏î‡πâ (‡∏ñ‡πâ‡∏≤‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤ unique)
        # await coll.create_index("issue_id", unique=True, sparse=True)
    except Exception:
        pass

def _normalize_tick_to_pass(obj):
    if isinstance(obj, dict):
        return {k: _normalize_tick_to_pass(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [_normalize_tick_to_pass(v) for v in obj]
    if isinstance(obj, str):
        return "pass" if obj == "‚úì" else obj
    return obj


@app.post("/dcreport/submit")
async def dcreport_submit(body: DCSubmitIn, current: UserClaims = Depends(get_current_user)):
    station_id = body.station_id.strip()
    # Auth: admin ‡∏ú‡πà‡∏≤‡∏ô‡∏´‡∏°‡∏î, ‡∏Ñ‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÉ‡∏ô station ‡∏ô‡∏µ‡πâ
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_dc_testreport_collection_for(station_id)
    await _ensure_dc_indexes(coll)

    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î cm_date (string 'YYYY-MM-DD') ‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á /cmreport/list
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏°‡∏≤ ‚Üí ‡πÉ‡∏ä‡πâ job.found_date ‚Üí ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏µ‡∏Å ‚Üí ‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ (‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢)
    dc_date_src = body.inspection_date or body.head.get("inspection_date")
    if dc_date_src:
        dc_date = normalize_pm_date(dc_date_src)   # ‡∏Ñ‡∏∑‡∏ô "YYYY-MM-DD"
    else:
        dc_date = datetime.now(th_tz).date().isoformat()

    issue_id = (body.head or {}).get("issue_id")  or (body.job or {}).get("issue_id") 

    electrical_safety = _normalize_tick_to_pass(body.electrical_safety or {})

    charger_safety = _normalize_tick_to_pass(body.charger_safety or {})
    doc = {
        "station_id": station_id,
        "issue_id": issue_id,
        "inspection_date": dc_date,
        # "job": body.job,              # ‡πÄ‡∏Å‡πá‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏Å‡πâ‡∏≠‡∏ô (issue_id, severity, etc.)
        "head": body.head,
        "equipment": body.equipment.dict() if body.equipment else {"manufacturers": [], "models": [], "serialNumbers": []},
        "electrical_safety": electrical_safety,
        "charger_safety": charger_safety,
        "remarks": body.remarks or {},
        "symbol": body.symbol,
        "phaseSequence": body.phaseSequence,
        "signature": body.signature.dict() if body.signature else None,
        "createdAt": datetime.now(timezone.utc),
        "updatedAt": datetime.now(timezone.utc),
        "photos": {},                 # ‡∏£‡∏π‡∏õ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ï‡∏¥‡∏°‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏µ‡πà /cmreport/{report_id}/photos
    }

    res = await coll.insert_one(doc)
    return {"ok": True, "report_id": str(res.inserted_id)}

#---------------------------------------------------------------------- Test Report (AC)
def get_ac_testreport_collection_for(station_id: str):
    _validate_station_id(station_id)
    coll = ACTestReportDB.get_collection(str(station_id))
    return coll

def get_acurl_coll_upload(station_id: str):
    _validate_station_id(station_id)
    coll = ACUrlDB.get_collection(str(station_id))
    return coll

@app.get("/actestreport/list")
async def actestreport_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
):
    coll = get_ac_testreport_collection_for(station_id)
    skip = (page - 1) * pageSize

    cursor = coll.find({}, {"_id": 1, "inspection_date": 1, "createdAt": 1}).sort(
        [("createdAt", -1), ("_id", -1)]
    ).skip(skip).limit(pageSize)
    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    # --- ‡∏î‡∏∂‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å PMReportURL ‡πÇ‡∏î‡∏¢ map ‡∏î‡πâ‡∏ß‡∏¢ pm_date (string) ---
    ac_dates = [it.get("inspection_date") for it in items_raw if it.get("inspection_date")]
    urls_coll = get_acurl_coll_upload(station_id)
    url_by_day: dict[str, str] = {}

    if ac_dates:
        ucur = urls_coll.find({"inspection_date": {"$in": ac_dates}}, {"inspection_date": 1, "urls": 1})
        url_docs = await ucur.to_list(length=10_000)
        for u in url_docs:
            day = u.get("inspection_date")
            first_url = (u.get("urls") or [None])[0]
            if day and first_url and day not in url_by_day:
                url_by_day[day] = first_url

    items = [{
        "id": str(it["_id"]),
        "inspection_date": it.get("inspection_date"),
        "createdAt": _ensure_utc_iso(it.get("createdAt")),
        "file_url": url_by_day.get(it.get("inspection_date") or "", ""),
    } for it in items_raw]

    ac_date_arr = [it.get("inspection_date") for it in items_raw if it.get("inspection_date")]
    # status_arr = [it.get("status") for it in items_raw if it.get("status")]
    return {"items": items, "inspection_date": ac_date_arr, "page": page, "pageSize": pageSize, "total": total}

# ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
UPLOADS_ROOT = os.getenv("UPLOADS_ROOT", "./uploads")
os.makedirs(UPLOADS_ROOT, exist_ok=True)

# ‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏∑‡∏ô‡πÉ‡∏´‡πâ Frontend ‡∏ú‡πà‡∏≤‡∏ô /uploads/...
app.mount("/uploads", StaticFiles(directory=UPLOADS_ROOT, html=False), name="uploads")

# ALLOWED_EXTS = {"jpg","jpeg","png","webp","gif"}
# MAX_FILE_MB = 10

def _safe_name(name: str) -> str:
    # ‡∏Å‡∏±‡∏ô path traversal ‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡πÅ‡∏õ‡∏•‡∏Å ‡πÜ
    base = re.sub(r"[^A-Za-z0-9._-]+", "_", name)
    return base[:120] or secrets.token_hex(4)

def _ext(fname: str) -> str:
    return (fname.rsplit(".",1)[-1].lower() if "." in fname else "")

# ---- config ‡πÑ‡∏ü‡∏•‡πå/‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡∏ß‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô) ----
ALLOWED_IMAGE_EXTS = {"jpg", "jpeg", "png", "webp", "gif"}
MAX_IMAGE_FILE_MB = 10

PHOTO_GROUP_KEYS = [
    "nameplate",       # index 0
    "charger",         # index 1
    "circuit_breaker", # index 2
    "rcd",             # index 3
    "gun1",            # index 4
    "gun2",            # index 5
]

def _key_for_index(i: int) -> str:
    return PHOTO_GROUP_KEYS[i] if 0 <= i < len(PHOTO_GROUP_KEYS) else f"extra{i-5}"

@app.post("/actestreport/{report_id}/photos")
async def ac_testreport_upload_photos(
    report_id: str,
    station_id: str = Form(...),
    item_index: int = Form(...),               # <<-- ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å group ‚Üí index
    files: list[UploadFile] = File(...),
    remark: str | None = Form(None),
    current: UserClaims = Depends(get_current_user),
):
    # auth
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    # ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ô‡∏µ‡πâ
    coll = get_ac_testreport_collection_for(station_id)
    from bson import ObjectId
    try:
        oid = ObjectId(report_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Bad report_id")

    doc = await coll.find_one({"_id": oid}, {"_id": 1, "station_id": 1})
    if not doc:
        raise HTTPException(status_code=404, detail="Report not found")
    if doc.get("station_id") != station_id:
        raise HTTPException(status_code=400, detail="station_id mismatch")

    # ‡πÅ‡∏õ‡∏•‡∏á index ‚Üí ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏µ‡∏¢‡πå‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå/‡∏Ñ‡∏µ‡∏¢‡πå‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
    key = _key_for_index(item_index)  # e.g. nameplate/charger/.../extra1

    # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "actest" / station_id / report_id / key
    dest_dir.mkdir(parents=True, exist_ok=True)

    saved = []
    for f in files:
        ext = (f.filename.rsplit(".", 1)[-1].lower() if "." in (f.filename or "") else "")
        if ext not in ALLOWED_IMAGE_EXTS:
            raise HTTPException(status_code=400, detail=f"File type not allowed: {ext}")

        data = await f.read()
        if len(data) > MAX_IMAGE_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_IMAGE_FILE_MB} MB)")

        fname = _safe_name(f.filename or f"image_{secrets.token_hex(3)}.{ext}")
        path = dest_dir / fname
        with open(path, "wb") as out:
            out.write(data)

        url_path = f"/uploads/actest/{station_id}/{report_id}/{key}/{fname}"
        saved.append({
            "filename": fname,
            "size": len(data),
            "url": url_path,
            "remark": remark or "",
            "uploadedAt": datetime.now(timezone.utc),
            "index": item_index,          # ‡πÄ‡∏Å‡πá‡∏ö index ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Å‡∏•‡∏±‡∏ö
        })

    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô: push ‡∏•‡∏á photos.<key>
    await coll.update_one(
        {"_id": oid},
        {"$push": {f"photos.{key}": {"$each": saved}}, "$set": {"updatedAt": datetime.now(timezone.utc)}}
    )

    return {"ok": True, "count": len(saved), "key": key, "files": saved}


@app.post("/actestreport/{report_id}/finalize")
async def ac_testreport_finalize(
    report_id: str,
    station_id: str = Form(...),
    current: UserClaims = Depends(get_current_user),
):
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_ac_testreport_collection_for(station_id)
    from bson import ObjectId
    oid = ObjectId(report_id)
    res = await coll.update_one(
        {"_id": oid},
        {"$set": {"status": "submitted", "submittedAt": datetime.now(timezone.utc)}}
    )
    if res.matched_count == 0:
        raise HTTPException(status_code=404, detail="Report not found")
    return {"ok": True}

@app.post("/acurl/upload-files", status_code=201)
async def acurl_upload_files(
    station_id: str = Form(...),
    reportDate: str = Form(...),                 # "YYYY-MM-DD" ‡∏´‡∏£‡∏∑‡∏≠ ISO
    files: list[UploadFile] = File(...),
    current: UserClaims = Depends(get_current_user),
):
    # auth
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    # ‡∏ï‡∏£‡∏ß‡∏à/‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô
    coll = get_acurl_coll_upload(station_id)

    # parse ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô UTC datetime (‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß)
    ac_date = normalize_pm_date(reportDate)

    # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á: /uploads/pmurl/<station_id>/<YYYY-MM-DD>/
    # subdir = report_dt_utc.astimezone(th_tz).date().isoformat()
    subdir = ac_date
    dest_dir = pathlib.Path(UPLOADS_ROOT) / "acurl" / station_id / subdir
    dest_dir.mkdir(parents=True, exist_ok=True)

    urls = []
    metas = []
    total_size = 0

    for f in files:
        ext = (f.filename.rsplit(".",1)[-1].lower() if "." in f.filename else "")
        if ext not in ALLOWED_EXTS or ext != "pdf":
            raise HTTPException(status_code=400, detail=f"Only PDF allowed, got: {ext}")

        data = await f.read()
        total_size += len(data)
        if len(data) > MAX_FILE_MB * 1024 * 1024:
            raise HTTPException(status_code=413, detail=f"File too large (> {MAX_FILE_MB} MB)")

        safe = _safe_name(f.filename or f"file_{secrets.token_hex(3)}.pdf")
        dest = dest_dir / safe
        with open(dest, "wb") as out:
            out.write(data)

        url = f"/uploads/acurl/{station_id}/{subdir}/{safe}"   # ‚Üê ‡∏à‡∏∞‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å StaticFiles ‡∏ó‡∏µ‡πà mount ‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß
        urls.append(url)
        metas.append({"name": f.filename, "size": len(data)})

    now = datetime.now(timezone.utc)
    doc = {
        "station": station_id,
        "ac_date": ac_date,   
        "urls": urls,
        "meta": {"files": metas},
        "source": "upload-files",
        "createdAt": now,
        "updatedAt": now,
    }
    res = await coll.insert_one(doc)

    return {"ok": True, "inserted_id": str(res.inserted_id), "count": len(urls), "urls": urls}

@app.get("/acurl/list")
async def acurl_list(
    station_id: str = Query(...),
    page: int = Query(1, ge=1),
    pageSize: int = Query(20, ge=1, le=100),
):
    """
    ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå PM (PDF) ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ‡∏ï‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ ‡∏à‡∏≤‡∏Å PMUrlDB/<station_id>
    - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö pm_date (string 'YYYY-MM-DD') ‡πÅ‡∏•‡∏∞ reportDate (Date/ISO)
    - ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏õ‡πÄ‡∏Å‡πà‡∏≤ (createdAt desc, _id desc)
    - ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô /pmreport/list (‡∏°‡∏µ file_url ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å)
    """
    coll = get_acurl_coll_upload(station_id)
    skip = (page - 1) * pageSize

    # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    cursor = coll.find(
        {},
        {"_id": 1, "ac_date": 1, "reportDate": 1, "urls": 1, "createdAt": 1}
    ).sort([("createdAt", -1), ("_id", -1)]).skip(skip).limit(pageSize)

    items_raw = await cursor.to_list(length=pageSize)
    total = await coll.count_documents({})

    def _ac_date_from(doc: dict) -> str | None:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ string 'YYYY-MM-DD'
        - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ pm_date (string) ‚Üí ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
        - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ reportDate (datetime/string) ‚Üí ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡πâ‡∏ß .date().isoformat()
        """
        # ‡∏£‡∏∏‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà: ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô pm_date (string)
        s = doc.get("ac_date")
        if isinstance(s, str) and re.fullmatch(r"\d{4}-\d{2}-\d{2}$", s):
            return s

        # ‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Å‡πà‡∏≤: ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô reportDate (Date/ISO)
        rd = doc.get("reportDate")
        if isinstance(rd, datetime):
            return rd.astimezone(th_tz).date().isoformat()
        if isinstance(rd, str):
            try:
                dt = datetime.fromisoformat(rd.replace("Z", "+00:00"))
            except Exception:
                # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏ã‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ ‚Üí ‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢
                try:
                    dt = datetime.fromisoformat(rd).replace(tzinfo=th_tz)
                except Exception:
                    return None
            return dt.astimezone(th_tz).date().isoformat()

        return None

    items = []
    ac_date_arr = []

    for it in items_raw:
        ac_date_str = _ac_date_from(it)
        if ac_date_str:
            ac_date_arr.append(ac_date_str)

        urls = it.get("urls") or []
        first_url = urls[0] if urls else ""

        items.append({
            "id": str(it["_id"]),
            "ac_date": ac_date_str,                         # 'YYYY-MM-DD' | None
            "createdAt": _ensure_utc_iso(it.get("createdAt")),
            "file_url": first_url,                          # ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å (‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î)
            "urls": urls,                                   # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ü‡∏£‡∏≠‡∏ô‡∏ï‡πå‡∏≠‡∏¢‡∏≤‡∏Å‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        })

    return {
        "items": items,
        "ac_date": [d for d in ac_date_arr if d],          # ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô /pmreport/list
        "page": page,
        "pageSize": pageSize,
        "total": total,
    }



# class ACEquipmentBlock(BaseModel):
#     manufacturers: List[str] = []
#     models: List[str] = []
#     serialNumbers: List[str] = []

# ACSymbolLiteral = Literal["", "pass", "notPass", "notTest"]
# ACPhaseLiteral  = Literal["", "L1L2L3", "L3L2L1"]

# class ACPersonSig(BaseModel):
#     name: str = ""
#     signature: str = ""   # ‡πÄ‡∏Å‡πá‡∏ö path/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏≤‡∏¢‡πÄ‡∏ã‡πá‡∏ô (‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)
#     date: str = ""        # "YYYY-MM-DD"
#     company: str = ""

# class ACResponsibilityBlock(BaseModel):
#     performed: PersonSig = PersonSig()
#     approved:  PersonSig = PersonSig()
#     witnessed: PersonSig = PersonSig()

# class ACSignatureBlock(BaseModel):
#     responsibility: ResponsibilityBlock = ResponsibilityBlock()

class ACSubmitIn(BaseModel):
    station_id: str
    issue_id: Optional[str] = None 
    # job: Dict[str, Any]          # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏°‡∏ü‡∏≠‡∏£‡πå‡∏° (issue_id, found_date, ... )
    head: Dict[str,Any]
    inspection_date: Optional[str] = None  # "YYYY-MM-DD" ‡∏´‡∏£‡∏∑‡∏≠ ISO; ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏à‡∏∞ fallback ‡πÄ‡∏õ‡πá‡∏ô job.found_date
    equipment: Optional[EquipmentBlock] = None
    electrical_safety: Dict[str, Any] = Field(default_factory=dict)
    charger_safety: Dict[str, Any] = Field(default_factory=dict)
    remarks: Dict[str, Any] = Field(default_factory=dict)
    symbol: Optional[SymbolLiteral] = None
    phaseSequence: Optional[PhaseLiteral] = None
    signature: Optional[SignatureBlock] = None 

async def _ensure_dc_indexes(coll):
    try:
        await coll.create_index([("createdAt", -1), ("_id", -1)])
        # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏Å‡∏±‡∏ô‡∏ã‡πâ‡∏≥‡πÄ‡∏•‡∏Ç‡πÉ‡∏ö‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ: ‡πÄ‡∏õ‡∏¥‡∏î unique issue_id ‡∏Å‡πá‡πÑ‡∏î‡πâ (‡∏ñ‡πâ‡∏≤‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤ unique)
        # await coll.create_index("issue_id", unique=True, sparse=True)
    except Exception:
        pass

def _normalize_tick_to_pass(obj):
    if isinstance(obj, dict):
        return {k: _normalize_tick_to_pass(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [_normalize_tick_to_pass(v) for v in obj]
    if isinstance(obj, str):
        return "pass" if obj == "‚úì" else obj
    return obj


@app.post("/acreport/submit")
async def acreport_submit(body: ACSubmitIn, current: UserClaims = Depends(get_current_user)):
    station_id = body.station_id.strip()
    # Auth: admin ‡∏ú‡πà‡∏≤‡∏ô‡∏´‡∏°‡∏î, ‡∏Ñ‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÉ‡∏ô station ‡∏ô‡∏µ‡πâ
    if current.role != "admin" and station_id not in set(current.station_ids):
        raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_ac_testreport_collection_for(station_id)
    await _ensure_dc_indexes(coll)

    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î cm_date (string 'YYYY-MM-DD') ‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á /cmreport/list
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏°‡∏≤ ‚Üí ‡πÉ‡∏ä‡πâ job.found_date ‚Üí ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏µ‡∏Å ‚Üí ‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ (‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢)
    ac_date_src = body.inspection_date or body.head.get("inspection_date")
    if ac_date_src:
        ac_date = normalize_pm_date(ac_date_src)   # ‡∏Ñ‡∏∑‡∏ô "YYYY-MM-DD"
    else:
        ac_date = datetime.now(th_tz).date().isoformat()

    issue_id = (body.head or {}).get("issue_id")  or (body.head or {}).get("issue_id") 

    electrical_safety = _normalize_tick_to_pass(body.electrical_safety or {})

    charger_safety = _normalize_tick_to_pass(body.charger_safety or {})
    doc = {
        "station_id": station_id,
        "issue_id": issue_id,
        "inspection_date": ac_date,
        # "job": body.job,              # ‡πÄ‡∏Å‡πá‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏Å‡πâ‡∏≠‡∏ô (issue_id, severity, etc.)
        "head": body.head,
        "equipment": body.equipment.dict() if body.equipment else {"manufacturers": [], "models": [], "serialNumbers": []},
        "electrical_safety": electrical_safety,
        "charger_safety": charger_safety,
        "remarks": body.remarks or {},
        "symbol": body.symbol,
        "phaseSequence": body.phaseSequence,
        "signature": body.signature.dict() if body.signature else None,
        "createdAt": datetime.now(timezone.utc),
        "updatedAt": datetime.now(timezone.utc),
        "photos": {},                 # ‡∏£‡∏π‡∏õ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ï‡∏¥‡∏°‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏µ‡πà /cmreport/{report_id}/photos
    }

    res = await coll.insert_one(doc)
    return {"ok": True, "report_id": str(res.inserted_id)}


# ----------------------------------------------------------------------- device page
def get_device_collection_for(station_id: str):
    if not re.fullmatch(r"[A-Za-z0-9_\-]+", str(station_id)):
        raise HTTPException(status_code=400, detail="Bad station_id")
    return deviceDB.get_collection(str(station_id))

# (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ) ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡πÅ‡∏ö‡∏ö lazy ‡∏ï‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ
async def _ensure_util_index(coll):
    try:
        await coll.create_index([("timestamp", -1), ("_id", -1)])
    except Exception:
        pass

@app.get("/utilization/stream")
async def utilization_stream(request: Request, station_id: str = Query(...), current: UserClaims = Depends(get_current_user)):
    # if current.role != "admin" and station_id not in set(current.station_ids):
    #     raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_device_collection_for(station_id)
    headers = {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "X-Accel-Buffering": "no",
    }

    async def event_generator():
        # ‡∏™‡πà‡∏á snapshot ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô
        latest = await coll.find_one({}, sort=[("timestamp", -1), ("_id", -1)])
        if latest:
            latest["_id"] = str(latest["_id"])
            latest["timestamp_utc"] = _ensure_utc_iso(latest.get("timestamp_utc"))
            yield f"event: init\ndata: {json.dumps(latest)}\n\n"

        # ‡∏ï‡πà‡∏≠‡∏î‡πâ‡∏ß‡∏¢ change stream (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô replica set / Atlas tier ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)
        try:
            async with coll.watch(full_document='updateLookup') as stream:
                async for change in stream:
                    if await request.is_disconnected():
                        break
                    doc = change.get("fullDocument")
                    if not doc:
                        continue
                    doc["_id"] = str(doc["_id"])
                    doc["timestamp_utc"] = _ensure_utc_iso(doc.get("timestamp_utc"))
                    yield f"data: {json.dumps(doc)}\n\n"
        except Exception:
            # fallback: ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (‡πÄ‡∏ä‡πà‡∏ô standalone) ‡πÉ‡∏´‡πâ polling
            last_id = latest.get("_id") if latest else None
            while not await request.is_disconnected():
                doc = await coll.find_one({}, sort=[("timestamp_utc", -1), ("_id", -1)])
                if doc and str(doc["_id"]) != str(last_id):
                    last_id = str(doc["_id"])
                    doc["_id"] = last_id
                    doc["timestamp_utc"] = _ensure_utc_iso(doc.get("timestamp_utc"))
                    yield f"data: {json.dumps(doc)}\n\n"
                else:
                    yield ": keep-alive\n\n"
                await asyncio.sleep(5)

    return StreamingResponse(event_generator(), headers=headers)



#-------------------------------------------------------------------- setting page
def get_setting_collection_for(station_id: str):
    if not re.fullmatch(r"[A-Za-z0-9_\-]+", str(station_id)):
        raise HTTPException(status_code=400, detail="Bad station_id")
    return settingDB.get_collection(str(station_id))

# (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ) ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡πÅ‡∏ö‡∏ö lazy ‡∏ï‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ
async def _ensure_util_index(coll):
    try:
        await coll.create_index([("timestamp", -1), ("_id", -1)])
    except Exception:
        pass

@app.get("/setting/stream")
async def setting_stream(request: Request, station_id: str = Query(...), current: UserClaims = Depends(get_current_user)):
    # if current.role != "admin" and station_id not in set(current.station_ids):
    #     raise HTTPException(status_code=403, detail="Forbidden station_id")

    coll = get_setting_collection_for(station_id)
    headers = {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "X-Accel-Buffering": "no",
    }

    async def event_generator():
        # ‡∏™‡πà‡∏á snapshot ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô
        latest = await coll.find_one({}, sort=[("timestamp", -1), ("_id", -1)])
        if latest:
            latest["_id"] = str(latest["_id"])
            latest["timestamp"] = _ensure_utc_iso(latest.get("timestamp"))
            yield f"event: init\ndata: {json.dumps(latest)}\n\n"

        # ‡∏ï‡πà‡∏≠‡∏î‡πâ‡∏ß‡∏¢ change stream (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô replica set / Atlas tier ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)
        try:
            async with coll.watch(full_document='updateLookup') as stream:
                async for change in stream:
                    if await request.is_disconnected():
                        break
                    doc = change.get("fullDocument")
                    if not doc:
                        continue
                    doc["_id"] = str(doc["_id"])
                    doc["timestamp"] = _ensure_utc_iso(doc.get("timestamp"))
                    yield f"data: {json.dumps(doc)}\n\n"
        except Exception:
            # fallback: ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (‡πÄ‡∏ä‡πà‡∏ô standalone) ‡πÉ‡∏´‡πâ polling
            last_id = latest.get("_id") if latest else None
            while not await request.is_disconnected():
                doc = await coll.find_one({}, sort=[("timestamp", -1), ("_id", -1)])
                if doc and str(doc["_id"]) != str(last_id):
                    last_id = str(doc["_id"])
                    doc["_id"] = last_id
                    doc["timestamp"] = _ensure_utc_iso(doc.get("timestamp"))
                    yield f"data: {json.dumps(doc)}\n\n"
                else:
                    yield ": keep-alive\n\n"
                await asyncio.sleep(5)

    return StreamingResponse(event_generator(), headers=headers)

@app.get("/setting")
async def setting_query(request: Request, station_id: str = Query(...), current: UserClaims = Depends(get_current_user)):
    """
    SSE ‡πÅ‡∏ö‡∏ö query param:
    - ‡∏™‡πà‡∏á snapshot ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (event: init)
    - ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô polling ‡∏Ç‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏ß‡∏á ‡πÜ
    """
    headers = {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "X-Accel-Buffering": "no",
    }
    coll = get_setting_collection_for(station_id)

    async def event_generator():
        last_id = None
        latest = await coll.find_one({}, sort=[("_id", -1)])  # ‚¨ÖÔ∏è ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á filter station_id ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÅ‡∏•‡πâ‡∏ß
        if latest:
            # latest["timestamp"] = _ensure_utc_iso(latest.get("timestamp"))
            latest["timestamp"] = latest.get("timestamp")
            last_id = latest.get("_id")
            yield "retry: 3000\n"
            yield "event: init\n"
            yield f"data: {to_json(latest)}\n\n"
        else:
            yield "retry: 3000\n\n"

        while True:
            if await request.is_disconnected():
                break

            doc = await coll.find_one({}, sort=[("_id", -1)])
            if doc and doc.get("_id") != last_id:
                # doc["timestamp"] = _ensure_utc_iso(doc.get("timestamp"))
                doc["timestamp"] = doc.get("timestamp")
                last_id = doc.get("_id")
                yield f"data: {to_json(doc)}\n\n"
            else:
                yield ": keep-alive\n\n"

            await asyncio.sleep(5)

    return StreamingResponse(event_generator(), headers=headers)

# from pdf.pdf_routes import router as pdf_router
# app.include_router(pdf_router, prefix="/pdf")
from pdf.pdf_routes import router as pdf_router
app.include_router(pdf_router)
from pdf.test_pdf import router as test_pdf_router
app.include_router(test_pdf_router)


class PLCMaxSetting(BaseModel):
    station_id: str = Field(..., min_length=1)
    dynamic_max_current1: Optional[float] = None   # A
    dynamic_max_power1: Optional[float] = None  


@app.post("/setting/PLC/MAX")
async def setting_plc(payload: PLCMaxSetting):
    now_iso = datetime.now().isoformat()

    # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà client ‡∏™‡πà‡∏á‡∏°‡∏≤‡∏à‡∏£‡∏¥‡∏á ‡πÜ (‡πÑ‡∏°‡πà‡∏î‡∏∂‡∏á default None)
    try:
        incoming = payload.model_dump(exclude_unset=True)   # Pydantic v2
    except Exception:
        incoming = payload.dict(exclude_unset=True)         # Pydantic v1

    station_id = incoming.get("station_id", payload.station_id)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á changes ‡∏à‡∏≤‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô request
    keys = ("dynamic_max_current1", "dynamic_max_power1")
    changes = {k: float(incoming[k]) for k in keys if k in incoming}

    # logging ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
    print(f"[{now_iso}] ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å Front:")
    print(f"  station_id = {station_id}")
    print("  dynamic_max_current1 =", changes.get("dynamic_max_current1", "(no change)"), "A")
    print("  dynamic_max_power1  =", changes.get("dynamic_max_power1",  "(no change)"), "kW")

    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏±‡∏Å‡∏ü‡∏¥‡∏•‡∏î‡πå ‚Üí ‡πÑ‡∏°‡πà publish (‡∏à‡∏∞‡∏ï‡∏≠‡∏ö 200 ‡∏´‡∏£‡∏∑‡∏≠ 400 ‡∏Å‡πá‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà‡∏î‡∏µ‡πÑ‡∏ã‡∏ô‡πå)
    if not changes:
        return {
            "ok": True,
            "message": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á (‡πÑ‡∏°‡πà‡∏™‡πà‡∏á MQTT)",
            "timestamp": now_iso,
            "mqtt": {
                "broker": f"{BROKER_HOST}:{BROKER_PORT}",
                "topic": MQTT_TOPIC,
                "published": False,
            },
            "data": {"station_id": station_id, "timestamp": now_iso},
        }

    # ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö payload MQTT ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô
    msg = {
        "station_id": station_id,
        **changes,
        "timestamp": now_iso,
        # "source": "fastapi/setting_plc"
    }
    payload_str = json.dumps(msg, ensure_ascii=False)

    # ‡∏™‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô MQTT
    published = False
    try:
        pub_result = mqtt_client.publish(MQTT_TOPIC, payload_str, qos=1, retain=False)
        pub_result.wait_for_publish(timeout=2.0)
        published = pub_result.is_published()
        rc = pub_result.rc
        print(f"[MQTT] publish rc={rc}, published={published}, topic={MQTT_TOPIC}")
    except Exception as e:
        print(f"[MQTT] publish error: {e}")
        published = False

    # ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö frontend
    return {
        "ok": True,
        "message": "‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å frontend ‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏™‡πà‡∏á MQTT ‡πÅ‡∏•‡πâ‡∏ß (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô)",
        "timestamp": now_iso,
        "mqtt": {
            "broker": f"{BROKER_HOST}:{BROKER_PORT}",
            "topic": MQTT_TOPIC,
            "published": bool(published),
        },
        "data": msg,
    }
class PLCCPCommand(BaseModel):
    station_id: str
    cp_status1: Literal["start", "stop"]

@app.post("/setting/PLC/CP")
async def setting_plc(payload: PLCCPCommand):
    now_iso = datetime.now().isoformat()

    # log ‡∏ù‡∏±‡πà‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
    print(f"[{now_iso}] ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å Front:")
    print(f"  station_id = {payload.station_id}")
    print(f"  cp_status1 = {payload.cp_status1}")
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° message ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô MQTT (‡πÉ‡∏™‡πà timestamp ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡πâ)
    msg = {
        "station_id": payload.station_id,
        "cp_status1": payload.cp_status1,
        "timestamp": now_iso,
        # "source": "fastapi/setting_plc"
    }
    payload_str = json.dumps(msg, ensure_ascii=False)

    # ‡∏™‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô MQTT (QoS 1, ‡πÑ‡∏°‡πà retain)
    try:
        pub_result = mqtt_client.publish(MQTT_TOPIC, payload_str, qos=1, retain=False)
        # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡πÜ (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ß‡∏£‡πå)
        pub_result.wait_for_publish(timeout=2.0)
        published = pub_result.is_published()
        rc = pub_result.rc
        print(f"[MQTT] publish rc={rc}, published={published}, topic={MQTT_TOPIC}")
    except Exception as e:
        print(f"[MQTT] publish error: {e}")
        published = False

    # ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö frontend
    return {
        "ok": True,
        "message": "‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å frontend ‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏™‡πà‡∏á MQTT ‡πÅ‡∏•‡πâ‡∏ß",
        "timestamp": now_iso,
        "mqtt": {
            "broker": f"{BROKER_HOST}:{BROKER_PORT}",
            "topic": MQTT_TOPIC,
            "published": bool(published),
        },
        "data": msg,
    }

class PLCH2MaxSetting(BaseModel):
    station_id: str = Field(..., min_length=1)
    dynamic_max_current2: Optional[float] = None   # A  ‚Üê optional
    dynamic_max_power2: Optional[float] = None     # kW (‡∏à‡∏≤‡∏Å front)


@app.post("/setting/PLC/MAXH2")
async def setting_plc(payload: PLCH2MaxSetting):
    now_iso = datetime.now().isoformat()

    # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ fields ‡∏ó‡∏µ‡πà client ‡∏™‡πà‡∏á‡∏°‡∏≤ (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ default)
    try:
        incoming = payload.model_dump(exclude_unset=True)  # Pydantic v2
    except Exception:
        incoming = payload.dict(exclude_unset=True)        # Pydantic v1

    station_id = incoming.get("station_id", payload.station_id)

    # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏à‡∏≤‡∏Å‡∏™‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏ô‡∏µ‡πâ
    keys = ("dynamic_max_current2", "dynamic_max_power2")
    changes = {k: float(incoming[k]) for k in keys if k in incoming}

    if not changes:
        # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô error ‡∏Å‡πá return ok=False ‡πÑ‡∏î‡πâ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô
        raise HTTPException(
            status_code=400,
            detail="At least one of dynamic_max_current2 or dynamic_max_power2 is required"
        )

    print(f"[{now_iso}] ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å Front: station_id={station_id}")
    print("  dynamic_max_current2 =", changes.get("dynamic_max_current2", "(no change)"), "A")
    print("  dynamic_max_power2  =", changes.get("dynamic_max_power2", "(no change)"), "kW")

    msg = {"station_id": station_id, **changes, "timestamp": now_iso}
    payload_str = json.dumps(msg, ensure_ascii=False)

    published = False
    try:
        pub_result = mqtt_client.publish(MQTT_TOPIC, payload_str, qos=1, retain=False)
        pub_result.wait_for_publish(timeout=2.0)
        published = pub_result.is_published()
        rc = pub_result.rc
        print(f"[MQTT] publish rc={rc}, published={published}, topic={MQTT_TOPIC}")
    except Exception as e:
        print(f"[MQTT] publish error: {e}")
        published = False

    return {
        "ok": True,
        "message": "‡∏™‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô",
        "timestamp": now_iso,
        "mqtt": {
            "broker": f"{BROKER_HOST}:{BROKER_PORT}",
            "topic": MQTT_TOPIC,
            "published": bool(published),
        },
        "data": msg,
    }

class PLCH2CPCommand(BaseModel):
    station_id: str
    cp_status2: Literal["start", "stop"]

@app.post("/setting/PLC/CPH2")
async def setting_plc(payload: PLCH2CPCommand):
    now_iso = datetime.now().isoformat()

    # log ‡∏ù‡∏±‡πà‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
    print(f"[{now_iso}] ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å Front:")
    print(f"  station_id = {payload.station_id}")
    print(f"  cp_status2 = {payload.cp_status2}")
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° message ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô MQTT (‡πÉ‡∏™‡πà timestamp ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡πâ)
    msg = {
        "station_id": payload.station_id,
        "cp_status2": payload.cp_status2,
        "timestamp": now_iso,
        # "source": "fastapi/setting_plc"
    }
    payload_str = json.dumps(msg, ensure_ascii=False)

    # ‡∏™‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô MQTT (QoS 1, ‡πÑ‡∏°‡πà retain)
    try:
        pub_result = mqtt_client.publish(MQTT_TOPIC, payload_str, qos=1, retain=False)
        # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡πÜ (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ß‡∏£‡πå)
        pub_result.wait_for_publish(timeout=2.0)
        published = pub_result.is_published()
        rc = pub_result.rc
        print(f"[MQTT] publish rc={rc}, published={published}, topic={MQTT_TOPIC}")
    except Exception as e:
        print(f"[MQTT] publish error: {e}")
        published = False

    # ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö frontend
    return {
        "ok": True,
        "message": "‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å frontend ‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏™‡πà‡∏á MQTT ‡πÅ‡∏•‡πâ‡∏ß",
        "timestamp": now_iso,
        "mqtt": {
            "broker": f"{BROKER_HOST}:{BROKER_PORT}",
            "topic": MQTT_TOPIC,
            "published": bool(published),
        },
        "data": msg,
    }

# --------------------------------------------------------------------- CBM Page
def get_cbm_collection_for(station_id: str):
    # ‡∏Å‡∏±‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡πÅ‡∏õ‡∏•‡∏Å ‡πÜ / injection: ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï a-z A-Z 0-9 _ -
    if not re.fullmatch(r"[A-Za-z0-9_\-]+", str(station_id)):
        raise HTTPException(status_code=400, detail="Bad station_id")
    return CBM_DB.get_collection(str(station_id))


@app.get("/CBM")
async def cbm_query(request: Request, station_id: str = Query(...), current: UserClaims = Depends(get_current_user)):
    """
    SSE ‡πÅ‡∏ö‡∏ö query param:
    - ‡∏™‡πà‡∏á snapshot ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (event: init)
    - ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô polling ‡∏Ç‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏ß‡∏á ‡πÜ
    """
    headers = {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "X-Accel-Buffering": "no",
    }
    coll = get_cbm_collection_for(station_id)

    async def event_generator():
        last_id = None
        latest = await coll.find_one({}, sort=[("_id", -1)])  # ‚¨ÖÔ∏è ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á filter station_id ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÅ‡∏•‡πâ‡∏ß
        if latest:
            # latest["timestamp"] = _ensure_utc_iso(latest.get("timestamp"))
            latest["timestamp"] = latest.get("timestamp")
            last_id = latest.get("_id")
            yield "retry: 3000\n"
            yield "event: init\n"
            yield f"data: {to_json(latest)}\n\n"
        else:
            yield "retry: 3000\n\n"

        while True:
            if await request.is_disconnected():
                break

            doc = await coll.find_one({}, sort=[("_id", -1)])
            if doc and doc.get("_id") != last_id:
                # doc["timestamp"] = _ensure_utc_iso(doc.get("timestamp"))
                doc["timestamp"] = doc.get("timestamp")
                last_id = doc.get("_id")
                yield f"data: {to_json(doc)}\n\n"
            else:
                yield ": keep-alive\n\n"

            await asyncio.sleep(5)

    return StreamingResponse(event_generator(), headers=headers)